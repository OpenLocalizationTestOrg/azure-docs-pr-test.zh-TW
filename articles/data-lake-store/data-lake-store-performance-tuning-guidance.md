---
title: "資料湖存放區效能調整指導方針 aaaAzure |Microsoft 文件"
description: "Azure Data Lake Store 效能微調指導方針"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: 939faa068c0f81d18d9533956f4d336bc4d0cbe3
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/06/2017
---
# <a name="tuning-azure-data-lake-store-for-performance"></a><span data-ttu-id="5ff12-103">針對效能目的調整 Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="5ff12-103">Tuning Azure Data Lake Store for performance</span></span>

<span data-ttu-id="5ff12-104">Data Lake Store 支援 I/O 密集分析和資料移動的高輸送量。</span><span class="sxs-lookup"><span data-stu-id="5ff12-104">Data Lake Store supports high-throughput for I/O intensive analytics and data movement.</span></span>  <span data-ttu-id="5ff12-105">在 Azure 資料湖存放區，使用所有可用的輸送量 – hello 可以讀取或寫入每秒資料量 – 是重要的 tooget hello 達到最佳效能。</span><span class="sxs-lookup"><span data-stu-id="5ff12-105">In Azure Data Lake Store, using all available throughput – hello amount of data that can be read or written per second – is important tooget hello best performance.</span></span>  <span data-ttu-id="5ff12-106">這可以藉由盡可能平行執行讀取和寫入來達成。</span><span class="sxs-lookup"><span data-stu-id="5ff12-106">This is achieved by performing as many reads and writes in parallel as possible.</span></span>

![Data Lake Store 效能](./media/data-lake-store-performance-tuning-guidance/throughput.png)

<span data-ttu-id="5ff12-108">Azure Data Lake Store 可以調整所有分析案例的 tooprovide hello 必要輸送量。</span><span class="sxs-lookup"><span data-stu-id="5ff12-108">Azure Data Lake Store can scale tooprovide hello necessary throughput for all analytics scenario.</span></span> <span data-ttu-id="5ff12-109">根據預設，Azure Data Lake Store 帳戶提供自動足夠處理能力 toomeet hello 需求廣泛的類別目錄的使用案例。</span><span class="sxs-lookup"><span data-stu-id="5ff12-109">By default, an Azure Data Lake Store account provides automatically enough throughput toomeet hello needs of a broad category of use cases.</span></span> <span data-ttu-id="5ff12-110">客戶會遇到 hello 預設限制 hello 的情況下，hello ADLS 帳戶可以設定的 tooprovide 增加輸送量，藉由連絡 Microsoft 支援服務。</span><span class="sxs-lookup"><span data-stu-id="5ff12-110">For hello cases where customers run into hello default limit, hello ADLS account can be configured tooprovide more throughput by contacting Microsoft support.</span></span>

## <a name="data-ingestion"></a><span data-ttu-id="5ff12-111">資料擷取</span><span class="sxs-lookup"><span data-stu-id="5ff12-111">Data ingestion</span></span>

<span data-ttu-id="5ff12-112">當擷取資料從來源系統 tooADLS，務必 hello 來源硬體、 來源的網路硬體和網路連線 tooADLS 的 tooconsider 可能 hello 形成瓶頸。</span><span class="sxs-lookup"><span data-stu-id="5ff12-112">When ingesting data from a source system tooADLS, it is important tooconsider that hello source hardware, source network hardware, and network connectivity tooADLS can be hello bottleneck.</span></span>  

![Data Lake Store 效能](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

<span data-ttu-id="5ff12-114">請務必 tooensure hello 資料移動，不會受到這些因素。</span><span class="sxs-lookup"><span data-stu-id="5ff12-114">It is important tooensure that hello data movement is not affected by these factors.</span></span>

### <a name="source-hardware"></a><span data-ttu-id="5ff12-115">來源硬體</span><span class="sxs-lookup"><span data-stu-id="5ff12-115">Source Hardware</span></span>

<span data-ttu-id="5ff12-116">不論您在 Azure 中使用內部部署電腦或 Vm，您應該仔細選取 hello 適當的硬體。</span><span class="sxs-lookup"><span data-stu-id="5ff12-116">Whether you are using on-premises machines or VMs in Azure, you should carefully select hello appropriate hardware.</span></span> <span data-ttu-id="5ff12-117">來源磁碟硬體，偏好 Ssd tooHDDs 並挑選更快的磁針與磁碟硬體。</span><span class="sxs-lookup"><span data-stu-id="5ff12-117">For Source Disk Hardware, prefer SSDs tooHDDs and pick disk hardware with faster spindles.</span></span> <span data-ttu-id="5ff12-118">使用來源網路硬體，hello 最 Nic。</span><span class="sxs-lookup"><span data-stu-id="5ff12-118">For Source Network Hardware, use hello fastest NICs possible.</span></span>  <span data-ttu-id="5ff12-119">在 Azure 上，我們建議 Azure D14 Vm 有 hello 適當功能強大的磁碟和網路硬體。</span><span class="sxs-lookup"><span data-stu-id="5ff12-119">On Azure, we recommend Azure D14 VMs which have hello appropriately powerful disk and networking hardware.</span></span>

### <a name="network-connectivity-tooazure-data-lake-store"></a><span data-ttu-id="5ff12-120">網路連線 tooAzure 資料湖存放區</span><span class="sxs-lookup"><span data-stu-id="5ff12-120">Network Connectivity tooAzure Data Lake Store</span></span>

<span data-ttu-id="5ff12-121">hello 網路連線，您的來源資料與 Azure 資料湖存放區之間有時可能 hello 瓶頸。</span><span class="sxs-lookup"><span data-stu-id="5ff12-121">hello network connectivity between your source data and Azure Data Lake store can sometimes be hello bottleneck.</span></span> <span data-ttu-id="5ff12-122">當您的來源資料是內部部署時，請考慮使用與 [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) 的專用連結。</span><span class="sxs-lookup"><span data-stu-id="5ff12-122">When your source data is On-Premises, consider using a dedicated link with [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span></span> <span data-ttu-id="5ff12-123">如果您的來源資料是在 Azure 中，hello 效能時將會最佳 hello 資料位於 hello 與 hello Data Lake Store 的相同 Azure 區域。</span><span class="sxs-lookup"><span data-stu-id="5ff12-123">If your source data is in Azure, hello performance will be best when hello data is in hello same Azure region as hello Data Lake Store.</span></span>

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a><span data-ttu-id="5ff12-124">設定最大平行處理的資料擷取工具</span><span class="sxs-lookup"><span data-stu-id="5ff12-124">Configure Data Ingestion tools for maximum parallelization</span></span>

<span data-ttu-id="5ff12-125">一旦您解決 hello 來源硬體和網路連線上述的瓶頸，您就準備好 tooconfigure 擷取工具。</span><span class="sxs-lookup"><span data-stu-id="5ff12-125">Once you have addressed hello source hardware and network connectivity bottlenecks above, you are ready tooconfigure your ingestion tools.</span></span> <span data-ttu-id="5ff12-126">hello 下表摘要說明 hello 金鑰設定數個常用的擷取工具並提供深入的效能微調他們的文件。</span><span class="sxs-lookup"><span data-stu-id="5ff12-126">hello following table summarizes hello key settings for several popular ingestion tools and provides in-depth performance tuning articles for them.</span></span>  <span data-ttu-id="5ff12-127">toolearn 更多有關哪些工具 toouse 案例中，請瀏覽[文章](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios)。</span><span class="sxs-lookup"><span data-stu-id="5ff12-127">toolearn more about which tool toouse for your scenario, visit this [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span></span>

| <span data-ttu-id="5ff12-128">工具</span><span class="sxs-lookup"><span data-stu-id="5ff12-128">Tool</span></span>               | <span data-ttu-id="5ff12-129">Settings</span><span class="sxs-lookup"><span data-stu-id="5ff12-129">Settings</span></span>     | <span data-ttu-id="5ff12-130">其他詳細資訊</span><span class="sxs-lookup"><span data-stu-id="5ff12-130">More Details</span></span>                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| <span data-ttu-id="5ff12-131">Powershell</span><span class="sxs-lookup"><span data-stu-id="5ff12-131">Powershell</span></span>       | <span data-ttu-id="5ff12-132">PerFileThreadCount、ConcurrentFileCount</span><span class="sxs-lookup"><span data-stu-id="5ff12-132">PerFileThreadCount, ConcurrentFileCount</span></span> |  [<span data-ttu-id="5ff12-133">連結</span><span class="sxs-lookup"><span data-stu-id="5ff12-133">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-get-started-powershell#performance-guidance-while-using-powershell)   |
| <span data-ttu-id="5ff12-134">AdlCopy</span><span class="sxs-lookup"><span data-stu-id="5ff12-134">AdlCopy</span></span>    | <span data-ttu-id="5ff12-135">Azure Data Lake Analytics units</span><span class="sxs-lookup"><span data-stu-id="5ff12-135">Azure Data Lake Analytics units</span></span>  |   [<span data-ttu-id="5ff12-136">連結</span><span class="sxs-lookup"><span data-stu-id="5ff12-136">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| <span data-ttu-id="5ff12-137">DistCp</span><span class="sxs-lookup"><span data-stu-id="5ff12-137">DistCp</span></span>            | <span data-ttu-id="5ff12-138">-m (mapper)</span><span class="sxs-lookup"><span data-stu-id="5ff12-138">-m (mapper)</span></span>   | [<span data-ttu-id="5ff12-139">連結</span><span class="sxs-lookup"><span data-stu-id="5ff12-139">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| <span data-ttu-id="5ff12-140">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5ff12-140">Azure Data Factory</span></span>| <span data-ttu-id="5ff12-141">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="5ff12-141">parallelCopies</span></span>    | [<span data-ttu-id="5ff12-142">連結</span><span class="sxs-lookup"><span data-stu-id="5ff12-142">Link</span></span>](../data-factory/data-factory-copy-activity-performance.md)                          |
| <span data-ttu-id="5ff12-143">Sqoop</span><span class="sxs-lookup"><span data-stu-id="5ff12-143">Sqoop</span></span>           | <span data-ttu-id="5ff12-144">fs.azure.block.size、-m (mapper)</span><span class="sxs-lookup"><span data-stu-id="5ff12-144">fs.azure.block.size, -m (mapper)</span></span>    |   [<span data-ttu-id="5ff12-145">連結</span><span class="sxs-lookup"><span data-stu-id="5ff12-145">Link</span></span>](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a><span data-ttu-id="5ff12-146">結構化您的資料集</span><span class="sxs-lookup"><span data-stu-id="5ff12-146">Structure your data set</span></span>

<span data-ttu-id="5ff12-147">當資料儲存在資料湖存放區，hello 檔案大小、 檔案及資料夾結構的數字會對效能造成影響。</span><span class="sxs-lookup"><span data-stu-id="5ff12-147">When data is stored in Data Lake Store, hello file size, number of files, and folder structure have an impact on performance.</span></span>  <span data-ttu-id="5ff12-148">hello 下一節說明這些區域中的最佳作法。</span><span class="sxs-lookup"><span data-stu-id="5ff12-148">hello following section describes best practices in these areas.</span></span>  

### <a name="file-size"></a><span data-ttu-id="5ff12-149">檔案大小</span><span class="sxs-lookup"><span data-stu-id="5ff12-149">File size</span></span>

<span data-ttu-id="5ff12-150">一般而言，例如 HDInsight 和 Azure Data Lake Analytics 的分析引擎都有每個檔案的額外負荷。</span><span class="sxs-lookup"><span data-stu-id="5ff12-150">Typically, analytics engines such as HDInsight and Azure Data Lake Analytics have a per-file overhead.</span></span>  <span data-ttu-id="5ff12-151">如果您將資料儲存為許多小型檔案，會造成效能的負面影響。</span><span class="sxs-lookup"><span data-stu-id="5ff12-151">If you store your data as many small files, this can negatively affect performance.</span></span>  

<span data-ttu-id="5ff12-152">一般情況下，將您的資料組織成較大大小的檔案，以提升效能。</span><span class="sxs-lookup"><span data-stu-id="5ff12-152">In general, organize your data into larger sized files for better performance.</span></span>  <span data-ttu-id="5ff12-153">根據經驗法則，將檔案中的資料集組織為 256MB 以上。</span><span class="sxs-lookup"><span data-stu-id="5ff12-153">As a rule of thumb, organize data sets in files of 256MB or larger.</span></span> <span data-ttu-id="5ff12-154">在類似影像和二進位資料的某些情況下，就不可能 tooprocess 它們以平行方式。</span><span class="sxs-lookup"><span data-stu-id="5ff12-154">In some cases such as images and binary data, it is not possible tooprocess them in parallel.</span></span>  <span data-ttu-id="5ff12-155">在這些情況下，建議您 tookeep 個別檔案小於 2 GB。</span><span class="sxs-lookup"><span data-stu-id="5ff12-155">In these cases, it is recommended tookeep individual files under 2GB.</span></span>

<span data-ttu-id="5ff12-156">有時候，在資料管線有限有大量的小型檔案 hello 未經處理資料的控制權。</span><span class="sxs-lookup"><span data-stu-id="5ff12-156">Sometimes, data pipelines have limited control over hello raw data which has lots of small files.</span></span>  <span data-ttu-id="5ff12-157">建議 toohave"烹飪 」 程序會產生較大的檔案 toouse 下游應用程式。</span><span class="sxs-lookup"><span data-stu-id="5ff12-157">It is recommended toohave a “cooking” process that generates larger files toouse for downstream applications.</span></span>  

### <a name="organizing-time-series-data-in-folders"></a><span data-ttu-id="5ff12-158">組織資料夾中的時間序列資料</span><span class="sxs-lookup"><span data-stu-id="5ff12-158">Organizing Time Series data in folders</span></span>

<span data-ttu-id="5ff12-159">Hive 和 ADLA 工作負載的時間序列資料的資料分割剪除有助於某些查詢讀取 hello 資料，進而改善效能的子集。</span><span class="sxs-lookup"><span data-stu-id="5ff12-159">For Hive and ADLA workloads, partition pruning of time-series data can help some queries read only a subset of hello data which improves performance.</span></span>    

<span data-ttu-id="5ff12-160">擷取時間序列資料的這些管線，通常會以檔案和資料夾結構命名非常嚴謹的方式來處理檔案。</span><span class="sxs-lookup"><span data-stu-id="5ff12-160">Those pipelines that ingest time-series data, often place their files with a very structured naming for files and folders.</span></span> <span data-ttu-id="5ff12-161">以下是很常見的範例，依日期結構化資料：</span><span class="sxs-lookup"><span data-stu-id="5ff12-161">Below is a very common example we see for data that is structured by date:</span></span>

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

<span data-ttu-id="5ff12-162">請注意，做為資料夾，以及在 hello 檔名不會顯示 hello 日期時間資訊。</span><span class="sxs-lookup"><span data-stu-id="5ff12-162">Notice that hello datetime information appears both as folders and in hello filename.</span></span>

<span data-ttu-id="5ff12-163">日期和時間，hello 以下是常見的模式</span><span class="sxs-lookup"><span data-stu-id="5ff12-163">For date and time, hello following is a common pattern</span></span>

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

<span data-ttu-id="5ff12-164">同樣地，您與 hello 資料夾和檔案的組織選擇的 hello 應該最佳化 hello 較大的檔案大小和合理的每個資料夾中的檔案數目。</span><span class="sxs-lookup"><span data-stu-id="5ff12-164">Again, hello choice you make with hello folder and file organization should optimize for hello larger file sizes and a reasonable number of files in each folder.</span></span>

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a><span data-ttu-id="5ff12-165">最佳化 HDInsight 上 Hadoop 和 Spark 工作負載的 I/O 大量作業</span><span class="sxs-lookup"><span data-stu-id="5ff12-165">Optimizing I/O intensive jobs on Hadoop and Spark workloads on HDInsight</span></span>

<span data-ttu-id="5ff12-166">作業分為下列三個類別的 hello:</span><span class="sxs-lookup"><span data-stu-id="5ff12-166">Jobs fall into one of hello following three categories:</span></span>

* <span data-ttu-id="5ff12-167">**CPU 密集作業**</span><span class="sxs-lookup"><span data-stu-id="5ff12-167">**CPU intensive.**</span></span>  <span data-ttu-id="5ff12-168">這些作業有很長的計算時間和最短的 I/O 時間。</span><span class="sxs-lookup"><span data-stu-id="5ff12-168">These jobs have long computation times with minimal I/O times.</span></span>  <span data-ttu-id="5ff12-169">範例包括機器學習和自然語言處理作業。</span><span class="sxs-lookup"><span data-stu-id="5ff12-169">Examples include machine learning and natural language processing jobs.</span></span>  
* <span data-ttu-id="5ff12-170">**記憶體密集作業**</span><span class="sxs-lookup"><span data-stu-id="5ff12-170">**Memory intensive.**</span></span>  <span data-ttu-id="5ff12-171">這些作業會使用大量記憶體。</span><span class="sxs-lookup"><span data-stu-id="5ff12-171">These jobs use lots of memory.</span></span>  <span data-ttu-id="5ff12-172">範例包括 PageRank 和即時分析作業。</span><span class="sxs-lookup"><span data-stu-id="5ff12-172">Examples include PageRank and real-time analytics jobs.</span></span>  
* <span data-ttu-id="5ff12-173">**I/O 密集作業**</span><span class="sxs-lookup"><span data-stu-id="5ff12-173">**I/O intensive.**</span></span>  <span data-ttu-id="5ff12-174">這些作業花費大部分時間執行 I/O。</span><span class="sxs-lookup"><span data-stu-id="5ff12-174">These jobs spend most of their time doing I/O.</span></span>  <span data-ttu-id="5ff12-175">常見範例是僅執行讀取和寫入作業的複製作業。</span><span class="sxs-lookup"><span data-stu-id="5ff12-175">A common example is a copy job which does only read and write operations.</span></span>  <span data-ttu-id="5ff12-176">其他範例包括讀取大量資料時，會執行某些資料轉換的資料準備工作，然後寫入 hello 資料回復 toohello 存放區。</span><span class="sxs-lookup"><span data-stu-id="5ff12-176">Other examples include data preparation jobs that read a lot of data, performs some data transformation, and then writes hello data back toohello store.</span></span>  

<span data-ttu-id="5ff12-177">下列指導方針的 hello 是只適用 tooI/O 密集的工作。</span><span class="sxs-lookup"><span data-stu-id="5ff12-177">hello following guidance is only applicable tooI/O intensive jobs.</span></span>

### <a name="general-considerations-for-an-hdinsight-cluster"></a><span data-ttu-id="5ff12-178">HDInsight 叢集的一般考量</span><span class="sxs-lookup"><span data-stu-id="5ff12-178">General Considerations for an HDInsight cluster</span></span>

* <span data-ttu-id="5ff12-179">**HDInsight 版本**</span><span class="sxs-lookup"><span data-stu-id="5ff12-179">**HDInsight versions.**</span></span> <span data-ttu-id="5ff12-180">為了達到最佳效能，使用 HDInsight hello 最新版本。</span><span class="sxs-lookup"><span data-stu-id="5ff12-180">For best performance, use hello latest release of HDInsight.</span></span>
* <span data-ttu-id="5ff12-181">**區域**</span><span class="sxs-lookup"><span data-stu-id="5ff12-181">**Regions.**</span></span> <span data-ttu-id="5ff12-182">Hello 資料湖存放區置於 hello 與 hello HDInsight 叢集相同的區域。</span><span class="sxs-lookup"><span data-stu-id="5ff12-182">Place hello Data Lake Store in hello same region as hello HDInsight cluster.</span></span>  

<span data-ttu-id="5ff12-183">HDInsight 叢集是由兩個前端節點和一些背景工作角色節點所組成。</span><span class="sxs-lookup"><span data-stu-id="5ff12-183">An HDInsight cluster is composed of two head nodes and some worker nodes.</span></span> <span data-ttu-id="5ff12-184">每個背景工作節點提供特定數目的核心和記憶體，由 hello VM 類型所決定。</span><span class="sxs-lookup"><span data-stu-id="5ff12-184">Each worker node provides a specific number of cores and memory, which is determined by hello VM-type.</span></span>  <span data-ttu-id="5ff12-185">執行作業，YARN 時配置 hello 可用的記憶體及核心 toocreate 容器的 hello 資源交涉器。</span><span class="sxs-lookup"><span data-stu-id="5ff12-185">When running a job, YARN is hello resource negotiator that allocates hello available memory and cores toocreate containers.</span></span>  <span data-ttu-id="5ff12-186">每個容器執行 hello 工作所需的 toocomplete hello 作業。</span><span class="sxs-lookup"><span data-stu-id="5ff12-186">Each container runs hello tasks needed toocomplete hello job.</span></span>  <span data-ttu-id="5ff12-187">容器快速地執行平行 tooprocess 工作中。</span><span class="sxs-lookup"><span data-stu-id="5ff12-187">Containers run in parallel tooprocess tasks quickly.</span></span> <span data-ttu-id="5ff12-188">因此，盡可能平行執行最多容器可提升效能。</span><span class="sxs-lookup"><span data-stu-id="5ff12-188">Therefore, performance is improved by running as many parallel containers as possible.</span></span>

<span data-ttu-id="5ff12-189">有三個層級可以是微調的 tooincrease 的 HDInsight 叢集內 hello 數目的容器，並使用所有可用的輸送量。</span><span class="sxs-lookup"><span data-stu-id="5ff12-189">There are three layers within an HDInsight cluster that can be tuned tooincrease hello number of containers and use all available throughput.</span></span>  

* <span data-ttu-id="5ff12-190">**實體層**</span><span class="sxs-lookup"><span data-stu-id="5ff12-190">**Physical layer**</span></span>
* <span data-ttu-id="5ff12-191">**YARN 層**</span><span class="sxs-lookup"><span data-stu-id="5ff12-191">**YARN layer**</span></span>
* <span data-ttu-id="5ff12-192">**工作負載層**</span><span class="sxs-lookup"><span data-stu-id="5ff12-192">**Workload layer**</span></span>

### <a name="physical-layer"></a><span data-ttu-id="5ff12-193">實體層</span><span class="sxs-lookup"><span data-stu-id="5ff12-193">Physical Layer</span></span>

<span data-ttu-id="5ff12-194">**執行具有更多節點和/或較大大小 VM 的叢集。**</span><span class="sxs-lookup"><span data-stu-id="5ff12-194">**Run cluster with more nodes and/or larger sized VMs.**</span></span>  <span data-ttu-id="5ff12-195">較大的叢集可讓您 toorun 更多的 YARN 容器 hello 圖所示。</span><span class="sxs-lookup"><span data-stu-id="5ff12-195">A larger cluster will enable you toorun more YARN containers as shown in hello picture below.</span></span>

![Data Lake Store 效能](./media/data-lake-store-performance-tuning-guidance/VM.png)

<span data-ttu-id="5ff12-197">**使用具有較大網路頻寬的 VM。**</span><span class="sxs-lookup"><span data-stu-id="5ff12-197">**Use VMs with more network bandwidth.**</span></span>  <span data-ttu-id="5ff12-198">hello 的網路頻寬量可能是瓶頸，如果沒有 Data Lake Store 輸送量比網路頻寬比較少。</span><span class="sxs-lookup"><span data-stu-id="5ff12-198">hello amount of network bandwidth can be a bottleneck if there is less network bandwidth than Data Lake Store throughput.</span></span>  <span data-ttu-id="5ff12-199">不同 VM 會有不同的網路頻寬大小。</span><span class="sxs-lookup"><span data-stu-id="5ff12-199">Different VMs will have varying network bandwidth sizes.</span></span>  <span data-ttu-id="5ff12-200">選擇具有 hello 最大可能的網路頻寬的 VM 類型。</span><span class="sxs-lookup"><span data-stu-id="5ff12-200">Choose a VM-type that has hello largest possible network bandwidth.</span></span>

### <a name="yarn-layer"></a><span data-ttu-id="5ff12-201">YARN 層</span><span class="sxs-lookup"><span data-stu-id="5ff12-201">YARN Layer</span></span>

<span data-ttu-id="5ff12-202">**使用較小的 YARN 容器。**</span><span class="sxs-lookup"><span data-stu-id="5ff12-202">**Use smaller YARN containers.**</span></span>  <span data-ttu-id="5ff12-203">多個容器以 hello 減少每個 YARN 容器 toocreate hello 大小相同的資源數量。</span><span class="sxs-lookup"><span data-stu-id="5ff12-203">Reduce hello size of each YARN container toocreate more containers with hello same amount of resources.</span></span>

![Data Lake Store 效能](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

<span data-ttu-id="5ff12-205">根據您的工作負載，一定有需要的最小 YARN 容器大小。</span><span class="sxs-lookup"><span data-stu-id="5ff12-205">Depending on your workload, there will always be a minimum YARN container size that is needed.</span></span> <span data-ttu-id="5ff12-206">如果您挑選的容器太小，您的作業會遇到記憶體不足的問題。</span><span class="sxs-lookup"><span data-stu-id="5ff12-206">If you pick too small a container, your jobs will run into out-of-memory issues.</span></span> <span data-ttu-id="5ff12-207">通常 YARN 容器應該不小於 1GB。</span><span class="sxs-lookup"><span data-stu-id="5ff12-207">Typically YARN containers should be no smaller than 1GB.</span></span> <span data-ttu-id="5ff12-208">它是一般 toosee 3 GB YARN 容器。</span><span class="sxs-lookup"><span data-stu-id="5ff12-208">It’s common toosee 3GB YARN containers.</span></span> <span data-ttu-id="5ff12-209">針對某些工作負載，您可能需要較大的 YARN 容器。</span><span class="sxs-lookup"><span data-stu-id="5ff12-209">For some workloads, you may need larger YARN containers.</span></span>  

<span data-ttu-id="5ff12-210">**增加每個 YARN 容器的核心。**</span><span class="sxs-lookup"><span data-stu-id="5ff12-210">**Increase cores per YARN container.**</span></span>  <span data-ttu-id="5ff12-211">增加 hello 配置 tooeach 容器 tooincrease hello 數目在每個容器中執行的平行工作的核心數目。</span><span class="sxs-lookup"><span data-stu-id="5ff12-211">Increase hello number of cores allocated tooeach container tooincrease hello number of parallel tasks that run in each container.</span></span>  <span data-ttu-id="5ff12-212">這適用於類似 Spark 的應用程式，它會在每個容器執行多項工作。</span><span class="sxs-lookup"><span data-stu-id="5ff12-212">This works for applications like Spark which run multiple tasks per container.</span></span>  <span data-ttu-id="5ff12-213">應用程式，像是 hive 控制檔的執行單一執行緒的每個容器，它提供更好的 toohave 多個容器，而不是每個容器的更多核心。</span><span class="sxs-lookup"><span data-stu-id="5ff12-213">For applications like Hive which run a single thread in each container, it is better toohave more containers rather than more cores per container.</span></span>   

### <a name="workload-layer"></a><span data-ttu-id="5ff12-214">工作負載層</span><span class="sxs-lookup"><span data-stu-id="5ff12-214">Workload Layer</span></span>

<span data-ttu-id="5ff12-215">**使用所有可用的容器。**</span><span class="sxs-lookup"><span data-stu-id="5ff12-215">**Use all available containers.**</span></span>  <span data-ttu-id="5ff12-216">等於或大於 hello 數目可用的容器，以便利用所有資源，設定工作 toobe hello 號碼。</span><span class="sxs-lookup"><span data-stu-id="5ff12-216">Set hello number of tasks toobe equal or larger than hello number of available containers so that all resources are utilized.</span></span>

![Data Lake Store 效能](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

<span data-ttu-id="5ff12-218">**失敗的工作成本很高。**</span><span class="sxs-lookup"><span data-stu-id="5ff12-218">**Failed tasks are costly.**</span></span> <span data-ttu-id="5ff12-219">如果每個工作有大量的資料 tooprocess，工作失敗導致昂貴的重試。</span><span class="sxs-lookup"><span data-stu-id="5ff12-219">If each task has a large amount of data tooprocess, then failure of a task results in an expensive retry.</span></span>  <span data-ttu-id="5ff12-220">因此，它是較佳的 toocreate 更多的工作，其中每個處理少量資料。</span><span class="sxs-lookup"><span data-stu-id="5ff12-220">Therefore, it is better toocreate more tasks, each of which processes a small amount of data.</span></span>

<span data-ttu-id="5ff12-221">加法 toohello 的一般指導方針上述，在每個應用程式會有不同的參數使用 tootune 該特定應用程式。</span><span class="sxs-lookup"><span data-stu-id="5ff12-221">In addition toohello general guidelines above, each application has different parameters available tootune for that specific application.</span></span> <span data-ttu-id="5ff12-222">hello 下表列出一些 hello 參數和連結 tooget 入門效能調整每個應用程式。</span><span class="sxs-lookup"><span data-stu-id="5ff12-222">hello table below lists some of hello parameters and links tooget started with performance tuning for each application.</span></span>

| <span data-ttu-id="5ff12-223">工作負載</span><span class="sxs-lookup"><span data-stu-id="5ff12-223">Workload</span></span>               | <span data-ttu-id="5ff12-224">參數 tooset 工作</span><span class="sxs-lookup"><span data-stu-id="5ff12-224">Parameter tooset tasks</span></span>                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [<span data-ttu-id="5ff12-225">HDInsight 上的 Spark</span><span class="sxs-lookup"><span data-stu-id="5ff12-225">Spark on HDInisight</span></span>](data-lake-store-performance-tuning-spark.md)       | <ul><li><span data-ttu-id="5ff12-226">Num-executors</span><span class="sxs-lookup"><span data-stu-id="5ff12-226">Num-executors</span></span></li><li><span data-ttu-id="5ff12-227">Executor-memory</span><span class="sxs-lookup"><span data-stu-id="5ff12-227">Executor-memory</span></span></li><li><span data-ttu-id="5ff12-228">Executor-cores</span><span class="sxs-lookup"><span data-stu-id="5ff12-228">Executor-cores</span></span></li></ul> |
| [<span data-ttu-id="5ff12-229">Hive on HDInsight</span><span class="sxs-lookup"><span data-stu-id="5ff12-229">Hive on HDInsight</span></span>](data-lake-store-performance-tuning-hive.md)    | <ul><li><span data-ttu-id="5ff12-230">hive.tez.container.size</span><span class="sxs-lookup"><span data-stu-id="5ff12-230">hive.tez.container.size</span></span></li></ul>         |
| [<span data-ttu-id="5ff12-231">MapReduce on HDInsight</span><span class="sxs-lookup"><span data-stu-id="5ff12-231">MapReduce on HDInsight</span></span>](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li><span data-ttu-id="5ff12-232">Mapreduce.map.memory</span><span class="sxs-lookup"><span data-stu-id="5ff12-232">Mapreduce.map.memory</span></span></li><li><span data-ttu-id="5ff12-233">Mapreduce.job.maps</span><span class="sxs-lookup"><span data-stu-id="5ff12-233">Mapreduce.job.maps</span></span></li><li><span data-ttu-id="5ff12-234">Mapreduce.reduce.memory</span><span class="sxs-lookup"><span data-stu-id="5ff12-234">Mapreduce.reduce.memory</span></span></li><li><span data-ttu-id="5ff12-235">Mapreduce.job.reduces</span><span class="sxs-lookup"><span data-stu-id="5ff12-235">Mapreduce.job.reduces</span></span></li></ul> |
| [<span data-ttu-id="5ff12-236">Storm on HDInsight</span><span class="sxs-lookup"><span data-stu-id="5ff12-236">Storm on HDInsight</span></span>](data-lake-store-performance-tuning-storm.md)| <ul><li><span data-ttu-id="5ff12-237">背景工作處理序數目</span><span class="sxs-lookup"><span data-stu-id="5ff12-237">Number of worker processes</span></span></li><li><span data-ttu-id="5ff12-238">Spout 執行程式執行個體數目</span><span class="sxs-lookup"><span data-stu-id="5ff12-238">Number of spout executor instances</span></span></li><li><span data-ttu-id="5ff12-239">Bolt 執行程式執行個體數目</span><span class="sxs-lookup"><span data-stu-id="5ff12-239">Number of bolt executor instances</span></span> </li><li><span data-ttu-id="5ff12-240">Spout 工作數目</span><span class="sxs-lookup"><span data-stu-id="5ff12-240">Number of spout tasks</span></span></li><li><span data-ttu-id="5ff12-241">Bolt 工作數目</span><span class="sxs-lookup"><span data-stu-id="5ff12-241">Number of bolt tasks</span></span></li></ul>|

## <a name="see-also"></a><span data-ttu-id="5ff12-242">另請參閱</span><span class="sxs-lookup"><span data-stu-id="5ff12-242">See also</span></span>
* [<span data-ttu-id="5ff12-243">Azure Data Lake Store 概觀</span><span class="sxs-lookup"><span data-stu-id="5ff12-243">Overview of Azure Data Lake Store</span></span>](data-lake-store-overview.md)
* [<span data-ttu-id="5ff12-244">開始使用 Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="5ff12-244">Get Started with Azure Data Lake Analytics</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
