---
title: "什麼是 HDInsight、Hadoop 技術堆疊和叢集？ - Azure | Microsoft Docs"
description: "HDInsight 和 Hadoop 技術堆疊和元件簡介，包括用於巨量資料分析的 Spark、Kafka、Hive、HBase。"
keywords: "azure hadoop, hadoop azure, hadoop 簡介, hadoop 簡介, hadoop 技術堆疊, hadoop 簡介, hadoop 簡介, 什麼是 hadoop 叢集, 什麼是 hadoop 叢集, 什麼是 hadoop"
services: hdinsight
documentationcenter: 
author: cjgronlund
manager: jhubbard
editor: cgronlun
ms.assetid: e56a396a-1b39-43e0-b543-f2dee5b8dd3a
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.devlang: na
ms.topic: get-started-article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/20/2017
ms.author: cgronlun
ms.openlocfilehash: b413b6f1a6c73251dfdbe6bf9d23cdfa6510839a
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/03/2017
---
# <a name="introduction-to-azure-hdinsight-the-hadoop-technology-stack-and-hadoop-clusters"></a><span data-ttu-id="203f1-105">Azure HDInsight、Hadoop 技術堆疊和 Hadoop 叢集簡介</span><span class="sxs-lookup"><span data-stu-id="203f1-105">Introduction to Azure HDInsight, the Hadoop technology stack, and Hadoop clusters</span></span>
 <span data-ttu-id="203f1-106">本文提供 Azure HDInsight (Hadoop 技術堆疊的雲端發佈) 的簡介。</span><span class="sxs-lookup"><span data-stu-id="203f1-106">This article provides an introduction to Azure HDInsight, a cloud distribution of the Hadoop technology stack.</span></span> <span data-ttu-id="203f1-107">它也涵蓋了 Hadoop 叢集的定義及其使用時機。</span><span class="sxs-lookup"><span data-stu-id="203f1-107">It also covers what a Hadoop cluster is and when you would use it.</span></span> 

## <a name="what-is-hdinsight-and-the-hadoop-technology-stack"></a><span data-ttu-id="203f1-108">什麼是 HDInsight 和 Hadoop 技術堆疊？</span><span class="sxs-lookup"><span data-stu-id="203f1-108">What is HDInsight and the Hadoop technology stack?</span></span> 
<span data-ttu-id="203f1-109">Azure HDInsight 是 [Hortonworks Data Platform (HDP)](https://hortonworks.com/products/data-center/hdp/) 中 Hadoop 元件的雲端發佈。</span><span class="sxs-lookup"><span data-stu-id="203f1-109">Azure HDInsight is a cloud distribution of the Hadoop components from the [Hortonworks Data Platform (HDP)](https://hortonworks.com/products/data-center/hdp/).</span></span> <span data-ttu-id="203f1-110">[Apache Hadoop](http://hadoop.apache.org/) 是原始的開放原始碼建構，用於分散式處理和分析電腦叢集上的巨量資料集。</span><span class="sxs-lookup"><span data-stu-id="203f1-110">[Apache Hadoop](http://hadoop.apache.org/) was the original open-source framework for distributed processing and analysis of big data sets on clusters of computers.</span></span> 


<span data-ttu-id="203f1-111">Hadoop 技術堆疊包含相關的軟體和公用程式，其中包括 Apache Hive、HBase、Spark、Kafka 和其他許多軟體。</span><span class="sxs-lookup"><span data-stu-id="203f1-111">The Hadoop technology stack includes related software and utilities, including Apache Hive, HBase, Spark, Kafka, and many others.</span></span> <span data-ttu-id="203f1-112">若要查看 HDInsight 上可用的 Hadoop 技術堆疊元件，請參閱 [HDInsight 可用的元件和版本][component-versioning]。</span><span class="sxs-lookup"><span data-stu-id="203f1-112">To see available Hadoop technology stack components on HDInsight, see [Components and versions available with HDInsight][component-versioning].</span></span> <span data-ttu-id="203f1-113">若要深入了解 HDInsight 中的 Hadoop，請參閱 [HDInsight 的 Azure 功能頁面](https://azure.microsoft.com/services/hdinsight/)。</span><span class="sxs-lookup"><span data-stu-id="203f1-113">To read more about Hadoop in HDInsight, see the [Azure features page for HDInsight](https://azure.microsoft.com/services/hdinsight/).</span></span>

## <a name="what-is-a-hadoop-cluster-and-when-do-you-use-it"></a><span data-ttu-id="203f1-114">什麼是 Hadoop 叢集，以及何時使用它？</span><span class="sxs-lookup"><span data-stu-id="203f1-114">What is a Hadoop cluster, and when do you use it?</span></span>
<span data-ttu-id="203f1-115">*Hadoop* 也是具有下列各項的叢集類型：</span><span class="sxs-lookup"><span data-stu-id="203f1-115">*Hadoop* is also a cluster type that has:</span></span>

* <span data-ttu-id="203f1-116">用於作業排程和資源管理的 YARN</span><span class="sxs-lookup"><span data-stu-id="203f1-116">YARN for job scheduling and resource management</span></span>
* <span data-ttu-id="203f1-117">用於平行處理的 MapReduce</span><span class="sxs-lookup"><span data-stu-id="203f1-117">MapReduce for parallel processing</span></span>
* <span data-ttu-id="203f1-118">Hadoop 分散式檔案系統 (HDFS)</span><span class="sxs-lookup"><span data-stu-id="203f1-118">The Hadoop distributed file system (HDFS)</span></span>
  
<span data-ttu-id="203f1-119">Hadoop 叢集最常用於已儲存資料的批次處理。</span><span class="sxs-lookup"><span data-stu-id="203f1-119">Hadoop clusters are most often used for batch processing of stored data.</span></span> <span data-ttu-id="203f1-120">HDInsight 中的其他叢集類型具有其他功能：Spark 因為其更快速的記憶體內部處理而日益普及。</span><span class="sxs-lookup"><span data-stu-id="203f1-120">Other kinds of clusters in HDInsight have additional capabilities: Spark has grown in popularity because of its faster, in-memory processing.</span></span> <span data-ttu-id="203f1-121">如需詳細資訊，請參閱 [HDInsight 上的叢集類型](#overview)。</span><span class="sxs-lookup"><span data-stu-id="203f1-121">See [Cluster types on HDInsight](#overview) for details.</span></span>

## <a name="what-is-big-data"></a><span data-ttu-id="203f1-122">什麼是巨量資料？</span><span class="sxs-lookup"><span data-stu-id="203f1-122">What is big data?</span></span>
<span data-ttu-id="203f1-123">巨量資料是指任何極為龐大的數位資訊，例如︰</span><span class="sxs-lookup"><span data-stu-id="203f1-123">Big data describes any large body of digital information, such as:</span></span>

* <span data-ttu-id="203f1-124">工業設備的感應器資料</span><span class="sxs-lookup"><span data-stu-id="203f1-124">Sensor data from industrial equipment</span></span>
* <span data-ttu-id="203f1-125">從網站收集的客戶活動</span><span class="sxs-lookup"><span data-stu-id="203f1-125">Customer activity collected from a website</span></span>
* <span data-ttu-id="203f1-126">Twitter 新聞摘要</span><span class="sxs-lookup"><span data-stu-id="203f1-126">A Twitter newsfeed</span></span>

<span data-ttu-id="203f1-127">巨量資料的收集量快速增加，收集速度加快，收集格式也愈來愈多。</span><span class="sxs-lookup"><span data-stu-id="203f1-127">Big data is being collected in escalating volumes, at higher velocities, and in a greater variety of formats.</span></span> <span data-ttu-id="203f1-128">它可以屬於過去 (亦即已儲存) 或即時 (亦即從來源串流而來)。</span><span class="sxs-lookup"><span data-stu-id="203f1-128">It can be historical (meaning stored) or real time (meaning streamed from the source).</span></span> 

## <span data-ttu-id="203f1-129"><a name="overview"></a>HDInsight 中的叢集類型</span><span class="sxs-lookup"><span data-stu-id="203f1-129"><a name="overview"></a>Cluster types in HDInsight</span></span>
<span data-ttu-id="203f1-130">HDInsight 包含特定叢集類型和叢集自訂功能，例如新增元件、公用程式及語言。</span><span class="sxs-lookup"><span data-stu-id="203f1-130">HDInsight includes specific cluster types and cluster customization capabilities, such as adding components, utilities, and languages.</span></span>

### <a name="spark-kafka-interactive-hive-hbase-customized-and-other-cluster-types"></a><span data-ttu-id="203f1-131">Spark、Kafka、Interactive Hive、HBase、自訂和其他叢集類型</span><span class="sxs-lookup"><span data-stu-id="203f1-131">Spark, Kafka, Interactive Hive, HBase, customized, and other cluster types</span></span>
<span data-ttu-id="203f1-132">HDInsight 提供下列叢集類型：</span><span class="sxs-lookup"><span data-stu-id="203f1-132">HDInsight offers the following cluster types:</span></span>

* <span data-ttu-id="203f1-133">**[Apache Hadoop](https://wiki.apache.org/hadoop)**︰使用 [HDFS](#hdfs)、[YARN](#yarn) 資源管理，以及簡單的 [MapReduce](#mapreduce) 程式設計模型來平行處理和分析批次資料。</span><span class="sxs-lookup"><span data-stu-id="203f1-133">**[Apache Hadoop](https://wiki.apache.org/hadoop)**: Uses [HDFS](#hdfs), [YARN](#yarn) resource management, and a simple [MapReduce](#mapreduce) programming model to process and analyze batch data in parallel.</span></span>
* <span data-ttu-id="203f1-134">**[Apache Spark](http://spark.apache.org/)**：一種平行處理架構，可支援記憶體內的處理，大幅提升巨量資料分析應用程式、SQL 之 Spark 工作、串流資料與機器學習的效能。</span><span class="sxs-lookup"><span data-stu-id="203f1-134">**[Apache Spark](http://spark.apache.org/)**: A parallel processing framework that supports in-memory processing to boost the performance of big-data analysis applications, Spark works for SQL, streaming data, and machine learning.</span></span> <span data-ttu-id="203f1-135">請參閱[什麼是 HDInsight 中的 Apache Spark？](hdinsight-apache-spark-overview.md)</span><span class="sxs-lookup"><span data-stu-id="203f1-135">See [What is Apache Spark in HDInsight?](hdinsight-apache-spark-overview.md)</span></span>
* <span data-ttu-id="203f1-136">**[Apache HBase](http://hbase.apache.org/)**：建置於 Hadoop 上的 NoSQL 資料庫，可針對大量非結構化及半結構化資料 (可能是數十億的資料列乘以數百萬的資料行)，提供隨機存取功能和強大一致性。</span><span class="sxs-lookup"><span data-stu-id="203f1-136">**[Apache HBase](http://hbase.apache.org/)**: A NoSQL database built on Hadoop that provides random access and strong consistency for large amounts of unstructured and semi-structured data - potentially billions of rows times millions of columns.</span></span> <span data-ttu-id="203f1-137">請參閱[什麼是 HDInsight 上的 HBase？](hdinsight-hbase-overview.md)</span><span class="sxs-lookup"><span data-stu-id="203f1-137">See [What is HBase on HDInsight?](hdinsight-hbase-overview.md)</span></span>
* <span data-ttu-id="203f1-138">**[Microsoft R 伺服器](https://msdn.microsoft.com/microsoft-r/rserver)**︰可用來裝載和管理並行、分散式 R 程序的伺服器。</span><span class="sxs-lookup"><span data-stu-id="203f1-138">**[Microsoft R Server](https://msdn.microsoft.com/microsoft-r/rserver)**: A server for hosting and managing parallel, distributed R processes.</span></span> <span data-ttu-id="203f1-139">這項新功能可讓資料科學家、統計學家以及 R 程式設計人員隨其所需存取 HDInsight 上可調整大小的分散式分析方法。</span><span class="sxs-lookup"><span data-stu-id="203f1-139">It provides data scientists, statisticians, and R programmers with on-demand access to scalable, distributed methods of analytics on HDInsight.</span></span> <span data-ttu-id="203f1-140">請參閱 [HDInsight 中的 R 伺服器概觀](hdinsight-hadoop-r-server-overview.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-140">See [Overview of R Server on HDInsight](hdinsight-hadoop-r-server-overview.md).</span></span>
* <span data-ttu-id="203f1-141">**[Apache Storm](https://storm.incubator.apache.org/)**：分散式、即時的運算系統，可快速處理大型的資料串流。</span><span class="sxs-lookup"><span data-stu-id="203f1-141">**[Apache Storm](https://storm.incubator.apache.org/)**: A distributed, real-time computation system for processing large streams of data fast.</span></span> <span data-ttu-id="203f1-142">Storm 以受管理叢集的形式在 HDInsight 中提供。</span><span class="sxs-lookup"><span data-stu-id="203f1-142">Storm is offered as a managed cluster in HDInsight.</span></span> <span data-ttu-id="203f1-143">請參閱＜ [使用 Storm 和 Hadoop 來分析即時感應器資料](hdinsight-storm-sensor-data-analysis.md)＞。</span><span class="sxs-lookup"><span data-stu-id="203f1-143">See [Analyze real-time sensor data using Storm and Hadoop](hdinsight-storm-sensor-data-analysis.md).</span></span>
* <span data-ttu-id="203f1-144">**[Apache 互動式 Hive 預覽 (也稱為︰Live Long and Process)](https://cwiki.apache.org/confluence/display/Hive/LLAP)**︰更快速之互動式 Hive 查詢的記憶體內快取。</span><span class="sxs-lookup"><span data-stu-id="203f1-144">**[Apache Interactive Hive preview (AKA: Live Long and Process)](https://cwiki.apache.org/confluence/display/Hive/LLAP)**: In-memory caching for interactive and faster Hive queries.</span></span> <span data-ttu-id="203f1-145">請參閱[在 HDInsight 中使用互動式 Hive](hdinsight-hadoop-use-interactive-hive.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-145">See [Use Interactive Hive in HDInsight](hdinsight-hadoop-use-interactive-hive.md).</span></span>
* <span data-ttu-id="203f1-146">**[Apache Kafka](https://kafka.apache.org/)**︰用來建立串流資料管線和應用程式的開放原始碼平台。</span><span class="sxs-lookup"><span data-stu-id="203f1-146">**[Apache Kafka](https://kafka.apache.org/)**: An open-source platform used for building streaming data pipelines and applications.</span></span> <span data-ttu-id="203f1-147">Kafka 也提供訊息佇列功能，可讓您發佈和訂閱資料串流。</span><span class="sxs-lookup"><span data-stu-id="203f1-147">Kafka also provides message-queue functionality that allows you to publish and subscribe to data streams.</span></span> <span data-ttu-id="203f1-148">請參閱 [HDInsight 上的 Apache Kafka 簡介](hdinsight-apache-kafka-introduction.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-148">See [Introduction to Apache Kafka on HDInsight](hdinsight-apache-kafka-introduction.md).</span></span>

<span data-ttu-id="203f1-149">您也可以使用下列方法來設定叢集：</span><span class="sxs-lookup"><span data-stu-id="203f1-149">You can also configure clusters using the following methods:</span></span>
* <span data-ttu-id="203f1-150">**[已加入網域的叢集預覽](hdinsight-domain-joined-introduction.md)**︰Active Directory 網域中加入的叢集，如此您可以控制存取並提供對資料的管理。</span><span class="sxs-lookup"><span data-stu-id="203f1-150">**[Domain-joined clusters preview](hdinsight-domain-joined-introduction.md)**: A cluster joined to an Active Directory domain so that you can control access and provide governance for data.</span></span>
* <span data-ttu-id="203f1-151">**[具指令碼動作的自訂叢集](hdinsight-hadoop-customize-cluster-linux.md)**：具指令碼的叢集，該指令碼於佈建期間執行，並安裝其他元件。</span><span class="sxs-lookup"><span data-stu-id="203f1-151">**[Custom clusters with script actions](hdinsight-hadoop-customize-cluster-linux.md)**: Clusters with scripts that run during provisioning and install additional components.</span></span>

### <a name="example-cluster-customization-scripts"></a><span data-ttu-id="203f1-152">範例叢集自訂指令碼</span><span class="sxs-lookup"><span data-stu-id="203f1-152">Example cluster customization scripts</span></span>
<span data-ttu-id="203f1-153">指令碼動作是在叢集佈建期間在 Linux 上執行的 Bash 指令碼，而且可用來在叢集上安裝其他元件。</span><span class="sxs-lookup"><span data-stu-id="203f1-153">Script actions are Bash scripts on Linux that run during cluster provisioning, and that can be used to install additional components on the cluster.</span></span> 

<span data-ttu-id="203f1-154">下列指令碼範例由 HDInsight 小組提供：</span><span class="sxs-lookup"><span data-stu-id="203f1-154">The following example scripts are provided by the HDInsight team:</span></span>

* <span data-ttu-id="203f1-155">**[Hue](hdinsight-hadoop-hue-linux.md)**：一組 Web 應用程式，可用來與叢集互動。</span><span class="sxs-lookup"><span data-stu-id="203f1-155">**[Hue](hdinsight-hadoop-hue-linux.md)**: A set of web applications used to interact with a cluster.</span></span> <span data-ttu-id="203f1-156">僅限於 Linux 叢集。</span><span class="sxs-lookup"><span data-stu-id="203f1-156">Linux clusters only.</span></span>
* <span data-ttu-id="203f1-157">**[Giraph](hdinsight-hadoop-giraph-install-linux.md)**：物品與人員間之模型關聯性的圖形處理。</span><span class="sxs-lookup"><span data-stu-id="203f1-157">**[Giraph](hdinsight-hadoop-giraph-install-linux.md)**: Graph processing to model relationships between things or people.</span></span>
* <span data-ttu-id="203f1-158">**[Solr](hdinsight-hadoop-solr-install-linux.md)**：一種企業級搜尋平台，可對資料進行全文檢索搜尋。</span><span class="sxs-lookup"><span data-stu-id="203f1-158">**[Solr](hdinsight-hadoop-solr-install-linux.md)**: An enterprise-scale search platform that allows full-text search on data.</span></span>

<span data-ttu-id="203f1-159">如需開發您自己的指令碼動作相關資訊，請參閱 [使用 HDInsight 開發指令碼動作](hdinsight-hadoop-script-actions-linux.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-159">For information on developing your own Script Actions, see [Script Action development with HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

## <a name="components-and-utilities-on-hdinsight-clusters"></a><span data-ttu-id="203f1-160">HDInsight 叢集上的元件和公用程式</span><span class="sxs-lookup"><span data-stu-id="203f1-160">Components and utilities on HDInsight clusters</span></span>
<span data-ttu-id="203f1-161">HDInsight 叢集包含下列元件和公用程式：</span><span class="sxs-lookup"><span data-stu-id="203f1-161">The following components and utilities are included on HDInsight clusters:</span></span>

* <span data-ttu-id="203f1-162">**[Ambari](#ambari)**：叢集佈建、管理、監視和公用程式。</span><span class="sxs-lookup"><span data-stu-id="203f1-162">**[Ambari](#ambari)**: Cluster provisioning, management, monitoring, and utilities.</span></span>
* <span data-ttu-id="203f1-163">**[Avro](#avro)** (Microsoft .NET Library for Avro)：Microsoft.NET 環境的資料序列化。</span><span class="sxs-lookup"><span data-stu-id="203f1-163">**[Avro](#avro)** (Microsoft .NET Library for Avro): Data serialization for the Microsoft .NET environment.</span></span> 
* <span data-ttu-id="203f1-164">**[Hive & HCatalog](#hive)**：類似 SQL 的查詢，以及資料表和儲存體管理層。</span><span class="sxs-lookup"><span data-stu-id="203f1-164">**[Hive & HCatalog](#hive)**: SQL-like querying, and a table and storage management layer.</span></span>
* <span data-ttu-id="203f1-165">**[Mahout](#mahout)**：適用於可調整的機器學習應用程式。</span><span class="sxs-lookup"><span data-stu-id="203f1-165">**[Mahout](#mahout)**: For scalable machine learning applications.</span></span>
* <span data-ttu-id="203f1-166">**[MapReduce](#mapreduce)**：Hadoop 分散式處理和資源管理的傳統架構。</span><span class="sxs-lookup"><span data-stu-id="203f1-166">**[MapReduce](#mapreduce)**: Legacy framework for Hadoop distributed processing and resource management.</span></span> <span data-ttu-id="203f1-167">請參閱 [YARN](#yarn)。</span><span class="sxs-lookup"><span data-stu-id="203f1-167">See [YARN](#yarn).</span></span>
* <span data-ttu-id="203f1-168">**[Oozie](#oozie)**：工作流程管理。</span><span class="sxs-lookup"><span data-stu-id="203f1-168">**[Oozie](#oozie)**: Workflow management.</span></span>
* <span data-ttu-id="203f1-169">**[Phoenix](#phoenix)**：對 HBase 的關聯式資料庫層。</span><span class="sxs-lookup"><span data-stu-id="203f1-169">**[Phoenix](#phoenix)**: Relational database layer over HBase.</span></span>
* <span data-ttu-id="203f1-170">**[Pig](#pig)**：簡單撰寫 MapReduce 轉換的指令碼。</span><span class="sxs-lookup"><span data-stu-id="203f1-170">**[Pig](#pig)**: Simpler scripting for MapReduce transformations.</span></span>
* <span data-ttu-id="203f1-171">**[Sqoop](#sqoop)**：資料匯入和匯出。</span><span class="sxs-lookup"><span data-stu-id="203f1-171">**[Sqoop](#sqoop)**: Data import and export.</span></span>
* <span data-ttu-id="203f1-172">**[Tez](#tez)**：允許資料密集程序有效率地大規模執行。</span><span class="sxs-lookup"><span data-stu-id="203f1-172">**[Tez](#tez)**: Allows data-intensive processes to run efficiently at scale.</span></span>
* <span data-ttu-id="203f1-173">**[YARN](#yarn)**：屬於Hadoop 核心程式庫一部分的資源管理。</span><span class="sxs-lookup"><span data-stu-id="203f1-173">**[YARN](#yarn)**: Resource management that is part of the Hadoop core library.</span></span>
* <span data-ttu-id="203f1-174">**[ZooKeeper](#zookeeper)**：協調分散式系統中的程序。</span><span class="sxs-lookup"><span data-stu-id="203f1-174">**[ZooKeeper](#zookeeper)**: Coordination of processes in distributed systems.</span></span>

> [!NOTE]
> <span data-ttu-id="203f1-175">如需特定元件及版本的相關資訊，請參閱 [HDInsight 中的 Hadoop 元件和版本][component-versioning]</span><span class="sxs-lookup"><span data-stu-id="203f1-175">For information on the specific components and version information, see [Hadoop components and versions in HDInsight][component-versioning]</span></span>
>
>

### <span data-ttu-id="203f1-176"><a name="ambari"></a>Ambari</span><span class="sxs-lookup"><span data-stu-id="203f1-176"><a name="ambari"></a>Ambari</span></span>
<span data-ttu-id="203f1-177">Apache Ambari 可用來佈建、管理及監視 Apache Hadoop 叢集。</span><span class="sxs-lookup"><span data-stu-id="203f1-177">Apache Ambari is for provisioning, managing, and monitoring Apache Hadoop clusters.</span></span> <span data-ttu-id="203f1-178">其中包含一組直接易懂的操作員工具和健全的 API 集，可消除 Hadoop 的複雜性，並簡化叢集作業。</span><span class="sxs-lookup"><span data-stu-id="203f1-178">It includes an intuitive collection of operator tools and a robust set of APIs that hide the complexity of Hadoop, simplifying the operation of clusters.</span></span> <span data-ttu-id="203f1-179">Linux 上的 HDInsight 叢集同時提供 Ambari Web UI 和 Ambari REST API。</span><span class="sxs-lookup"><span data-stu-id="203f1-179">HDInsight clusters on Linux provide both the Ambari web UI and the Ambari REST API.</span></span> <span data-ttu-id="203f1-180">HDInsight 叢集上的 Ambari 檢視允許外掛程式 UI 功能。</span><span class="sxs-lookup"><span data-stu-id="203f1-180">Ambari Views on HDInsight clusters allow plug-in UI capabilities.</span></span>
<span data-ttu-id="203f1-181">請參閱[使用 Ambari 管理 HDInsight 叢集](hdinsight-hadoop-manage-ambari.md)和 <a target="_blank" href="https://github.com/apache/ambari/blob/trunk/ambari-server/docs/api/v1/index.md">Apache Ambari API 參考</a>。</span><span class="sxs-lookup"><span data-stu-id="203f1-181">See [Manage HDInsight clusters using Ambari](hdinsight-hadoop-manage-ambari.md) and <a target="_blank" href="https://github.com/apache/ambari/blob/trunk/ambari-server/docs/api/v1/index.md">Apache Ambari API reference</a>.</span></span>

### <span data-ttu-id="203f1-182"><a name="avro"></a>Avro (Microsoft .NET Library for Avro)</span><span class="sxs-lookup"><span data-stu-id="203f1-182"><a name="avro"></a>Avro (Microsoft .NET Library for Avro)</span></span>
<span data-ttu-id="203f1-183">Microsoft .NET Library for Avro 針對 Microsoft .NET 環境的序列化，實作 Apache Avro 壓縮二進位資料交換格式。</span><span class="sxs-lookup"><span data-stu-id="203f1-183">The Microsoft .NET Library for Avro implements the Apache Avro compact binary data interchange format for serialization for the Microsoft .NET environment.</span></span> <span data-ttu-id="203f1-184">它會定義不限語言的結構描述，以某種語言序列化的資料便可使用另一個語言讀取。</span><span class="sxs-lookup"><span data-stu-id="203f1-184">It defines a language-agnostic schema so that data serialized in one language can be read in another.</span></span> <span data-ttu-id="203f1-185">如需此格式的詳細資訊，請參閱 <a target=_"blank" href="http://avro.apache.org/docs/current/spec.html">Apache Avro 規格</a>。</span><span class="sxs-lookup"><span data-stu-id="203f1-185">Detailed information on the format can be found in the <a target=_"blank" href="http://avro.apache.org/docs/current/spec.html">Apache Avro Specification</a>.</span></span> <span data-ttu-id="203f1-186">Avro 檔案格式支援分散式 MapReduce 程式設計模型：檔案「可分割」，這表示您可以從檔案中的任何一點開始讀取特定區塊。</span><span class="sxs-lookup"><span data-stu-id="203f1-186">The format of Avro files supports the distributed MapReduce programming model: Files are “splittable”, meaning you can seek any point in a file and start reading from a particular block.</span></span> <span data-ttu-id="203f1-187">如需了解作法，請參閱[使用 Microsoft .NET Library for Avro 將資料序列化](hdinsight-dotnet-avro-serialization.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-187">To find out how, see [Serialize data with the Microsoft .NET Library for Avro](hdinsight-dotnet-avro-serialization.md).</span></span> <span data-ttu-id="203f1-188">即將提供以 Linux 為基礎的叢集支援。</span><span class="sxs-lookup"><span data-stu-id="203f1-188">Linux-based cluster support to come.</span></span>

### <span data-ttu-id="203f1-189"><a name="hdfs"></a>HDFS</span><span class="sxs-lookup"><span data-stu-id="203f1-189"><a name="hdfs"></a>HDFS</span></span>
<span data-ttu-id="203f1-190">Hadoop Distributed File System (HDFS) 是一套檔案系統，加上 YARN 和 MapReduce，成為 Hadoop 技術的核心。</span><span class="sxs-lookup"><span data-stu-id="203f1-190">Hadoop Distributed File System (HDFS) is a file system that, with YARN and MapReduce, is the core of Hadoop technology.</span></span> <span data-ttu-id="203f1-191">它是 HDInsight 上的 Hadoop 叢集的標準檔案系統。</span><span class="sxs-lookup"><span data-stu-id="203f1-191">It's the standard file system for Hadoop clusters on HDInsight.</span></span> <span data-ttu-id="203f1-192">請參閱[從 HDFS 相容儲存體查詢資料](hdinsight-hadoop-use-blob-storage.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-192">See [Query data from HDFS-compatible storage](hdinsight-hadoop-use-blob-storage.md).</span></span>

### <span data-ttu-id="203f1-193"><a name="hive"></a>Hive 和 HCatalog</span><span class="sxs-lookup"><span data-stu-id="203f1-193"><a name="hive"></a>Hive & HCatalog</span></span>
<span data-ttu-id="203f1-194"><a target="_blank" href="http://hive.apache.org/">Apache Hive</a> 是以 Hadoop 為基礎的資料倉儲軟體，可讓您使用一種稱為 HiveQL 的 SQL 式語言，以查詢和管理分散式儲存體中的大型資料集。</span><span class="sxs-lookup"><span data-stu-id="203f1-194"><a target="_blank" href="http://hive.apache.org/">Apache Hive</a> is data warehouse software built on Hadoop that allows you to query and manage large datasets in distributed storage by using a SQL-like language called HiveQL.</span></span> <span data-ttu-id="203f1-195">如同 Pig，Hive 是 MapReduce 的抽象概念，可將查詢轉譯成一系列的 MapReduce 作業。</span><span class="sxs-lookup"><span data-stu-id="203f1-195">Hive, like Pig, is an abstraction on top of MapReduce, and it translates queries into a series of MapReduce jobs.</span></span> <span data-ttu-id="203f1-196">Hive 比 Pig 更接近關聯式資料庫管理系統，而且適用於更具結構化的資料。</span><span class="sxs-lookup"><span data-stu-id="203f1-196">Hive is closer to a relational database management system than Pig, and is used with more structured data.</span></span> <span data-ttu-id="203f1-197">對於非結構化資料，Pig 是較好的選擇。</span><span class="sxs-lookup"><span data-stu-id="203f1-197">For unstructured data, Pig is the better choice.</span></span> <span data-ttu-id="203f1-198">請參閱 [在 HDInsight 上將 Hive 與 Hadoop 搭配使用](hdinsight-use-hive.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-198">See [Use Hive with Hadoop in HDInsight](hdinsight-use-hive.md).</span></span>

<span data-ttu-id="203f1-199"><a target="_blank" href="https://cwiki.apache.org/confluence/display/Hive/HCatalog/">Apache HCatalog</a> 是 Hadoop 的資料表和儲存體管理層，可為您提供資料的關聯式檢視。</span><span class="sxs-lookup"><span data-stu-id="203f1-199"><a target="_blank" href="https://cwiki.apache.org/confluence/display/Hive/HCatalog/">Apache HCatalog</a> is a table and storage management layer for Hadoop that presents you with a relational view of data.</span></span> <span data-ttu-id="203f1-200">在 HCatalog 中，您可以任何適用於 Hive SerDe (序列化程式-還原序列化程式) 的格式來讀寫和撰寫檔案。</span><span class="sxs-lookup"><span data-stu-id="203f1-200">In HCatalog, you can read and write files in any format that works for a Hive SerDe (serializer-deserializer).</span></span>

### <span data-ttu-id="203f1-201"><a name="mahout"></a>Mahout</span><span class="sxs-lookup"><span data-stu-id="203f1-201"><a name="mahout"></a>Mahout</span></span>
<span data-ttu-id="203f1-202"><a target="_blank" href="https://mahout.apache.org/">Apache Mahout</a> 是在 Hadoop 上執行的機器學習演算法程式庫。</span><span class="sxs-lookup"><span data-stu-id="203f1-202"><a target="_blank" href="https://mahout.apache.org/">Apache Mahout</a> is a library of machine learning algorithms that run on Hadoop.</span></span> <span data-ttu-id="203f1-203">機器學習應用程式採用統計學的原理，教導系統從資料中學習，根據過去的結果來研判未來的行為。</span><span class="sxs-lookup"><span data-stu-id="203f1-203">Using principles of statistics, machine learning applications teach systems to learn from data and to use past outcomes to determine future behavior.</span></span> <span data-ttu-id="203f1-204">請參閱＜ [在 Hadoop 上使用 Mahout 來產生電影推薦](hdinsight-mahout.md)＞。</span><span class="sxs-lookup"><span data-stu-id="203f1-204">See [Generate movie recommendations using Mahout on Hadoop](hdinsight-mahout.md).</span></span>

### <span data-ttu-id="203f1-205"><a name="mapreduce"></a>MapReduce</span><span class="sxs-lookup"><span data-stu-id="203f1-205"><a name="mapreduce"></a>MapReduce</span></span>
<span data-ttu-id="203f1-206">MapReduce 是供 Hadoop 撰寫應用程式來以平行方式批次處理巨量資料集的傳統軟體架構。</span><span class="sxs-lookup"><span data-stu-id="203f1-206">MapReduce is the legacy software framework for Hadoop for writing applications to batch process big data sets in parallel.</span></span> <span data-ttu-id="203f1-207">MapReduce 工作可分割大型資料集，並將資料組織成機碼值組以便於處理。</span><span class="sxs-lookup"><span data-stu-id="203f1-207">A MapReduce job splits large datasets and organizes the data into key-value pairs for processing.</span></span> <span data-ttu-id="203f1-208">MapReduce 作業會在 [YARN](#yarn) 上執行。</span><span class="sxs-lookup"><span data-stu-id="203f1-208">MapReduce jobs run on [YARN](#yarn).</span></span> <span data-ttu-id="203f1-209">請參閱 Hadoop Wiki 中的 <a target="_blank" href="http://wiki.apache.org/hadoop/MapReduce">MapReduce</a>。</span><span class="sxs-lookup"><span data-stu-id="203f1-209">See <a target="_blank" href="http://wiki.apache.org/hadoop/MapReduce">MapReduce</a> in the Hadoop Wiki.</span></span>

### <span data-ttu-id="203f1-210"><a name="oozie"></a>Oozie</span><span class="sxs-lookup"><span data-stu-id="203f1-210"><a name="oozie"></a>Oozie</span></span>
<span data-ttu-id="203f1-211"><a target="_blank" href="http://oozie.apache.org/">Apache Oozie</a> 是可管理 Hadoop 工作的工作流程協調系統。</span><span class="sxs-lookup"><span data-stu-id="203f1-211"><a target="_blank" href="http://oozie.apache.org/">Apache Oozie</a> is a workflow coordination system that manages Hadoop jobs.</span></span> <span data-ttu-id="203f1-212">它可與 Hadoop 堆疊相整合，並支援 MapReduce、Pig、Hive 和 Sqoop 的 Hadoop 工作。</span><span class="sxs-lookup"><span data-stu-id="203f1-212">It is integrated with the Hadoop stack and supports Hadoop jobs for MapReduce, Pig, Hive, and Sqoop.</span></span> <span data-ttu-id="203f1-213">它也可用來排程系統的特定工作，例如 Java 程式或 Shell 指令碼。</span><span class="sxs-lookup"><span data-stu-id="203f1-213">It can also be used to schedule jobs specific to a system, like Java programs or shell scripts.</span></span> <span data-ttu-id="203f1-214">請參閱 [搭配使用 Oozie 與 Hadoop](hdinsight-use-oozie-linux-mac.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-214">See [Use Oozie with Hadoop](hdinsight-use-oozie-linux-mac.md).</span></span>

### <span data-ttu-id="203f1-215"><a name="phoenix"></a>Phoenix</span><span class="sxs-lookup"><span data-stu-id="203f1-215"><a name="phoenix"></a>Phoenix</span></span>
<span data-ttu-id="203f1-216"><a  target="_blank" href="http://phoenix.apache.org/">Apache Phoenix</a> 是對 HBase 的關聯式資料庫層。</span><span class="sxs-lookup"><span data-stu-id="203f1-216"><a  target="_blank" href="http://phoenix.apache.org/">Apache Phoenix</a> is a relational database layer over HBase.</span></span> <span data-ttu-id="203f1-217">Phoenix 包含 JDBC 驅動程式，可讓您直接查詢和管理 SQL 資料表。</span><span class="sxs-lookup"><span data-stu-id="203f1-217">Phoenix includes a JDBC driver that allows you to query and manage SQL tables directly.</span></span> <span data-ttu-id="203f1-218">Phoenix 會將查詢和其他陳述式轉譯為原生 NoSQL API 呼叫，而不是使用 MapReduce。因此能更快速地在 NoSQL 存放區上套用。</span><span class="sxs-lookup"><span data-stu-id="203f1-218">Phoenix translates queries and other statements into native NoSQL API calls - instead of using MapReduce - thus enabling faster applications on top of NoSQL stores.</span></span> <span data-ttu-id="203f1-219">請參閱[搭配 HBase 叢集使用 Phoenix 和 SQuirreL](hdinsight-hbase-phoenix-squirrel.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-219">See [Use Apache Phoenix and SQuirreL with HBase clusters](hdinsight-hbase-phoenix-squirrel.md).</span></span>

### <span data-ttu-id="203f1-220"><a name="pig"></a>Pig</span><span class="sxs-lookup"><span data-stu-id="203f1-220"><a name="pig"></a>Pig</span></span>
<span data-ttu-id="203f1-221"><a  target="_blank" href="http://pig.apache.org/">Apache Pig</a> 是一個高階平台，可讓您在大型資料集上，使用稱為 Pig Latin 的簡單指令碼語言來執行複雜的 MapReduce 轉換。</span><span class="sxs-lookup"><span data-stu-id="203f1-221"><a  target="_blank" href="http://pig.apache.org/">Apache Pig</a> is a high-level platform that allows you to perform complex MapReduce transformations on large datasets by using a simple scripting language called Pig Latin.</span></span> <span data-ttu-id="203f1-222">Pig 會將 Pig Latin 指令碼轉換成可在 Hadoop 內執行。</span><span class="sxs-lookup"><span data-stu-id="203f1-222">Pig translates the Pig Latin scripts so they’ll run within Hadoop.</span></span> <span data-ttu-id="203f1-223">您可以建立使用者定義的函式 (UDF) 來延伸 Pig Latin。</span><span class="sxs-lookup"><span data-stu-id="203f1-223">You can create User-Defined Functions (UDFs) to extend Pig Latin.</span></span> <span data-ttu-id="203f1-224">請參閱 [搭配使用 Pig 與 Hadoop](hdinsight-use-pig.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-224">See [Use Pig with Hadoop](hdinsight-use-pig.md).</span></span>

### <span data-ttu-id="203f1-225"><a name="sqoop"></a>Sqoop</span><span class="sxs-lookup"><span data-stu-id="203f1-225"><a name="sqoop"></a>Sqoop</span></span>
<span data-ttu-id="203f1-226"><a  target="_blank" href="http://sqoop.apache.org/">Apache Sqoop</a> 是在 Hadoop 與 SQL 之類的關聯式資料庫或其他結構化資料儲存之間盡可能以最高效率傳輸大量資料的工具。</span><span class="sxs-lookup"><span data-stu-id="203f1-226"><a  target="_blank" href="http://sqoop.apache.org/">Apache Sqoop</a> is a tool that transfers bulk data between Hadoop and relational databases such as SQL, or other structured data stores, as efficiently as possible.</span></span> <span data-ttu-id="203f1-227">請參閱＜ [使用 Sqoop 與 Hadoop](hdinsight-use-sqoop.md)＞。</span><span class="sxs-lookup"><span data-stu-id="203f1-227">See [Use Sqoop with Hadoop](hdinsight-use-sqoop.md).</span></span>

### <span data-ttu-id="203f1-228"><a name="tez"></a>Tez</span><span class="sxs-lookup"><span data-stu-id="203f1-228"><a name="tez"></a>Tez</span></span>
<span data-ttu-id="203f1-229"><a  target="_blank" href="http://tez.apache.org/">Apache Tez</a> 是以 Hadoop YARN 為建置基礎的應用程式架構，可執行一般資料處理的複雜非循環圖。</span><span class="sxs-lookup"><span data-stu-id="203f1-229"><a  target="_blank" href="http://tez.apache.org/">Apache Tez</a> is an application framework built on Hadoop YARN that executes complex, acyclic graphs of general data processing.</span></span> <span data-ttu-id="203f1-230">它是更有彈性且功能更強大的 MapReduce 架構後繼版本，可讓資料密集程序 (例如 Hive) 更有效率地大規模執行。</span><span class="sxs-lookup"><span data-stu-id="203f1-230">It's a more flexible and powerful successor to the MapReduce framework that allows data-intensive processes, such as Hive, to run more efficiently at scale.</span></span> <span data-ttu-id="203f1-231">請參閱 [＜使用 Hive 和 HiveQL＞中的＜使用 Apache Tez 以提升效能＞](hdinsight-use-hive.md#usetez)。</span><span class="sxs-lookup"><span data-stu-id="203f1-231">See ["Use Apache Tez for improved performance" in Use Hive and HiveQL](hdinsight-use-hive.md#usetez).</span></span>

### <span data-ttu-id="203f1-232"><a name="yarn"></a>YARN</span><span class="sxs-lookup"><span data-stu-id="203f1-232"><a name="yarn"></a>YARN</span></span>
<span data-ttu-id="203f1-233">Apache YARN 是新一代的 MapReduce (MapReduce 2.0，簡稱 MRv2)，可支援比 MapReduce 批次處理還要多的資料處理案例，並具有更佳的延展性和即時處理能力。</span><span class="sxs-lookup"><span data-stu-id="203f1-233">Apache YARN is the next generation of MapReduce (MapReduce 2.0, or MRv2) and supports data processing scenarios beyond MapReduce batch processing with greater scalability and real-time processing.</span></span> <span data-ttu-id="203f1-234">YARN 能提供資源管理和分散式應用程式架構。</span><span class="sxs-lookup"><span data-stu-id="203f1-234">YARN provides resource management and a distributed application framework.</span></span> <span data-ttu-id="203f1-235">MapReduce 作業會在 YARN 上執行。</span><span class="sxs-lookup"><span data-stu-id="203f1-235">MapReduce jobs run on YARN.</span></span> <span data-ttu-id="203f1-236">請參閱 <a target="_blank" href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">Apache Hadoop NextGen MapReduce (YARN)</a>。</span><span class="sxs-lookup"><span data-stu-id="203f1-236">See <a target="_blank" href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">Apache Hadoop NextGen MapReduce (YARN)</a>.</span></span>

### <span data-ttu-id="203f1-237"><a name="zookeeper"></a>ZooKeeper</span><span class="sxs-lookup"><span data-stu-id="203f1-237"><a name="zookeeper"></a>ZooKeeper</span></span>
<span data-ttu-id="203f1-238"><a  target="_blank" href="http://zookeeper.apache.org/">Apache ZooKeeper</a> 使用資料暫存器 (znode) 的共用階層式命名空間，協調大型分散式系統中的程序。</span><span class="sxs-lookup"><span data-stu-id="203f1-238"><a  target="_blank" href="http://zookeeper.apache.org/">Apache ZooKeeper</a> coordinates processes in large distributed systems using a shared hierarchical namespace of data registers (znodes).</span></span> <span data-ttu-id="203f1-239">Znodes 包含協調程序所需的少量中繼資訊：狀態、位置、組態等。</span><span class="sxs-lookup"><span data-stu-id="203f1-239">Znodes contain small amounts of meta information needed to coordinate processes: status, location, configuration, and so on.</span></span> <span data-ttu-id="203f1-240">請參閱[搭配使用 HBase 叢集與 Apache Phoenix 的 ZooKeeper](hdinsight-hbase-phoenix-squirrel-linux.md) 範例。</span><span class="sxs-lookup"><span data-stu-id="203f1-240">See an example of [ZooKeeper with an HBase cluster and Apache Phoenix](hdinsight-hbase-phoenix-squirrel-linux.md).</span></span> 

## <a name="programming-languages-on-hdinsight"></a><span data-ttu-id="203f1-241">HDInsight 上的程式設計語言</span><span class="sxs-lookup"><span data-stu-id="203f1-241">Programming languages on HDInsight</span></span>
<span data-ttu-id="203f1-242">HDInsight 叢集 (Spark、HBase、Kafka、Hadoop 和其他叢集) 支援許多種程式設計語言，但某些語言並未預設安裝。</span><span class="sxs-lookup"><span data-stu-id="203f1-242">HDInsight clusters - Spark, HBase, Kafka, Hadoop, and other clusters - support many programming languages, but some aren't installed by default.</span></span> <span data-ttu-id="203f1-243">針對未預設安裝的程式庫、模組或套件，請[使用指令碼動作來安裝元件](hdinsight-hadoop-script-actions-linux.md)。</span><span class="sxs-lookup"><span data-stu-id="203f1-243">For libraries, modules, or packages not installed by default, [use a script action to install the component](hdinsight-hadoop-script-actions-linux.md).</span></span> 

### <a name="default-programming-language-support"></a><span data-ttu-id="203f1-244">預設的程式設計語言支援</span><span class="sxs-lookup"><span data-stu-id="203f1-244">Default programming language support</span></span>
<span data-ttu-id="203f1-245">根據預設，HDInsight 叢集可支援：</span><span class="sxs-lookup"><span data-stu-id="203f1-245">By default, HDInsight clusters support:</span></span>

* <span data-ttu-id="203f1-246">Java</span><span class="sxs-lookup"><span data-stu-id="203f1-246">Java</span></span>
* <span data-ttu-id="203f1-247">Python</span><span class="sxs-lookup"><span data-stu-id="203f1-247">Python</span></span>

<span data-ttu-id="203f1-248">其他語言則可以使用[指令碼動作](hdinsight-hadoop-script-actions-linux.md)來加以安裝。</span><span class="sxs-lookup"><span data-stu-id="203f1-248">Additional languages can be installed using [script actions](hdinsight-hadoop-script-actions-linux.md).</span></span>

### <a name="java-virtual-machine-jvm-languages"></a><span data-ttu-id="203f1-249">Java 虛擬機器 (JVM) 語言</span><span class="sxs-lookup"><span data-stu-id="203f1-249">Java virtual machine (JVM) languages</span></span>
<span data-ttu-id="203f1-250">可以在 Java 虛擬機器 (JVM) 上執行 Java 以外的許多語言；不過，若要執行其中的某些語言，您可能必須在叢集上安裝其他元件。</span><span class="sxs-lookup"><span data-stu-id="203f1-250">Many languages other than Java can run on a Java virtual machine (JVM); however, running some of these languages may require additional components installed on the cluster.</span></span>

<span data-ttu-id="203f1-251">HDInsight 叢集上支援下列以 JVM 為基礎的語言：</span><span class="sxs-lookup"><span data-stu-id="203f1-251">These JVM-based languages are supported on HDInsight clusters:</span></span>

* <span data-ttu-id="203f1-252">Clojure</span><span class="sxs-lookup"><span data-stu-id="203f1-252">Clojure</span></span>
* <span data-ttu-id="203f1-253">Jython (適用於 Java 的 Python)</span><span class="sxs-lookup"><span data-stu-id="203f1-253">Jython (Python for Java)</span></span>
* <span data-ttu-id="203f1-254">Scala</span><span class="sxs-lookup"><span data-stu-id="203f1-254">Scala</span></span>

### <a name="hadoop-specific-languages"></a><span data-ttu-id="203f1-255">Hadoop 專屬語言</span><span class="sxs-lookup"><span data-stu-id="203f1-255">Hadoop-specific languages</span></span>
<span data-ttu-id="203f1-256">HDInsight 叢集支援下列 Hadoop 技術堆疊專屬語言：</span><span class="sxs-lookup"><span data-stu-id="203f1-256">HDInsight clusters support the following languages that are specific to the Hadoop technology stack:</span></span>

* <span data-ttu-id="203f1-257">適用於 Pig 工作的 Pig Latin</span><span class="sxs-lookup"><span data-stu-id="203f1-257">Pig Latin for Pig jobs</span></span>
* <span data-ttu-id="203f1-258">適用於 Hive 工作和 SparkSQL 的 HiveQL</span><span class="sxs-lookup"><span data-stu-id="203f1-258">HiveQL for Hive jobs and SparkSQL</span></span>

## <a name="hdinsight-standard-and-hdinsight-premium"></a><span data-ttu-id="203f1-259">HDInsight Standard 和 HDInsight Premium</span><span class="sxs-lookup"><span data-stu-id="203f1-259">HDInsight Standard and HDInsight Premium</span></span>
<span data-ttu-id="203f1-260">HDInsight 提供兩種類型的巨量資料雲端提供項目：Standard 和 Premium。</span><span class="sxs-lookup"><span data-stu-id="203f1-260">HDInsight provides big data cloud offerings in two categories, Standard and Premium.</span></span> <span data-ttu-id="203f1-261">HDInsight Standard 提供組織可用來執行其巨量資料工作負載的企業規模叢集。</span><span class="sxs-lookup"><span data-stu-id="203f1-261">HDInsight Standard provides an enterprise-scale cluster that organizations can use to run their big data workloads.</span></span> <span data-ttu-id="203f1-262">HDInsight Premium 以標準功能為基礎，並提供 HDInsight 叢集的進階分析與安全性功能。</span><span class="sxs-lookup"><span data-stu-id="203f1-262">HDInsight Premium builds on Standard capabilities and provides advanced analytical and security capabilities for an HDInsight cluster.</span></span> <span data-ttu-id="203f1-263">如需詳細資訊，請參閱 [Azure HDInsight Premium](hdinsight-component-versioning.md#hdinsight-standard-and-hdinsight-premium)</span><span class="sxs-lookup"><span data-stu-id="203f1-263">For more information, see [Azure HDInsight Premium](hdinsight-component-versioning.md#hdinsight-standard-and-hdinsight-premium)</span></span>

## <a name="microsoft-business-intelligence-and-hdinsight"></a><span data-ttu-id="203f1-264">Microsoft 商業智慧和 HDInsight</span><span class="sxs-lookup"><span data-stu-id="203f1-264">Microsoft business intelligence and HDInsight</span></span>
<span data-ttu-id="203f1-265">熟悉的商業智慧 (BI) 工具可整合使用 Power Query 增益集或 Microsoft Hive ODBC Driver 的 HDInsight 來擷取、分析和報告資料：</span><span class="sxs-lookup"><span data-stu-id="203f1-265">Familiar business intelligence (BI) tools retrieve, analyze, and report data integrated with HDInsight by using either the Power Query add-in or the Microsoft Hive ODBC Driver:</span></span>

* <span data-ttu-id="203f1-266">[使用 Power Query 將 Excel 連線到 Hadoop](hdinsight-connect-excel-power-query.md)：了解如何使用 Microsoft Power Query for Excel，將 Excel 連線到儲存 HDInsight 叢集資料的 Azure 儲存體帳戶。</span><span class="sxs-lookup"><span data-stu-id="203f1-266">[Connect Excel to Hadoop with Power Query](hdinsight-connect-excel-power-query.md): Learn how to connect Excel to the Azure Storage account that stores the data from your HDInsight cluster by using Microsoft Power Query for Excel.</span></span> <span data-ttu-id="203f1-267">必要的 Windows 工作站。</span><span class="sxs-lookup"><span data-stu-id="203f1-267">Windows workstation required.</span></span> 
* <span data-ttu-id="203f1-268">[使用 Microsoft Hive ODBC 驅動程式將 Excel 連接到 Hadoop](hdinsight-connect-excel-hive-odbc-driver.md)：了解如何使用 Microsoft Hive ODBC 驅動程式從 HDInsight 匯入資料。</span><span class="sxs-lookup"><span data-stu-id="203f1-268">[Connect Excel to Hadoop with the Microsoft Hive ODBC Driver](hdinsight-connect-excel-hive-odbc-driver.md): Learn how to import data from HDInsight with the Microsoft Hive ODBC Driver.</span></span> <span data-ttu-id="203f1-269">必要的 Windows 工作站。</span><span class="sxs-lookup"><span data-stu-id="203f1-269">Windows workstation required.</span></span> 
* <span data-ttu-id="203f1-270">[Microsoft 雲端平台](http://www.microsoft.com/server-cloud/solutions/business-intelligence/default.aspx)：了解 Power BI for Office 365、下載 SQL Server 試用版，以及設定 SharePoint Server 2013 和 SQL Server BI。</span><span class="sxs-lookup"><span data-stu-id="203f1-270">[Microsoft Cloud Platform](http://www.microsoft.com/server-cloud/solutions/business-intelligence/default.aspx): Learn about Power BI for Office 365, download the SQL Server trial, and set up SharePoint Server 2013 and SQL Server BI.</span></span>
* [<span data-ttu-id="203f1-271">SQL Server Analysis Services</span><span class="sxs-lookup"><span data-stu-id="203f1-271">SQL Server Analysis Services</span></span>](http://msdn.microsoft.com/library/hh231701.aspx)
* [<span data-ttu-id="203f1-272">SQL Server Reporting Services</span><span class="sxs-lookup"><span data-stu-id="203f1-272">SQL Server Reporting Services</span></span>](http://msdn.microsoft.com/library/ms159106.aspx)


## <a name="next-steps"></a><span data-ttu-id="203f1-273">後續步驟</span><span class="sxs-lookup"><span data-stu-id="203f1-273">Next steps</span></span>

* <span data-ttu-id="203f1-274">[開始使用 HDInsight 中的 Hadoop](hdinsight-hadoop-linux-tutorial-get-started.md)：佈建 HDInsight Hadoop 叢集以及執行範例 Hive 查詢的快速入門教學課程。</span><span class="sxs-lookup"><span data-stu-id="203f1-274">[Get started with Hadoop in HDInsight](hdinsight-hadoop-linux-tutorial-get-started.md): A quick-start tutorial for provisioning HDInsight Hadoop clusters and running sample Hive queries.</span></span>
* <span data-ttu-id="203f1-275">[開始使用 HDInsight 中的 Spark](hdinsight-apache-spark-jupyter-spark-sql.md)︰建立 Spark 叢集和執行互動式 Spark SQL 查詢的快速入門教學課程。</span><span class="sxs-lookup"><span data-stu-id="203f1-275">[Get started with Spark in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md): A quick-start tutorial for creating a Spark cluster and running interactive Spark SQL queries.</span></span>
* <span data-ttu-id="203f1-276">[在 HDInsight 上使用 R 伺服器](hdinsight-hadoop-r-server-get-started.md)︰開始在 HDInsight Premium 中使用 R 伺服器。</span><span class="sxs-lookup"><span data-stu-id="203f1-276">[Use R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md): Start using R Server in HDInsight Premium.</span></span>
* <span data-ttu-id="203f1-277">[佈建 HDInsight 叢集](hdinsight-hadoop-provision-linux-clusters.md)：了解如何透過 Azure 入口網站、Azure CLI 或 Azure PowerShell 佈建 HDInsight Hadoop 叢集。</span><span class="sxs-lookup"><span data-stu-id="203f1-277">[Provision HDInsight clusters](hdinsight-hadoop-provision-linux-clusters.md): Learn how to provision an HDInsight Hadoop cluster through the Azure portal, Azure CLI, or Azure PowerShell.</span></span>


[component-versioning]: hdinsight-component-versioning.md
[zookeeper]: http://zookeeper.apache.org/