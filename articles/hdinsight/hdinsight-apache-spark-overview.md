---
title: "Spark on Azure HDInsight 簡介 | Microsoft Docs"
description: "本文提供 Spark on HDInsight 簡介以及您可以在 HDInsight 上使用 Spark 叢集的各種案例。"
keywords: "什麼是 apache spark,spark 叢集,spark 簡介,spark on hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: acb80aa98cc978a906ccd6e4b4132a439e505bc8
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 07/11/2017
---
# <a name="introduction-to-spark-on-hdinsight"></a><span data-ttu-id="25623-104">Spark on HDInsight 簡介</span><span class="sxs-lookup"><span data-stu-id="25623-104">Introduction to Spark on HDInsight</span></span>

<span data-ttu-id="25623-105">本文為您提供 Spark on HDInsight 簡介。</span><span class="sxs-lookup"><span data-stu-id="25623-105">This article provides you with an introduction to Spark on HDInsight.</span></span> <span data-ttu-id="25623-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> 是一個開放原始碼平行處理架構，可支援記憶體內部處理，大幅提升巨量資料分析應用程式的效能。</span><span class="sxs-lookup"><span data-stu-id="25623-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="25623-107">HDInsight 上的 Spark 叢集也能與 Azure 儲存體 (WASB) 以及 Azure Data Lake Store 相容，因此您可以輕鬆地透過 Spark 叢集處理儲存在 Azure 中的現有資料。</span><span class="sxs-lookup"><span data-stu-id="25623-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="25623-108">當您在 HDInsight 上建立 Spark 叢集時，就是建立了已安裝及設定 Spark 的 Azure 計算資源。</span><span class="sxs-lookup"><span data-stu-id="25623-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="25623-109">在 HDInsight 中建立 Spark 叢集只需要約十分鐘。</span><span class="sxs-lookup"><span data-stu-id="25623-109">It only takes about ten minutes to create a Spark cluster in HDInsight.</span></span> <span data-ttu-id="25623-110">系統會將要處理的資料儲存在 Azure 儲存體或 Azure Data Lake Store 中。</span><span class="sxs-lookup"><span data-stu-id="25623-110">The data to be processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="25623-111">請參閱[搭配 HDInsight 使用 Azure 儲存體](hdinsight-hadoop-use-blob-storage.md)。</span><span class="sxs-lookup"><span data-stu-id="25623-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="25623-112">**若要在 HDInsight 上建立 Spark 叢集**，請參閱[快速入門：在 HDInsight 上建立 Spark 叢集並使用 Jupyter 執行互動式查詢](hdinsight-apache-spark-jupyter-spark-sql.md)。</span><span class="sxs-lookup"><span data-stu-id="25623-112">**To create a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="25623-113">什麼是 Apache Spark on Azure HDInsight？</span><span class="sxs-lookup"><span data-stu-id="25623-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="25623-114">HDInsight 上的 Spark 叢集可提供完全受管理的 Spark 服務。</span><span class="sxs-lookup"><span data-stu-id="25623-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="25623-115">在 HDInsight 上建立 Spark 叢集的優點如下所列。</span><span class="sxs-lookup"><span data-stu-id="25623-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="25623-116">功能</span><span class="sxs-lookup"><span data-stu-id="25623-116">Feature</span></span> | <span data-ttu-id="25623-117">說明</span><span class="sxs-lookup"><span data-stu-id="25623-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="25623-118">容易建立 Spark 叢集</span><span class="sxs-lookup"><span data-stu-id="25623-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="25623-119">您可以使用 Azure 入口網站、Azure PowerShell 或 HDInsight .NET SDK，在幾分鐘之內於 HDInsight 上建立新的 Spark 叢集。</span><span class="sxs-lookup"><span data-stu-id="25623-119">You can create a new Spark cluster on HDInsight in minutes using the Azure Portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="25623-120">請參閱 [開始使用 HDInsight 中的 Spark 叢集](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="25623-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="25623-121">容易使用</span><span class="sxs-lookup"><span data-stu-id="25623-121">Ease of use</span></span> |<span data-ttu-id="25623-122">HDInsight 上的 Spark 叢集包含 Jupyter 和 Zeppelin Notebook。</span><span class="sxs-lookup"><span data-stu-id="25623-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="25623-123">您可以使用它們來進行互動式的資料處理和視覺化。</span><span class="sxs-lookup"><span data-stu-id="25623-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="25623-124">REST API</span><span class="sxs-lookup"><span data-stu-id="25623-124">REST APIs</span></span> |<span data-ttu-id="25623-125">HDInsight 中的 Spark 叢集包含 [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)，它是 REST-API 型 Spark 作業伺服器，可用來遠端提交及監視作業。</span><span class="sxs-lookup"><span data-stu-id="25623-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="25623-126">支援 Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="25623-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="25623-127">HDInsight 上的 Spark 叢集可以設定為使用 Azure Data Lake Store 作為額外的儲存體以及主要儲存體 (只適用於 HDInsight 3.5 叢集)。</span><span class="sxs-lookup"><span data-stu-id="25623-127">Spark cluster on HDInsight can be configured to use Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="25623-128">如需有關 Data Lake Store 的詳細資訊，請參閱 [Azure Data Lake Store 概觀](../data-lake-store/data-lake-store-overview.md)。</span><span class="sxs-lookup"><span data-stu-id="25623-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="25623-129">Azure 服務整合</span><span class="sxs-lookup"><span data-stu-id="25623-129">Integration with Azure services</span></span> |<span data-ttu-id="25623-130">HDInsight 上的 Spark 叢集附有連線 Azure 事件中樞的連接器。</span><span class="sxs-lookup"><span data-stu-id="25623-130">Spark cluster on HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="25623-131">除了 Spark 已經提供的 [Kafka](http://kafka.apache.org/)之外，客戶還可以使用事件中樞來建置串流應用程式。</span><span class="sxs-lookup"><span data-stu-id="25623-131">Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="25623-132">支援 R 伺服器</span><span class="sxs-lookup"><span data-stu-id="25623-132">Support for R Server</span></span> | <span data-ttu-id="25623-133">您可以在 HDInsight Spark 叢集上設定 R 伺服器，以 Spark 叢集所承諾的速度執行分散式 R 計算。</span><span class="sxs-lookup"><span data-stu-id="25623-133">You can set up a R Server on HDInsight Spark cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="25623-134">如需詳細資訊，請參閱 [開始使用 HDInsight 上的 R 伺服器](hdinsight-hadoop-r-server-get-started.md)。</span><span class="sxs-lookup"><span data-stu-id="25623-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="25623-135">第三方 IDE 整合</span><span class="sxs-lookup"><span data-stu-id="25623-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="25623-136">HDInsight 會提供 IDEs like IntelliJ IDEA 和 Eclipse 的外掛程式，以供您建立應用程式並將其提交至 HDInsight Spark 叢集。</span><span class="sxs-lookup"><span data-stu-id="25623-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="25623-137">如需詳細資訊，請參閱[使用 Azure Toolkit for IntelliJ](hdinsight-apache-spark-intellij-tool-plugin.md)和[使用 Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md)。</span><span class="sxs-lookup"><span data-stu-id="25623-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="25623-138">並行查詢</span><span class="sxs-lookup"><span data-stu-id="25623-138">Concurrent Queries</span></span> |<span data-ttu-id="25623-139">HDInsight 中的 Spark 叢集支援並行查詢。</span><span class="sxs-lookup"><span data-stu-id="25623-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="25623-140">它能讓一位使用者執行多個查詢，或讓不同的使用者執行多個查詢，以及讓應用程式共用相同的叢集資源。</span><span class="sxs-lookup"><span data-stu-id="25623-140">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="25623-141">SSD 快取</span><span class="sxs-lookup"><span data-stu-id="25623-141">Caching on SSDs</span></span> |<span data-ttu-id="25623-142">您可以選擇將資料快取在記憶體中，或快取在連接叢集節點的 SSD 中。</span><span class="sxs-lookup"><span data-stu-id="25623-142">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="25623-143">記憶體快取能提供最高的查詢效能，但可能所費不疵。SSD 快取是改善查詢效能的絕佳選項，而且您不需要根據記憶體中的整個資料集建立滿足其需求的叢集規模。</span><span class="sxs-lookup"><span data-stu-id="25623-143">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="25623-144">BI 工具整合</span><span class="sxs-lookup"><span data-stu-id="25623-144">Integration with BI Tools</span></span> |<span data-ttu-id="25623-145">HDInsight 上的 Spark 叢集會為 BI 工具 (例如 [Power BI](http://www.powerbi.com/) 和 [Tableau](http://www.tableau.com/products/desktop)) 提供資料分析所需的連接器。</span><span class="sxs-lookup"><span data-stu-id="25623-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="25623-146">預先載入的 Anaconda 程式庫</span><span class="sxs-lookup"><span data-stu-id="25623-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="25623-147">HDInsight 上的 Spark 叢集附有預先安裝的 Anaconda 程式庫。</span><span class="sxs-lookup"><span data-stu-id="25623-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="25623-148">[Anaconda](http://docs.continuum.io/anaconda/) 為機器學習、資料分析、視覺化等主題提供將近 200 個程式庫。</span><span class="sxs-lookup"><span data-stu-id="25623-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="25623-149">延展性</span><span class="sxs-lookup"><span data-stu-id="25623-149">Scalability</span></span> |<span data-ttu-id="25623-150">雖然您可以在建立時指定叢集的節點數，但您可以擴大或縮小叢集以配合工作負載。</span><span class="sxs-lookup"><span data-stu-id="25623-150">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</span></span> <span data-ttu-id="25623-151">所有 HDInsight 叢集都允許您變更叢集中的節點數目。</span><span class="sxs-lookup"><span data-stu-id="25623-151">All HDInsight clusters allow you to change the number of nodes in the cluster.</span></span> <span data-ttu-id="25623-152">此外，由於所有資料都儲存在 Azure 儲存體或 Data Lake Store 內，因此您可以在不遺失資料的情況下卸除 Spark 叢集。</span><span class="sxs-lookup"><span data-stu-id="25623-152">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="25623-153">全天候支援</span><span class="sxs-lookup"><span data-stu-id="25623-153">24/7 Support</span></span> |<span data-ttu-id="25623-154">HDInsight 上的 Spark 叢集附有企業級的全天候支援和保證正常運作時間達 99.9% 的 SLA。</span><span class="sxs-lookup"><span data-stu-id="25623-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-the-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="25623-155">HDInsight 上的 Spark 有哪些使用案例？</span><span class="sxs-lookup"><span data-stu-id="25623-155">What are the use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="25623-156">HDInsight 中的 Spark 叢集適用於下列重要案例。</span><span class="sxs-lookup"><span data-stu-id="25623-156">Spark clusters in HDInsight enable the following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="25623-157">互動式資料分析和 BI</span><span class="sxs-lookup"><span data-stu-id="25623-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="25623-158">觀看教學課程</span><span class="sxs-lookup"><span data-stu-id="25623-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="25623-159">HDInsight 中的 Apache Spark 會將資料儲存在 Azure 儲存體或 Azure Data Lake Store 中。</span><span class="sxs-lookup"><span data-stu-id="25623-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="25623-160">商務專家和重要決策者可以利用這些資料來進行分析及建立報告，並使用 Microsoft Power BI 來根據分析資料建置互動式報告。</span><span class="sxs-lookup"><span data-stu-id="25623-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="25623-161">分析師可以從叢集儲存體中的非結構化/半結構化資料著手、使用 Notebook 來定義資料的結構描述，然後再使用 Microsoft Power BI 來建置資料模型。</span><span class="sxs-lookup"><span data-stu-id="25623-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="25623-162">HDInsight 中的 Spark 叢集也支援 Tableau 等多個第三方 BI 工具，因此能成為資料分析師、商務專家及重要決策者的理想平台。</span><span class="sxs-lookup"><span data-stu-id="25623-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="25623-163">Spark 機器學習服務</span><span class="sxs-lookup"><span data-stu-id="25623-163">Spark Machine Learning</span></span>
[<span data-ttu-id="25623-164">看看教學課程：利用 HVAC 資料來預測建築物的溫度</span><span class="sxs-lookup"><span data-stu-id="25623-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="25623-165">看看教學課程：預測食物檢查結果</span><span class="sxs-lookup"><span data-stu-id="25623-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="25623-166">Apache Spark 隨附 [MLlib](http://spark.apache.org/mllib/)，這是以 Spark 為基礎的機器學習程式庫，您可以從 HDInsight 中的 Spark 叢集使用。</span><span class="sxs-lookup"><span data-stu-id="25623-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="25623-167">HDInsight 上的 Spark 叢集也包含 Anaconda，這是提供各種機器學習套件的 Python 散發。</span><span class="sxs-lookup"><span data-stu-id="25623-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="25623-168">搭配內建的 Jupyter 和 Zeppelin Notebook 支援，您將擁有最先進的機器學習應用程式建立環境。</span><span class="sxs-lookup"><span data-stu-id="25623-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="25623-169">Spark 串流和即時資料分析</span><span class="sxs-lookup"><span data-stu-id="25623-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="25623-170">觀看教學課程</span><span class="sxs-lookup"><span data-stu-id="25623-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="25623-171">HDInsight 上的 Spark 叢集提供豐富的支援供您建置即時分析解決方案。</span><span class="sxs-lookup"><span data-stu-id="25623-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="25623-172">雖然 Spark 已附有從 Kafka、Flume、Twitter、ZeroMQ 或 TCP 通訊端等眾多來源擷取資料的連接器，不過 HDInsight 中的 Spark 仍加入首屈一指的支援，供您從 Azure 事件中樞擷取資料。</span><span class="sxs-lookup"><span data-stu-id="25623-172">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="25623-173">事件中樞是 Azure 上最廣泛使用的佇列服務。</span><span class="sxs-lookup"><span data-stu-id="25623-173">Event Hubs are the most widely used queuing service on Azure.</span></span> <span data-ttu-id="25623-174">擁有立即可用的事件中樞支援，讓 HDInsight 中的 Spark 叢集成為建置即時分析管線的理想平台。</span><span class="sxs-lookup"><span data-stu-id="25623-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="25623-175"><a name="next-steps"></a>Spark 叢集包含哪些元件？</span><span class="sxs-lookup"><span data-stu-id="25623-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="25623-176">依預設，HDInsight 中的 Spark 叢集能經由叢集提供下列元件。</span><span class="sxs-lookup"><span data-stu-id="25623-176">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="25623-177">[Spark Core](https://spark.apache.org/docs/1.5.1/)。</span><span class="sxs-lookup"><span data-stu-id="25623-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="25623-178">包括 Spark Core、Spark SQL、Spark 串流 API、GraphX 及 MLlib。</span><span class="sxs-lookup"><span data-stu-id="25623-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="25623-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="25623-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="25623-180">Livy</span><span class="sxs-lookup"><span data-stu-id="25623-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="25623-181">Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="25623-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="25623-182">Zeppelin Notebook</span><span class="sxs-lookup"><span data-stu-id="25623-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="25623-183">HDInsight 中的 Spark 叢集也提供 [ODBC 驅動程式](http://go.microsoft.com/fwlink/?LinkId=616229)，讓您能從 BI 工具 (例如 Microsoft Power BI 和 Tableau) 連線到 HDInsight 中的 Spark 叢集。</span><span class="sxs-lookup"><span data-stu-id="25623-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="25623-184">我該從哪裡開始？</span><span class="sxs-lookup"><span data-stu-id="25623-184">Where do I start?</span></span>
<span data-ttu-id="25623-185">請從在 HDInsight 上建立 Spark 叢集開始。</span><span class="sxs-lookup"><span data-stu-id="25623-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="25623-186">請參閱[快速入門：在 HDInsight Linux 上建立 Spark 叢集並利用 Jupyter 執行互動式查詢](hdinsight-apache-spark-jupyter-spark-sql.md)。</span><span class="sxs-lookup"><span data-stu-id="25623-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="25623-187">後續步驟</span><span class="sxs-lookup"><span data-stu-id="25623-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="25623-188">案例</span><span class="sxs-lookup"><span data-stu-id="25623-188">Scenarios</span></span>
* [<span data-ttu-id="25623-189">Spark 和 BI：在 HDInsight 中搭配使用 Spark 和 BI 工具執行互動式資料分析</span><span class="sxs-lookup"><span data-stu-id="25623-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="25623-190">Spark 和機器學習服務：使用 HDInsight 中的 Spark，利用 HVAC 資料來分析建築物溫度</span><span class="sxs-lookup"><span data-stu-id="25623-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="25623-191">Spark 和機器學習服務：使用 HDInsight 中的 Spark 來預測食品檢查結果</span><span class="sxs-lookup"><span data-stu-id="25623-191">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="25623-192">Spark 串流：使用 HDInsight 中的 Spark 來建置即時串流應用程式</span><span class="sxs-lookup"><span data-stu-id="25623-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="25623-193">使用 HDInsight 中的 Spark 進行網站記錄分析</span><span class="sxs-lookup"><span data-stu-id="25623-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="25623-194">建立及執行應用程式</span><span class="sxs-lookup"><span data-stu-id="25623-194">Create and run applications</span></span>
* [<span data-ttu-id="25623-195">使用 Scala 建立獨立應用程式</span><span class="sxs-lookup"><span data-stu-id="25623-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="25623-196">利用 Livy 在 Spark 叢集上遠端執行作業</span><span class="sxs-lookup"><span data-stu-id="25623-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="25623-197">工具和擴充功能</span><span class="sxs-lookup"><span data-stu-id="25623-197">Tools and extensions</span></span>
* [<span data-ttu-id="25623-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons (使用 IntelliJ IDEA 的 HDInsight Tools 外掛程式來建立和提交 Spark Scala 應用程式)</span><span class="sxs-lookup"><span data-stu-id="25623-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="25623-199">使用 IntelliJ IDEA 的 HDInsight Tools 外掛程式遠端偵錯 Spark 應用程式</span><span class="sxs-lookup"><span data-stu-id="25623-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="25623-200">利用 HDInsight 上的 Spark 叢集來使用 Zeppelin Notebook</span><span class="sxs-lookup"><span data-stu-id="25623-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="25623-201">HDInsight 的 Spark 叢集中 Jupyter Notebook 可用的核心</span><span class="sxs-lookup"><span data-stu-id="25623-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="25623-202">搭配 Jupyter Notebook 使用外部套件</span><span class="sxs-lookup"><span data-stu-id="25623-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="25623-203">在電腦上安裝 Jupyter 並連接到 HDInsight Spark 叢集</span><span class="sxs-lookup"><span data-stu-id="25623-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="25623-204">管理資源</span><span class="sxs-lookup"><span data-stu-id="25623-204">Manage resources</span></span>
* [<span data-ttu-id="25623-205">在 Azure HDInsight 中管理 Apache Spark 叢集的資源</span><span class="sxs-lookup"><span data-stu-id="25623-205">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="25623-206">追蹤和偵錯在 HDInsight 中的 Apache Spark 叢集上執行的作業</span><span class="sxs-lookup"><span data-stu-id="25623-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="25623-207">[Azure HDInsight 中 Apache Spark 的已知問題](hdinsight-apache-spark-known-issues.md)。</span><span class="sxs-lookup"><span data-stu-id="25623-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
