---
title: "aaaIntroduction tooData 工廠，資料整合服務 |Microsoft 文件"
description: "了解 Azure Data Factory 是什麼：一項雲端資料整合服務，用來協調以及自動移動和轉換資料。"
keywords: "資料整合、雲端資料整合、azure data factory 是什麼"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: 4cc30515315efc938951057743ff8eb3701214ef
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/06/2017
---
# <a name="introduction-tooazure-data-factory"></a><span data-ttu-id="31b71-104">簡介 tooAzure Data Factory</span><span class="sxs-lookup"><span data-stu-id="31b71-104">Introduction tooAzure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="31b71-105">Azure 資料處理站是什麼？</span><span class="sxs-lookup"><span data-stu-id="31b71-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="31b71-106">中巨量資料的 hello world，方式是現有資料中運用商務？</span><span class="sxs-lookup"><span data-stu-id="31b71-106">In hello world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="31b71-107">它是藉由使用參考資料，從內部部署資料來源或其他不同的資料來源產生 hello 雲端中的可能 tooenrich 資料嗎？</span><span class="sxs-lookup"><span data-stu-id="31b71-107">Is it possible tooenrich data generated in hello cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="31b71-108">例如，遊戲公司會收集許多遊戲 hello 雲端中所產生的記錄。</span><span class="sxs-lookup"><span data-stu-id="31b71-108">For example, a gaming company collects many logs produced by games in hello cloud.</span></span> <span data-ttu-id="31b71-109">想 tooanalyze toocustomer 喜好設定、 人口統計資料、 使用方式行為這些記錄檔 toogain insights 等 tooidentify 向上銷售和交叉銷售機會，開發新的絕佳功能 toodrive 業務成長，並提供更好的體驗toocustomers。</span><span class="sxs-lookup"><span data-stu-id="31b71-109">It wants tooanalyze these logs toogain insights in toocustomer preferences, demographics, usage behavior etc. tooidentify up-sell and cross-sell opportunities, develop new compelling features toodrive business growth, and provide a better experience toocustomers.</span></span> 

<span data-ttu-id="31b71-110">tooanalyze 這些記錄檔，hello 公司需要 toouse hello 參考資料，例如客戶資訊、 遊戲的資訊，行銷在內部部署資料存放區中的活動資訊。</span><span class="sxs-lookup"><span data-stu-id="31b71-110">tooanalyze these logs, hello company needs toouse hello reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="31b71-111">因此，hello 公司想 tooingest hello 雲端資料存放區中的記錄資料與參考資料，從 hello 在內部部署資料存放區。</span><span class="sxs-lookup"><span data-stu-id="31b71-111">Therefore, hello company wants tooingest log data from hello cloud data store and reference data from hello on-premises data store.</span></span> <span data-ttu-id="31b71-112">然後，利用 Hadoop hello 處理 hello 資料雲端 (Azure HDInsight)，並發行到雲端資料倉儲，例如 Azure SQL 資料倉儲或內部部署資料的資料存放區，例如 SQL Server 的 hello 結果。</span><span class="sxs-lookup"><span data-stu-id="31b71-112">Then, process hello data by using Hadoop in hello cloud (Azure HDInsight) and publish hello result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="31b71-113">它想要這個工作流程 toorun 每週一次。</span><span class="sxs-lookup"><span data-stu-id="31b71-113">It wants this workflow toorun weekly once.</span></span> 

<span data-ttu-id="31b71-114">需要的是允許的工作流程，可以使用現有的計算服務，例如 Hadoop，內嵌資料從內部部署和雲端資料存放區和轉換或處理序的資料及發行 hello 結果 tooan 內部部署的 hello 公司 toocreate 的平台或 BI 應用程式 tooconsume 的雲端資料儲存區。</span><span class="sxs-lookup"><span data-stu-id="31b71-114">What is needed is a platform that allows hello company toocreate a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish hello results tooan on-premises or cloud data store for BI applications tooconsume.</span></span> 

![Data Factory 概觀](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="31b71-116">Azure Data Factory 是這種案例的 hello 平台。</span><span class="sxs-lookup"><span data-stu-id="31b71-116">Azure Data Factory is hello platform for this kind of scenarios.</span></span> <span data-ttu-id="31b71-117">它是**以雲端為基礎的資料整合服務，可讓您 toocreate 資料驅動型工作流程中 hello 雲端來協調及自動化資料移動及轉換資料**。</span><span class="sxs-lookup"><span data-stu-id="31b71-117">It is a **cloud-based data integration service that allows you toocreate data-driven workflows in hello cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="31b71-118">使用 Azure Data Factory，您可以建立及排程資料驅動型工作流程 （稱為管線），內嵌來自不同資料存放區的資料、 處理序/轉換 hello 資料使用計算服務，例如 Azure HDInsight Hadoop Spark，Azure 資料湖分析和 Azure Machine Learning 中，並將輸出資料 toodata 存放區，例如 Azure SQL 資料倉儲的商務智慧 (BI) 應用程式 tooconsume 發行。</span><span class="sxs-lookup"><span data-stu-id="31b71-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform hello data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data toodata stores such as Azure SQL Data Warehouse for business intelligence (BI) applications tooconsume.</span></span>  

<span data-ttu-id="31b71-119">它與其說是傳統的擷取-轉換-和-載入 (ETL) 平台，還不如說是擷取並載入 (EL) 而後轉換並載入 (TL) 平台。</span><span class="sxs-lookup"><span data-stu-id="31b71-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="31b71-120">hello 轉換的使用計算服務會 tootransform/處理序資料，而不是直接 tooperform 轉換像 hello 的加入衍生的資料行，計算的資料列，排序資料等的數目。</span><span class="sxs-lookup"><span data-stu-id="31b71-120">hello transformations that are performed are tootransform/process data by using compute services rather than tooperform transformations like hello ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="31b71-121">目前，在 Azure Data Factory，hello 資料取用，且所產生的工作流程會**時間切割資料**（每小時、 每天、 每週、 等等）。</span><span class="sxs-lookup"><span data-stu-id="31b71-121">Currently, in Azure Data Factory, hello data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="31b71-122">例如，管線可以讀取輸入資料、處理資料，以及每天產生一次輸出資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="31b71-123">您也可以只執行一次工作流程。</span><span class="sxs-lookup"><span data-stu-id="31b71-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="31b71-124">運作方式</span><span class="sxs-lookup"><span data-stu-id="31b71-124">How does it work?</span></span> 
<span data-ttu-id="31b71-125">Azure Data Factory 中的 hello 管線 （資料驅動型工作流程） 通常會執行下列三個步驟的 hello:</span><span class="sxs-lookup"><span data-stu-id="31b71-125">hello pipelines (data-driven workflows) in Azure Data Factory typically perform hello following three steps:</span></span>

![Azure Data Factory 的三個階段](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="31b71-127">連線及收集</span><span class="sxs-lookup"><span data-stu-id="31b71-127">Connect and collect</span></span>
<span data-ttu-id="31b71-128">企業會有位於不同來源的各類型資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="31b71-129">hello 建置資訊生產系統中的第一個步驟是 tooconnect tooall hello 所需的資料來源和處理，SaaS 服務，例如檔案共用、 FTP、 web 服務，並移動 hello 資料視 tooa 集中式位置後續處理程序。</span><span class="sxs-lookup"><span data-stu-id="31b71-129">hello first step in building an information production system is tooconnect tooall hello required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move hello data as-needed tooa centralized location for subsequent processing.</span></span>

<span data-ttu-id="31b71-130">Data Factory 沒有企業必須建置自訂的資料移動元件，或撰寫自訂服務 toointegrate，這些資料來源和處理。</span><span class="sxs-lookup"><span data-stu-id="31b71-130">Without Data Factory, enterprises must build custom data movement components or write custom services toointegrate these data sources and processing.</span></span> <span data-ttu-id="31b71-131">它是高度耗費資源和固定 toointegrate 和維護這類系統中，且它通常缺少 hello 企業等級監視和警示和 hello 控制項可以提供完整受管理的服務。</span><span class="sxs-lookup"><span data-stu-id="31b71-131">It is expensive and hard toointegrate and maintain such systems, and it often lacks hello enterprise grade monitoring and alerting, and hello controls that a fully managed service can offer.</span></span>

<span data-ttu-id="31b71-132">使用 Data Factory 中，您可以使用 hello 複製活動在資料管線 toomove 資料從這兩個內部部署和雲端來源資料存放區 tooa 集中化資料存放區進行進一步的分析 hello 雲端中。</span><span class="sxs-lookup"><span data-stu-id="31b71-132">With Data Factory, you can use hello Copy Activity in a data pipeline toomove data from both on-premises and cloud source data stores tooa centralization data store in hello cloud for further analysis.</span></span> <span data-ttu-id="31b71-133">例如，您可以使用 Azure Data Lake Analytics 計算服務稍後收集 Azure Data Lake Store 和轉換 hello 資料中的資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-133">For example, you can collect data in an Azure Data Lake Store and transform hello data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="31b71-134">或者，收集 Azure Blob 儲存體中的資料，之後使用 Azure HDInsight Hadoop 叢集來轉換資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="31b71-135">轉換及擴充</span><span class="sxs-lookup"><span data-stu-id="31b71-135">Transform and enrich</span></span>
<span data-ttu-id="31b71-136">一旦資料存在於 hello 雲端中的集中式的資料存放區中，您會想 hello 收集資料 toobe 處理，或藉由計算服務，例如 HDInsight Hadoop、 Spark、 Data Lake Analytics 和機器學習轉換。</span><span class="sxs-lookup"><span data-stu-id="31b71-136">Once data is present in a centralized data store in hello cloud, you want hello collected data toobe processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="31b71-137">您想 tooreliably 產生轉換資料，可維護且受控制的排程 toofeed 生產環境使用信任的資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-137">You want tooreliably produce transformed data on a maintainable and controlled schedule toofeed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="31b71-138">發佈</span><span class="sxs-lookup"><span data-stu-id="31b71-138">Publish</span></span> 
<span data-ttu-id="31b71-139">已轉換將資料傳送 hello 雲端 tooon 內部部署來源，例如 SQL Server，或將它放在您的雲端儲存體耗用量的來源由商業智慧 (BI) 和分析工具和其他應用程式。</span><span class="sxs-lookup"><span data-stu-id="31b71-139">Deliver transformed data from hello cloud tooon-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="31b71-140">重要元件</span><span class="sxs-lookup"><span data-stu-id="31b71-140">Key components</span></span>
<span data-ttu-id="31b71-141">Azure 訂用帳戶可能會有一或多個 Azure Data Factory 執行個體 (或資料處理站)。</span><span class="sxs-lookup"><span data-stu-id="31b71-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="31b71-142">Azure Data Factory 是由四個主要元件可一起運作 tooprovide hello 平台，您可以撰寫步驟 toomove 和轉換資料的資料驅動型工作流程所組成。</span><span class="sxs-lookup"><span data-stu-id="31b71-142">Azure Data Factory is composed of four key components that work together tooprovide hello platform on which you can compose data-driven workflows with steps toomove and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="31b71-143">管線</span><span class="sxs-lookup"><span data-stu-id="31b71-143">Pipeline</span></span>
<span data-ttu-id="31b71-144">資料處理站可以有一或多個管線。</span><span class="sxs-lookup"><span data-stu-id="31b71-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="31b71-145">管線是一組活動。</span><span class="sxs-lookup"><span data-stu-id="31b71-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="31b71-146">同時，在管線中的 hello 活動執行的工作。</span><span class="sxs-lookup"><span data-stu-id="31b71-146">Together, hello activities in a pipeline perform a task.</span></span> <span data-ttu-id="31b71-147">例如，管線無法包含一組活動的內嵌資料從 Azure blob，而然後 HDInsight 叢集 toopartition hello 資料上執行 Hive 查詢。</span><span class="sxs-lookup"><span data-stu-id="31b71-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster toopartition hello data.</span></span> <span data-ttu-id="31b71-148">此設定的 hello 好處是該 hello 管線可讓您 toomanage hello 活動為一組，而不是每個個別。</span><span class="sxs-lookup"><span data-stu-id="31b71-148">hello benefit of this is that hello pipeline allows you toomanage hello activities as a set instead of each one individually.</span></span> <span data-ttu-id="31b71-149">例如，您可以部署和獨立排程 hello 管線，而不是 hello 活動。</span><span class="sxs-lookup"><span data-stu-id="31b71-149">For example, you can deploy and schedule hello pipeline, instead of hello activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="31b71-150">活動</span><span class="sxs-lookup"><span data-stu-id="31b71-150">Activity</span></span>
<span data-ttu-id="31b71-151">管線可以有一或多個活動。</span><span class="sxs-lookup"><span data-stu-id="31b71-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="31b71-152">活動定義 hello 動作 tooperform 對您的資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-152">Activities define hello actions tooperform on your data.</span></span> <span data-ttu-id="31b71-153">例如，您可以使用複製活動 toocopy 資料從一個資料存放區 tooanother 資料存放區。</span><span class="sxs-lookup"><span data-stu-id="31b71-153">For example, you may use a Copy activity toocopy data from one data store tooanother data store.</span></span> <span data-ttu-id="31b71-154">同樣地，您可能使用 Hive 活動，其在 Azure HDInsight 叢集 tootransform 上執行 Hive 查詢或分析資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster tootransform or analyze your data.</span></span> <span data-ttu-id="31b71-155">Data Factory 支援兩種活動類型︰資料移動活動和資料轉換活動。</span><span class="sxs-lookup"><span data-stu-id="31b71-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="31b71-156">資料移動活動</span><span class="sxs-lookup"><span data-stu-id="31b71-156">Data movement activities</span></span>
<span data-ttu-id="31b71-157">Data Factory 中的複製活動會將資料從來源資料存放區 tooa 接收資料存放區。</span><span class="sxs-lookup"><span data-stu-id="31b71-157">Copy Activity in Data Factory copies data from a source data store tooa sink data store.</span></span> <span data-ttu-id="31b71-158">Data Factory 支援下列資料存放區的 hello。</span><span class="sxs-lookup"><span data-stu-id="31b71-158">Data Factory supports hello following data stores.</span></span> <span data-ttu-id="31b71-159">從任何來源的資料可以寫入 tooany 接收。</span><span class="sxs-lookup"><span data-stu-id="31b71-159">Data from any source can be written tooany sink.</span></span> <span data-ttu-id="31b71-160">按一下 資料存放區 toolearn 如何 toocopy 資料 tooand 從該存放區。</span><span class="sxs-lookup"><span data-stu-id="31b71-160">Click a data store toolearn how toocopy data tooand from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="31b71-161">如需詳細資訊，請參閱[資料移動活動](data-factory-data-movement-activities.md)文章。</span><span class="sxs-lookup"><span data-stu-id="31b71-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="31b71-162">資料轉換活動</span><span class="sxs-lookup"><span data-stu-id="31b71-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="31b71-163">如需詳細資訊，請參閱[資料轉換活動](data-factory-data-transformation-activities.md)文章。</span><span class="sxs-lookup"><span data-stu-id="31b71-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="31b71-164">自訂 .NET 活動</span><span class="sxs-lookup"><span data-stu-id="31b71-164">Custom .NET activities</span></span>
<span data-ttu-id="31b71-165">如果您需要 toomove 資料/從資料存放區的複製活動不支援，或使用您自己的邏輯轉換資料，建立**自訂.NET 活動**。</span><span class="sxs-lookup"><span data-stu-id="31b71-165">If you need toomove data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="31b71-166">如需有關建立及使用自訂活動的詳細資料，請參閱 [在 Azure Data Factory 管線中使用自訂活動](data-factory-use-custom-activities.md)。</span><span class="sxs-lookup"><span data-stu-id="31b71-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="31b71-167">資料集</span><span class="sxs-lookup"><span data-stu-id="31b71-167">Datasets</span></span>
<span data-ttu-id="31b71-168">活動可取得零或多個資料集作為輸入，並取得一或多個資料集作為輸出。</span><span class="sxs-lookup"><span data-stu-id="31b71-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="31b71-169">資料集代表 hello 資料存放區，這只是點，或參考您程式活動中要 toouse 做為輸入或輸出的 hello 資料內的資料結構。</span><span class="sxs-lookup"><span data-stu-id="31b71-169">Datasets represent data structures within hello data stores, which simply point or reference hello data you want toouse in your activities as inputs or outputs.</span></span> <span data-ttu-id="31b71-170">例如，Azure Blob 資料集 hello Azure Blob 儲存體中的 hello 管線應該讀取 hello 資料指定 hello blob 容器和資料夾。</span><span class="sxs-lookup"><span data-stu-id="31b71-170">For example, an Azure Blob dataset specifies hello blob container and folder in hello Azure Blob Storage from which hello pipeline should read hello data.</span></span> <span data-ttu-id="31b71-171">或者，Azure SQL 資料表資料集指定 hello 資料表 toowhich hello 輸出資料寫入 hello 活動。</span><span class="sxs-lookup"><span data-stu-id="31b71-171">Or, an Azure SQL Table dataset specifies hello table toowhich hello output data is written by hello activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="31b71-172">連結的服務</span><span class="sxs-lookup"><span data-stu-id="31b71-172">Linked services</span></span>
<span data-ttu-id="31b71-173">連結的服務非常類似連接字串，定義所需的 Data Factory tooconnect tooexternal 資源 hello 連接資訊中。</span><span class="sxs-lookup"><span data-stu-id="31b71-173">Linked services are much like connection strings, which define hello connection information needed for Data Factory tooconnect tooexternal resources.</span></span> <span data-ttu-id="31b71-174">將它這種方式-連結的服務定義 hello 連線 toohello 資料來源和資料集代表 hello hello 資料結構。</span><span class="sxs-lookup"><span data-stu-id="31b71-174">Think of it this way - a linked service defines hello connection toohello data source and a dataset represents hello structure of hello data.</span></span> <span data-ttu-id="31b71-175">例如，Azure 儲存體連結服務指定連線字串 tooconnect toohello Azure 儲存體帳戶。</span><span class="sxs-lookup"><span data-stu-id="31b71-175">For example, an Azure Storage linked service specifies connection string tooconnect toohello Azure Storage account.</span></span> <span data-ttu-id="31b71-176">此外，Azure Blob 資料集指定 hello blob 容器和包含 hello 資料 hello 資料夾。</span><span class="sxs-lookup"><span data-stu-id="31b71-176">And, an Azure Blob dataset specifies hello blob container and hello folder that contains hello data.</span></span>   

<span data-ttu-id="31b71-177">Data Factory 中的連結服務，有兩個用途：</span><span class="sxs-lookup"><span data-stu-id="31b71-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="31b71-178">toorepresent**資料存放區**包括但不是限於在內部部署 SQL Server、 Oracle 資料庫、 檔案共用或 Azure Blob 儲存體帳戶。</span><span class="sxs-lookup"><span data-stu-id="31b71-178">toorepresent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="31b71-179">請參閱 hello[資料移動活動](#data-movement-activities)部分支援的資料存放區的清單。</span><span class="sxs-lookup"><span data-stu-id="31b71-179">See hello [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="31b71-180">toorepresent**計算資源**可以裝載 hello 活動執行的。</span><span class="sxs-lookup"><span data-stu-id="31b71-180">toorepresent a **compute resource** that can host hello execution of an activity.</span></span> <span data-ttu-id="31b71-181">例如，hello HDInsightHive 活動 HDInsight Hadoop 叢集上執行。</span><span class="sxs-lookup"><span data-stu-id="31b71-181">For example, hello HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="31b71-182">如需支援的計算環境清單，請參閱[資料轉換活動](#data-transformation-activities)一節。</span><span class="sxs-lookup"><span data-stu-id="31b71-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="31b71-183">Data Factory 實體之間的關聯性</span><span class="sxs-lookup"><span data-stu-id="31b71-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="31b71-184">![圖表︰Data Factory 概觀 (雲端資料整合服務) - 重要概念](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**圖 2.**</span><span class="sxs-lookup"><span data-stu-id="31b71-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="31b71-185">資料集、活動、管線和連結服務之間的關聯性。</span><span class="sxs-lookup"><span data-stu-id="31b71-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="31b71-186">支援區域</span><span class="sxs-lookup"><span data-stu-id="31b71-186">Supported regions</span></span>
<span data-ttu-id="31b71-187">目前，您可以建立 data factory 中 hello**美國西部**，**美國東部**，和**北歐**區域。</span><span class="sxs-lookup"><span data-stu-id="31b71-187">Currently, you can create data factories in hello **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="31b71-188">不過，資料處理站可以存取資料存放區，並計算其他資料存放區之間的 Azure 區域 toomove 資料中的服務或處理程序使用的資料計算服務。</span><span class="sxs-lookup"><span data-stu-id="31b71-188">However, a data factory can access data stores and compute services in other Azure regions toomove data between data stores or process data using compute services.</span></span>

<span data-ttu-id="31b71-189">Azure Data Factory 本身不會儲存任何資料。</span><span class="sxs-lookup"><span data-stu-id="31b71-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="31b71-190">它可讓您建立資料驅動型工作流程 tooorchestrate 之間資料移動的[支援資料存放區](#data-movement-activities)和處理的資料使用[計算服務](#data-transformation-activities)內部或其他區域中環境。</span><span class="sxs-lookup"><span data-stu-id="31b71-190">It lets you create data-driven workflows tooorchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="31b71-191">它也可讓您太[監視和管理工作流程](data-factory-monitor-manage-pipelines.md)同時以程式設計方式使用和 UI 機制。</span><span class="sxs-lookup"><span data-stu-id="31b71-191">It also allows you too[monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="31b71-192">即使 Data Factory 僅提供**美國西部**，**美國東部**，和**北歐**區域，電源 hello Data Factory 中的資料移動的 hello 服務可供使用[全域](data-factory-data-movement-activities.md#global)數個區域中。</span><span class="sxs-lookup"><span data-stu-id="31b71-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, hello service powering hello data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="31b71-193">如果資料存放區是在防火牆後面，則[資料管理閘道器](data-factory-move-data-between-onprem-and-cloud.md)改為安裝在內部部署環境移動 hello 資料中。</span><span class="sxs-lookup"><span data-stu-id="31b71-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves hello data instead.</span></span>

<span data-ttu-id="31b71-194">如需範例，讓我們假設您的計算環境 (例如 Azure HDInsight 叢集和 Azure 機器學習服務) 即將用盡西歐區域的資源。</span><span class="sxs-lookup"><span data-stu-id="31b71-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="31b71-195">您可以建立和使用 Azure Data Factory 中的執行個體北歐和使用它 tooschedule 作業在西歐中計算環境。</span><span class="sxs-lookup"><span data-stu-id="31b71-195">You can create and use an Azure Data Factory instance in North Europe and use it tooschedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="31b71-196">毫秒幾個 Data Factory tootrigger hello 作業於您的運算環境，但不會變更執行 hello 作業上您的運算環境的 hello 時間。</span><span class="sxs-lookup"><span data-stu-id="31b71-196">It takes a few milliseconds for Data Factory tootrigger hello job on your compute environment but hello time for running hello job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="31b71-197">開始建立管線</span><span class="sxs-lookup"><span data-stu-id="31b71-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="31b71-198">您可以使用這些工具或 Api toocreate 資料管線的其中一個 Azure Data Factory 中：</span><span class="sxs-lookup"><span data-stu-id="31b71-198">You can use one of these tools or APIs toocreate data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="31b71-199">Azure 入口網站</span><span class="sxs-lookup"><span data-stu-id="31b71-199">Azure portal</span></span>
- <span data-ttu-id="31b71-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="31b71-200">Visual Studio</span></span>
- <span data-ttu-id="31b71-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="31b71-201">PowerShell</span></span>
- <span data-ttu-id="31b71-202">.NET API</span><span class="sxs-lookup"><span data-stu-id="31b71-202">.NET API</span></span>
- <span data-ttu-id="31b71-203">REST API</span><span class="sxs-lookup"><span data-stu-id="31b71-203">REST API</span></span>
- <span data-ttu-id="31b71-204">Azure Resource Manager 範本。</span><span class="sxs-lookup"><span data-stu-id="31b71-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="31b71-205">toolearn 資料 toobuild data factory 管線的方式，請依照下列 hello 遵循教學課程中的逐步指示：</span><span class="sxs-lookup"><span data-stu-id="31b71-205">toolearn how toobuild data factories with data pipelines, follow step-by-step instructions in hello following tutorials:</span></span>

| <span data-ttu-id="31b71-206">教學課程</span><span class="sxs-lookup"><span data-stu-id="31b71-206">Tutorial</span></span> | <span data-ttu-id="31b71-207">說明</span><span class="sxs-lookup"><span data-stu-id="31b71-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="31b71-208">在兩個雲端資料存放區之間移動資料</span><span class="sxs-lookup"><span data-stu-id="31b71-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="31b71-209">在本教學課程中，您建立 data factory 管線，**移動資料**從 Blob 儲存體 tooSQL 資料庫。</span><span class="sxs-lookup"><span data-stu-id="31b71-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage tooSQL database.</span></span> |
| [<span data-ttu-id="31b71-210">使用 Hadoop 叢集轉換資料</span><span class="sxs-lookup"><span data-stu-id="31b71-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="31b71-211">在本教學課程中，您會在 Azure HDInsight (Hadoop) 叢集上執行 Hive 指令碼，以建立您的第一個 Azure Data Factory 與用來 **處理資料** 的資料管線。</span><span class="sxs-lookup"><span data-stu-id="31b71-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="31b71-212">使用資料管理閘道，在內部部署資料存放區與雲端資料存放區之間移動資料</span><span class="sxs-lookup"><span data-stu-id="31b71-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="31b71-213">在此教學課程中，您建立具有管線的 data factory 的**移動資料**從**內部**SQL Server 資料庫 tooan Azure blob。</span><span class="sxs-lookup"><span data-stu-id="31b71-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database tooan Azure blob.</span></span> <span data-ttu-id="31b71-214">Hello 逐步解說中，您可以安裝並設定 hello 資料管理閘道器電腦上。</span><span class="sxs-lookup"><span data-stu-id="31b71-214">As part of hello walkthrough, you install and configure hello Data Management Gateway on your machine.</span></span> |
