---
title: "aaaCopy 活動效能及微調指南 |Microsoft 文件"
description: "深入了解當您使用複製活動時，會影響 Azure Data Factory 中的資料移動 hello 效能的關鍵因素。"
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: b0fb5a76c34752d07e8ddfffbb799a05fb5d6be6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/06/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="0da85-103">複製活動的效能及微調指南</span><span class="sxs-lookup"><span data-stu-id="0da85-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="0da85-104">Azure Data Factory 複製活動會提供安全、可靠、高效能的頂級資料載入解決方案。</span><span class="sxs-lookup"><span data-stu-id="0da85-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="0da85-105">它可讓您 toocopy 數以萬計的 tb 的資料每天在各式各樣的雲端，並在內部部署資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-105">It enables you toocopy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="0da85-106">急速資料載入效能是您可以專注於 hello 核心"巨量資料 」 問題的索引鍵 tooensure： 建立進階的分析解決方案，並從所有資料取得的深入資訊。</span><span class="sxs-lookup"><span data-stu-id="0da85-106">Blazing-fast data loading performance is key tooensure you can focus on hello core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="0da85-107">Azure 提供企業等級的一組資料的儲存體和資料倉儲方案，並複製活動提供高度最佳化的資料載入輕鬆 tooconfigure 及設定的體驗。</span><span class="sxs-lookup"><span data-stu-id="0da85-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy tooconfigure and set up.</span></span> <span data-ttu-id="0da85-108">只要使用單一的複製活動，您便可以達成下列目的︰</span><span class="sxs-lookup"><span data-stu-id="0da85-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="0da85-109">以 **1.2 GBps** 的速度將資料載入 **Azure SQL 資料倉儲**。</span><span class="sxs-lookup"><span data-stu-id="0da85-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="0da85-110">如需使用案例的逐步解說，請參閱[使用 Azure Data Factory 在 15 分鐘內將 1 TB 載入至 Azure SQL 資料倉儲](data-factory-load-sql-data-warehouse.md)。</span><span class="sxs-lookup"><span data-stu-id="0da85-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="0da85-111">以 **1.0 GBps** 的速度將資料載入 **Azure Blob 儲存體**</span><span class="sxs-lookup"><span data-stu-id="0da85-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="0da85-112">以 **1.0 GBps** 的速度將資料載入 **Azure Data Lake Store**</span><span class="sxs-lookup"><span data-stu-id="0da85-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="0da85-113">本文章說明：</span><span class="sxs-lookup"><span data-stu-id="0da85-113">This article describes:</span></span>

* <span data-ttu-id="0da85-114">[效能參考編號](#performance-reference)針對支援的來源和接收資料存放區 toohelp 您計劃您的專案。</span><span class="sxs-lookup"><span data-stu-id="0da85-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores toohelp you plan your project;</span></span>
* <span data-ttu-id="0da85-115">功能，可以提升 hello 不同的案例，包括複製輸送量[雲端資料移動的單位](#cloud-data-movement-units)，[平行複製](#parallel-copy)，和[分段複製](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="0da85-115">Features that can boost hello copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="0da85-116">[效能調整指引](#performance-tuning-steps)上 tootune hello 效能與 hello 關鍵因素會影響如何複製效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-116">[Performance tuning guidance](#performance-tuning-steps) on how tootune hello performance and hello key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="0da85-117">如果您大致來說並不熟悉複製活動，請先參閱 [使用複製活動來移動資料](data-factory-data-movement-activities.md) 再閱讀本文。</span><span class="sxs-lookup"><span data-stu-id="0da85-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="0da85-118">效能參考</span><span class="sxs-lookup"><span data-stu-id="0da85-118">Performance reference</span></span>

<span data-ttu-id="0da85-119">做為參考下表, 會顯示 hello 複製輸送量數字中 MBps hello 指定來源和接收組內部測試為基礎。</span><span class="sxs-lookup"><span data-stu-id="0da85-119">As a reference, below table shows hello copy throughput number in MBps for hello given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="0da85-120">為了進行比較，該表格也會示範[雲端資料移動單位](#cloud-data-movement-units)或[資料管理閘道延展性](data-factory-data-management-gateway-high-availability-scalability.md) (多個閘道節點) 的不同設定如何協助複製效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![效能矩陣](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="0da85-122">**點 toonote:**</span><span class="sxs-lookup"><span data-stu-id="0da85-122">**Points toonote:**</span></span>
* <span data-ttu-id="0da85-123">輸送量使用 hello 下列公式來計算: [從來源讀取資料的大小] / [複製活動執行持續時間]。</span><span class="sxs-lookup"><span data-stu-id="0da85-123">Throughput is calculated by using hello following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="0da85-124">hello 資料表中的 hello 效能參考編號已測量使用[TPC H](http://www.tpc.org/tpch/)執行單一複製活動中的資料集。</span><span class="sxs-lookup"><span data-stu-id="0da85-124">hello performance reference numbers in hello table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="0da85-125">在 Azure 的資料存放區，hello 來源和接收器是 hello 中相同的 Azure 區域。</span><span class="sxs-lookup"><span data-stu-id="0da85-125">In Azure data stores, hello source and sink are in hello same Azure region.</span></span>
* <span data-ttu-id="0da85-126">在內部部署和雲端之間的混合式複製的資料存放區，已與 hello 在內部部署資料存放區下方規格不同的電腦上執行閘道的每個節點。</span><span class="sxs-lookup"><span data-stu-id="0da85-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from hello on-premises data store with below specification.</span></span> <span data-ttu-id="0da85-127">當單一活動執行閘道上時，hello 複製作業會取用一小部分的 hello 測試機器的 CPU、 記憶體或網路頻寬。</span><span class="sxs-lookup"><span data-stu-id="0da85-127">When a single activity was running on gateway, hello copy operation consumed only a small portion of hello test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="0da85-128">深入了解[資料管理閘道的考量](#considerations-for-data-management-gateway)。</span><span class="sxs-lookup"><span data-stu-id="0da85-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="0da85-129">CPU</span><span class="sxs-lookup"><span data-stu-id="0da85-129">CPU</span></span></td>
        <td><span data-ttu-id="0da85-130">32 核心 2.20 GHz Intel Xeon E5-2660 v2</span><span class="sxs-lookup"><span data-stu-id="0da85-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="0da85-131">記憶體</span><span class="sxs-lookup"><span data-stu-id="0da85-131">Memory</span></span></td>
        <td><span data-ttu-id="0da85-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="0da85-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="0da85-133">網路</span><span class="sxs-lookup"><span data-stu-id="0da85-133">Network</span></span></td>
        <td><span data-ttu-id="0da85-134">網際網路介面：10 Gbps；內部網路介面：40 Gbps</span><span class="sxs-lookup"><span data-stu-id="0da85-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="0da85-135">您可以利用更多資料移動的單位 (DMUs) 比 hello，以達到更高的輸送量預設最大 DMUs，即 32 雲端至雲端複製活動執行。</span><span class="sxs-lookup"><span data-stu-id="0da85-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than hello default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="0da85-136">比方說，使用 100 DMU，您就可以用 **1.0GBps** 的速率將資料從 Azure Blob 複製到 Azure Data Lake Store。</span><span class="sxs-lookup"><span data-stu-id="0da85-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="0da85-137">請參閱 hello[雲端資料移動的單位](#cloud-data-movement-units)> 一節，如需詳細資訊，此功能和 hello 支援案例。</span><span class="sxs-lookup"><span data-stu-id="0da85-137">See hello [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and hello supported scenario.</span></span> <span data-ttu-id="0da85-138">請連絡[Azure 支援](https://azure.microsoft.com/support/)toorequest 詳細 DMUs。</span><span class="sxs-lookup"><span data-stu-id="0da85-138">Contact [Azure support](https://azure.microsoft.com/support/) toorequest more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="0da85-139">平行複製</span><span class="sxs-lookup"><span data-stu-id="0da85-139">Parallel copy</span></span>
<span data-ttu-id="0da85-140">您可以閱讀 hello 從資料來源，或寫入資料 toohello 目的地**在複製活動中執行的平行**。</span><span class="sxs-lookup"><span data-stu-id="0da85-140">You can read data from hello source or write data toohello destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="0da85-141">這項功能可加強 hello 的複製作業的輸送量並減少 hello toomove 資料所花費的時間。</span><span class="sxs-lookup"><span data-stu-id="0da85-141">This feature enhances hello throughput of a copy operation and reduces hello time it takes toomove data.</span></span>

<span data-ttu-id="0da85-142">這項設定是不同於 hello**並行**hello 活動定義中的屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-142">This setting is different from hello **concurrency** property in hello activity definition.</span></span> <span data-ttu-id="0da85-143">hello**並行**屬性決定 hello 數目**並行複製活動執行**tooprocess 資料從不同的活動視窗 (1 AM too2 AM，2 AM too3 AM，3 AM too4 等等)。</span><span class="sxs-lookup"><span data-stu-id="0da85-143">hello **concurrency** property determines hello number of **concurrent Copy Activity runs** tooprocess data from different activity windows (1 AM too2 AM, 2 AM too3 AM, 3 AM too4 AM, and so on).</span></span> <span data-ttu-id="0da85-144">在執行歷程載入時，這個功能非常有用。</span><span class="sxs-lookup"><span data-stu-id="0da85-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="0da85-145">hello 平行複製功能適用於 tooa**單一活動執行**。</span><span class="sxs-lookup"><span data-stu-id="0da85-145">hello parallel copy capability applies tooa **single activity run**.</span></span>

<span data-ttu-id="0da85-146">讓我們看一下範例案例。</span><span class="sxs-lookup"><span data-stu-id="0da85-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="0da85-147">在下列範例的 hello，從過去的 hello 的多個配量會需要 toobe 處理。</span><span class="sxs-lookup"><span data-stu-id="0da85-147">In hello following example, multiple slices from hello past need toobe processed.</span></span> <span data-ttu-id="0da85-148">Data Factory 會對每個配量執行一個複製活動執行個體 (活動執行)：</span><span class="sxs-lookup"><span data-stu-id="0da85-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="0da85-149">從第一個活動視窗 hello hello 資料配量 （1 AM too2 是） = = > 活動執行 1</span><span class="sxs-lookup"><span data-stu-id="0da85-149">hello data slice from hello first activity window (1 AM too2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="0da85-150">從第二個活動視窗 hello hello 資料配量 （2 AM too3 是） = = > 執行 2 活動。</span><span class="sxs-lookup"><span data-stu-id="0da85-150">hello data slice from hello second activity window (2 AM too3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="0da85-151">從第二個活動視窗 hello hello 資料配量 （3 AM too4 是） = = > 執行的活動 3</span><span class="sxs-lookup"><span data-stu-id="0da85-151">hello data slice from hello second activity window (3 AM too4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="0da85-152">依此類推。</span><span class="sxs-lookup"><span data-stu-id="0da85-152">And so on.</span></span>

<span data-ttu-id="0da85-153">在此範例中，當 hello**並行**設 too2，**活動執行 1**和**活動執行 2**資料複製兩個活動視窗**同時** tooimprove 資料移動的效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-153">In this example, when hello **concurrency** value is set too2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** tooimprove data movement performance.</span></span> <span data-ttu-id="0da85-154">不過，如果多個檔案會與活動執行 1 相關聯，hello 資料移動服務將檔案複製從 hello 來源 toohello 目的地一個檔案一次。</span><span class="sxs-lookup"><span data-stu-id="0da85-154">However, if multiple files are associated with Activity run 1, hello data movement service copies files from hello source toohello destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="0da85-155">雲端資料移動單位</span><span class="sxs-lookup"><span data-stu-id="0da85-155">Cloud data movement units</span></span>
<span data-ttu-id="0da85-156">A**雲端資料移動單位 (DMU)**量值會呈現 hello 乘冪 （CPU、 記憶體和網路資源配置的組合） 的 Data Factory 中的單一單位。</span><span class="sxs-lookup"><span data-stu-id="0da85-156">A **cloud data movement unit (DMU)** is a measure that represents hello power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="0da85-157">DMU 可用於雲端到雲端的複製作業，但不可用於混合式複製。</span><span class="sxs-lookup"><span data-stu-id="0da85-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="0da85-158">根據預設，資料處理站會使用單一雲端 DMU tooperform 執行單一複製活動。</span><span class="sxs-lookup"><span data-stu-id="0da85-158">By default, Data Factory uses a single cloud DMU tooperform a single Copy Activity run.</span></span> <span data-ttu-id="0da85-159">toooverride 此預設值，指定的值為 hello **cloudDataMovementUnits** ，如下所示的屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-159">toooverride this default, specify a value for hello **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="0da85-160">相關之效能改善的 hello 層級的資訊可能會收到時設定特定的複製來源與接收器的多個單位，請參閱 hello[效能參考](#performance-reference)。</span><span class="sxs-lookup"><span data-stu-id="0da85-160">For information about hello level of performance gain you might get when you configure more units for a specific copy source and sink, see hello [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="0da85-161">hello**允許的值**hello **cloudDataMovementUnits**屬性是 1 （預設值）、 2、 4、 8、 16、 32。</span><span class="sxs-lookup"><span data-stu-id="0da85-161">hello **allowed values** for hello **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="0da85-162">hello**雲端 DMUs 的實際數目**hello 複製作業會使用在執行階段會等於 tooor 小於 hello 設定值，根據資料模式。</span><span class="sxs-lookup"><span data-stu-id="0da85-162">hello **actual number of cloud DMUs** that hello copy operation uses at run time is equal tooor less than hello configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="0da85-163">如果您需要更多雲端 DMU 以提高輸送量，請連絡 [Azure 支援](https://azure.microsoft.com/support/)。</span><span class="sxs-lookup"><span data-stu-id="0da85-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="0da85-164">設定為 8 及更新版本的目前運作時，才您**複製多個檔案從 Blob 儲存體/Data Lake Store/Amazon S3/雲端 FTP/雲端 SFTP tooBlob 儲存體/Data Lake Store/Azure SQL Database**。</span><span class="sxs-lookup"><span data-stu-id="0da85-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP tooBlob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="0da85-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="0da85-165">parallelCopies</span></span>
<span data-ttu-id="0da85-166">您可以使用 hello **parallelCopies**屬性 tooindicate hello 您想複製活動 toouse 的平行處理原則。</span><span class="sxs-lookup"><span data-stu-id="0da85-166">You can use hello **parallelCopies** property tooindicate hello parallelism that you want Copy Activity toouse.</span></span> <span data-ttu-id="0da85-167">您可以將此屬性視為 hello 內可以從您的來源讀取或寫入 tooyour 接收資料存放區，以平行方式複製活動的執行緒數目上限。</span><span class="sxs-lookup"><span data-stu-id="0da85-167">You can think of this property as hello maximum number of threads within Copy Activity that can read from your source or write tooyour sink data stores in parallel.</span></span>

<span data-ttu-id="0da85-168">對於每個複製活動時執行，Data Factory 會決定 hello 數目平行複製 toouse toocopy 資料從 hello 來源資料存放區和 toohello 目的地資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-168">For each Copy Activity run, Data Factory determines hello number of parallel copies toouse toocopy data from hello source data store and toohello destination data store.</span></span> <span data-ttu-id="0da85-169">它會使用的平行複本的 hello 預設數目取決於 hello 的來源和接收您所使用的型別。</span><span class="sxs-lookup"><span data-stu-id="0da85-169">hello default number of parallel copies that it uses depends on hello type of source and sink that you are using.</span></span>  

| <span data-ttu-id="0da85-170">來源和接收</span><span class="sxs-lookup"><span data-stu-id="0da85-170">Source and sink</span></span> | <span data-ttu-id="0da85-171">由服務決定的預設平行複製計數</span><span class="sxs-lookup"><span data-stu-id="0da85-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="0da85-172">在檔案型存放區 (Blob 儲存體、Data Lake Store、Amazon S3、內部部署檔案系統、內部部署 HDFS) 之間複製資料</span><span class="sxs-lookup"><span data-stu-id="0da85-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="0da85-173">介於 1 到 32。</span><span class="sxs-lookup"><span data-stu-id="0da85-173">Between 1 and 32.</span></span> <span data-ttu-id="0da85-174">大小而定 hello hello 檔案和雲端資料移動單元 (DMUs) 的 hello 數目的兩個雲端資料存放區之間使用的 toocopy 資料或 hello 實體組態的 hello 閘道機器用於混合式複製 (toocopy 資料 tooor 從內部部署資料存放區).</span><span class="sxs-lookup"><span data-stu-id="0da85-174">Depends on hello size of hello files and hello number of cloud data movement units (DMUs) used toocopy data between two cloud data stores, or hello physical configuration of hello Gateway machine used for a hybrid copy (toocopy data tooor from an on-premises data store).</span></span> |
| <span data-ttu-id="0da85-175">將資料從複製**tooAzure 資料表儲存體的任何來源資料存放區**</span><span class="sxs-lookup"><span data-stu-id="0da85-175">Copy data from **any source data store tooAzure Table storage**</span></span> |<span data-ttu-id="0da85-176">4</span><span class="sxs-lookup"><span data-stu-id="0da85-176">4</span></span> |
| <span data-ttu-id="0da85-177">所有其他來源和接收組</span><span class="sxs-lookup"><span data-stu-id="0da85-177">All other source and sink pairs</span></span> |<span data-ttu-id="0da85-178">1</span><span class="sxs-lookup"><span data-stu-id="0da85-178">1</span></span> |

<span data-ttu-id="0da85-179">通常，hello 預設行為，應該能 hello 最佳輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-179">Usually, hello default behavior should give you hello best throughput.</span></span> <span data-ttu-id="0da85-180">不過，toocontrol hello 載入機器上裝載您的資料存放區或 tootune 複製的效能，您可能選擇 toooverride hello 預設值，然後指定一個值為 hello **parallelCopies**屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-180">However, toocontrol hello load on machines that host your data stores, or tootune copy performance, you may choose toooverride hello default value and specify a value for hello **parallelCopies** property.</span></span> <span data-ttu-id="0da85-181">hello 值必須介於 1 和 32 （兩者內含）。</span><span class="sxs-lookup"><span data-stu-id="0da85-181">hello value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="0da85-182">在執行階段，hello 獲得最佳效能，複製活動會使用值小於或等於 toohello 您所設定的值。</span><span class="sxs-lookup"><span data-stu-id="0da85-182">At run time, for hello best performance, Copy Activity uses a value that is less than or equal toohello value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="0da85-183">點 toonote:</span><span class="sxs-lookup"><span data-stu-id="0da85-183">Points toonote:</span></span>

* <span data-ttu-id="0da85-184">當您複製檔案為基礎的存放區之間的資料時，hello **parallelCopies**判斷 hello hello 檔案層級的平行處理原則。</span><span class="sxs-lookup"><span data-stu-id="0da85-184">When you copy data between file-based stores, hello **parallelCopies** determine hello parallelism at hello file level.</span></span> <span data-ttu-id="0da85-185">單一檔案中的 hello 區塊處理時會發生情況之下自動且明確地，和其設計目的是 toouse hello 最佳適合區塊大小的指定的來源資料存放區中平行和正交 tooparallelCopies 輸入 tooload 資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-185">hello chunking within a single file would happen underneath automatically and transparently, and it's designed toouse hello best suitable chunk size for a given source data store type tooload data in parallel and orthogonal tooparallelCopies.</span></span> <span data-ttu-id="0da85-186">hello 的平行複本 hello 資料移動服務會使用 hello 複製作業在執行階段是不超過您擁有的檔案的 hello 數目的實際數目。</span><span class="sxs-lookup"><span data-stu-id="0da85-186">hello actual number of parallel copies hello data movement service uses for hello copy operation at run time is no more than hello number of files you have.</span></span> <span data-ttu-id="0da85-187">如果 hello 複製行為**mergeFile**，複製活動無法充分利用檔案層級平行處理原則。</span><span class="sxs-lookup"><span data-stu-id="0da85-187">If hello copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="0da85-188">當您指定的值為 hello **parallelCopies**屬性，如果是混合式複製，請考慮在您的來源和接收的資料存放區和 toogateway hello 負載增加。</span><span class="sxs-lookup"><span data-stu-id="0da85-188">When you specify a value for hello **parallelCopies** property, consider hello load increase on your source and sink data stores, and toogateway if it is a hybrid copy.</span></span> <span data-ttu-id="0da85-189">發生這種情況特別是當您有多個活動或 hello 並行執行相同的活動執行 hello 相同資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-189">This happens especially when you have multiple activities or concurrent runs of hello same activities that run against hello same data store.</span></span> <span data-ttu-id="0da85-190">如果您注意到 hello 資料存放區或閘道爆 hello 負載，減少 hello **parallelCopies**值 toorelieve hello 負載。</span><span class="sxs-lookup"><span data-stu-id="0da85-190">If you notice that either hello data store or Gateway is overwhelmed with hello load, decrease hello **parallelCopies** value toorelieve hello load.</span></span>
* <span data-ttu-id="0da85-191">當您從存放區不是以檔案為基礎的檔案為基礎 toostores 複製資料時，hello 資料移動服務將會忽略 hello **parallelCopies**屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-191">When you copy data from stores that are not file-based toostores that are file-based, hello data movement service ignores hello **parallelCopies** property.</span></span> <span data-ttu-id="0da85-192">即使已指定平行處理原則，也不會套用於此案例。</span><span class="sxs-lookup"><span data-stu-id="0da85-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="0da85-193">您必須使用資料管理閘道器版本 1.11 或更新版本的 toouse hello **parallelCopies**功能，當您執行混合式複製。</span><span class="sxs-lookup"><span data-stu-id="0da85-193">You must use Data Management Gateway version 1.11 or later toouse hello **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="0da85-194">toobetter 使用這些兩個屬性和 tooenhance 您資料移動的輸送量，請參閱 hello[範例使用案例](#case-study-use-parallel-copy)。</span><span class="sxs-lookup"><span data-stu-id="0da85-194">toobetter use these two properties, and tooenhance your data movement throughput, see hello [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="0da85-195">您不需要 tooconfigure **parallelCopies** tootake 優點 hello 預設行為。</span><span class="sxs-lookup"><span data-stu-id="0da85-195">You don't need tooconfigure **parallelCopies** tootake advantage of hello default behavior.</span></span> <span data-ttu-id="0da85-196">如果您有設定且 **parallelCopies** 太小，將可能無法充分利用多個雲端 DMU。</span><span class="sxs-lookup"><span data-stu-id="0da85-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="0da85-197">計費影響</span><span class="sxs-lookup"><span data-stu-id="0da85-197">Billing impact</span></span>
<span data-ttu-id="0da85-198">它有**重要**向您收費的 tooremember 根據 hello hello 複製作業的時間總計。</span><span class="sxs-lookup"><span data-stu-id="0da85-198">It's **important** tooremember that you are charged based on hello total time of hello copy operation.</span></span> <span data-ttu-id="0da85-199">如果複製作業 tootake 一小時搭配使用雲端的一個單位，現在只需要四個雲端單位 15 分鐘 hello 整體帳單會維持幾乎 hello 相同。</span><span class="sxs-lookup"><span data-stu-id="0da85-199">If a copy job used tootake one hour with one cloud unit and now it takes 15 minutes with four cloud units, hello overall bill remains almost hello same.</span></span> <span data-ttu-id="0da85-200">例如，您使用 4 個雲端單位。</span><span class="sxs-lookup"><span data-stu-id="0da85-200">For example, you use four cloud units.</span></span> <span data-ttu-id="0da85-201">第一個雲端單位 hello 花費在 10 分鐘，hello 第二個，10 分鐘，hello 第三個，5 分鐘，hello 第四個的其中一個，所有在執行一個複製活動中的 5 分鐘。</span><span class="sxs-lookup"><span data-stu-id="0da85-201">hello first cloud unit spends 10 minutes, hello second one, 10 minutes, hello third one, 5 minutes, and hello fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="0da85-202">您必須支付 hello 總複製 （資料移動） 時間，也就是 10 + 10 + 5 + 5 = 30 分鐘。</span><span class="sxs-lookup"><span data-stu-id="0da85-202">You are charged for hello total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="0da85-203">是否使用 **parallelCopies** 對計費沒有任何影響。</span><span class="sxs-lookup"><span data-stu-id="0da85-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="0da85-204">分段複製</span><span class="sxs-lookup"><span data-stu-id="0da85-204">Staged copy</span></span>
<span data-ttu-id="0da85-205">當您複製資料來源建立資料存放區 tooa 接收資料存放區時，您可能會選擇 toouse Blob 儲存體做為暫時的臨時存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-205">When you copy data from a source data store tooa sink data store, you might choose toouse Blob storage as an interim staging store.</span></span> <span data-ttu-id="0da85-206">臨時區域是特別適用於下列情況下的 hello:</span><span class="sxs-lookup"><span data-stu-id="0da85-206">Staging is especially useful in hello following cases:</span></span>

1. <span data-ttu-id="0da85-207">**您想從各種資料存放區 tooingest 資料到 SQL 資料倉儲 PolyBase 透過**。</span><span class="sxs-lookup"><span data-stu-id="0da85-207">**You want tooingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="0da85-208">SQL 資料倉儲會使用 PolyBase，作為到 SQL 資料倉儲的高輸送量機制 tooload 大量的資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism tooload a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="0da85-209">不過，hello 來源資料必須在 Blob 儲存體，而且它必須符合其他準則。</span><span class="sxs-lookup"><span data-stu-id="0da85-209">However, hello source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="0da85-210">當您從 Blob 儲存體以外的資料存放區載入資料時，您可以啟用透過過渡暫存 Blob 儲存體的資料複製。</span><span class="sxs-lookup"><span data-stu-id="0da85-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="0da85-211">在此情況下，Data Factory 執行所需的 hello 資料轉換 tooensure 確定它符合 PolyBase hello 需求。</span><span class="sxs-lookup"><span data-stu-id="0da85-211">In that case, Data Factory performs hello required data transformations tooensure that it meets hello requirements of PolyBase.</span></span> <span data-ttu-id="0da85-212">然後它會使用 PolyBase tooload 資料到 SQL 資料倉儲。</span><span class="sxs-lookup"><span data-stu-id="0da85-212">Then it uses PolyBase tooload data into SQL Data Warehouse.</span></span> <span data-ttu-id="0da85-213">如需詳細資訊，請參閱[使用 PolyBase tooload 資料到 Azure SQL 資料倉儲](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)。</span><span class="sxs-lookup"><span data-stu-id="0da85-213">For more details, see [Use PolyBase tooload data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="0da85-214">如需使用案例的逐步解說，請參閱[使用 Azure Data Factory 在 15 分鐘內將 1 TB 載入至 Azure SQL 資料倉儲](data-factory-load-sql-data-warehouse.md)。</span><span class="sxs-lookup"><span data-stu-id="0da85-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="0da85-215">**有時它需要一些時間 tooperform 混合資料移動 (也就是在內部部署資料存放區與雲端資料存放區之間 toocopy) 透過低速網路連線**。</span><span class="sxs-lookup"><span data-stu-id="0da85-215">**Sometimes it takes a while tooperform a hybrid data movement (that is, toocopy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="0da85-216">tooimprove 效能，您可以壓縮的 hello 內部資料，使其接受 toomove 資料 toohello 臨時資料存放區 hello 雲端中的時間。</span><span class="sxs-lookup"><span data-stu-id="0da85-216">tooimprove performance, you can compress hello data on-premises so that it takes less time toomove data toohello staging data store in hello cloud.</span></span> <span data-ttu-id="0da85-217">然後您可以解壓縮 hello hello 執行之前載入 hello 目的地資料存放區的存放區中的資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-217">Then you can decompress hello data in hello staging store before you load it into hello destination data store.</span></span>
3. <span data-ttu-id="0da85-218">**您不想 tooopen 連接埠以外的連接埠 80 和由於公司的 IT 原則的連接埠 443，在您的防火牆，**。</span><span class="sxs-lookup"><span data-stu-id="0da85-218">**You don't want tooopen ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="0da85-219">例如，當您從內部部署資料存放區 tooan Azure SQL Database 接收或 Azure SQL 資料倉儲接收複製資料，您需要 tooactivate 連出 TCP 通訊埠 1433年上的 hello Windows 防火牆和在公司防火牆。</span><span class="sxs-lookup"><span data-stu-id="0da85-219">For example, when you copy data from an on-premises data store tooan Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need tooactivate outbound TCP communication on port 1433 for both hello Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="0da85-220">在此案例中，利用 hello 閘道 toofirst 複製資料 tooa Blob 儲存體預備執行個體透過 HTTP 或 HTTPS 連接埠 443。</span><span class="sxs-lookup"><span data-stu-id="0da85-220">In this scenario, take advantage of hello gateway toofirst copy data tooa Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="0da85-221">然後，hello 將資料載入 SQL Database 或 SQL 資料倉儲從 Blob 儲存體臨時區域。</span><span class="sxs-lookup"><span data-stu-id="0da85-221">Then, load hello data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="0da85-222">在此流程，您不需要 tooenable 通訊埠 1433年。</span><span class="sxs-lookup"><span data-stu-id="0da85-222">In this flow, you don't need tooenable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="0da85-223">分段複製的運作方式</span><span class="sxs-lookup"><span data-stu-id="0da85-223">How staged copy works</span></span>
<span data-ttu-id="0da85-224">當您啟用 hello 暫存功能時，第一個 hello 會資料從複製 hello 來源資料存放區 toohello 暫存資料存放區 （攜帶您自己）。</span><span class="sxs-lookup"><span data-stu-id="0da85-224">When you activate hello staging feature, first hello data is copied from hello source data store toohello staging data store (bring your own).</span></span> <span data-ttu-id="0da85-225">接下來，從 hello 暫存資料存放區 toohello 接收資料存放區複製 hello 資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-225">Next, hello data is copied from hello staging data store toohello sink data store.</span></span> <span data-ttu-id="0da85-226">Data Factory 自動管理您的 hello 兩階段流程。</span><span class="sxs-lookup"><span data-stu-id="0da85-226">Data Factory automatically manages hello two-stage flow for you.</span></span> <span data-ttu-id="0da85-227">Data Factory 也會清除從 hello hello 資料移動完成之後，暫存儲存體的暫存資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-227">Data Factory also cleans up temporary data from hello staging storage after hello data movement is complete.</span></span>

<span data-ttu-id="0da85-228">在 hello 雲端複製案例 （來源和接收的資料存放區是 hello 雲端中），不會使用閘道。</span><span class="sxs-lookup"><span data-stu-id="0da85-228">In hello cloud copy scenario (both source and sink data stores are in hello cloud), gateway is not used.</span></span> <span data-ttu-id="0da85-229">hello Data Factory 服務會執行 hello 複製作業。</span><span class="sxs-lookup"><span data-stu-id="0da85-229">hello Data Factory service performs hello copy operations.</span></span>

![分段複製：雲端案例](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="0da85-231">在 hello 混合式案例中複製 （來源是在內部部署和接收器是 hello 雲端中） hello 閘道才會移動 hello 來源資料中的資料存放區 tooa 暫存資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-231">In hello hybrid copy scenario (source is on-premises and sink is in hello cloud), hello gateway moves data from hello source data store tooa staging data store.</span></span> <span data-ttu-id="0da85-232">資料處理站服務移從 hello 暫存資料的資料存放區 toohello 接收資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-232">Data Factory service moves data from hello staging data store toohello sink data store.</span></span> <span data-ttu-id="0da85-233">資料複製到雲端資料儲存區 tooan 內部部署資料存放區透過臨時區域也支援 hello 反轉流程。</span><span class="sxs-lookup"><span data-stu-id="0da85-233">Copying data from a cloud data store tooan on-premises data store via staging also is supported with hello reversed flow.</span></span>

![分段複製：混合式案例](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="0da85-235">當您使用的暫存儲存區啟動資料移動時，您可以指定是否要讓 hello 資料 toobe 之前先將資料從 hello 來源資料儲存 tooan 暫時的或暫存資料存放區，然後再將資料從暫時移解壓縮壓縮或暫存資料存放區 toohello 接收資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-235">When you activate data movement by using a staging store, you can specify whether you want hello data toobe compressed before moving data from hello source data store tooan interim or staging data store, and then decompressed before moving data from an interim or staging data store toohello sink data store.</span></span>

<span data-ttu-id="0da85-236">目前您還無法使用暫存存放區在兩個內部部署資料存放區之間複製資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="0da85-237">我們希望能使用這個選項 toobe 推出。</span><span class="sxs-lookup"><span data-stu-id="0da85-237">We expect this option toobe available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="0da85-238">組態</span><span class="sxs-lookup"><span data-stu-id="0da85-238">Configuration</span></span>
<span data-ttu-id="0da85-239">設定 hello **enableStaging**是否要先載入目的地資料存放區，暫置在 Blob 儲存體中的 hello 資料 toobe 在複製活動 toospecify 設定。</span><span class="sxs-lookup"><span data-stu-id="0da85-239">Configure hello **enableStaging** setting in Copy Activity toospecify whether you want hello data toobe staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="0da85-240">當您將**enableStaging** tooTRUE，指定 hello hello 下一個表格中列出的其他屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-240">When you set **enableStaging** tooTRUE, specify hello additional properties listed in hello next table.</span></span> <span data-ttu-id="0da85-241">如果您沒有帳戶，您也需要 toocreate Azure 儲存體或存放裝置共用存取簽章連結服務的預備環境。</span><span class="sxs-lookup"><span data-stu-id="0da85-241">If you don’t have one, you also need toocreate an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="0da85-242">屬性</span><span class="sxs-lookup"><span data-stu-id="0da85-242">Property</span></span> | <span data-ttu-id="0da85-243">說明</span><span class="sxs-lookup"><span data-stu-id="0da85-243">Description</span></span> | <span data-ttu-id="0da85-244">預設值</span><span class="sxs-lookup"><span data-stu-id="0da85-244">Default value</span></span> | <span data-ttu-id="0da85-245">必要</span><span class="sxs-lookup"><span data-stu-id="0da85-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="0da85-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="0da85-246">**enableStaging**</span></span> |<span data-ttu-id="0da85-247">指定是否要透過暫存存放區暫時 toocopy 資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-247">Specify whether you want toocopy data via an interim staging store.</span></span> |<span data-ttu-id="0da85-248">False</span><span class="sxs-lookup"><span data-stu-id="0da85-248">False</span></span> |<span data-ttu-id="0da85-249">否</span><span class="sxs-lookup"><span data-stu-id="0da85-249">No</span></span> |
| <span data-ttu-id="0da85-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="0da85-250">**linkedServiceName**</span></span> |<span data-ttu-id="0da85-251">指定 hello 名稱[AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service)或[AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service)連結服務，它會參考您做為暫時的臨時存放區的儲存體 toohello 執行個體。</span><span class="sxs-lookup"><span data-stu-id="0da85-251">Specify hello name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers toohello instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="0da85-252">您無法使用共用的存取簽章 tooload 資料儲存到透過 PolyBase 的 SQL 資料倉儲。</span><span class="sxs-lookup"><span data-stu-id="0da85-252">You cannot use Storage with a shared access signature tooload data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="0da85-253">您可以將它用於其他所有案例。</span><span class="sxs-lookup"><span data-stu-id="0da85-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="0da85-254">N/A</span><span class="sxs-lookup"><span data-stu-id="0da85-254">N/A</span></span> |<span data-ttu-id="0da85-255">是，當**enableStaging**設定 tooTRUE</span><span class="sxs-lookup"><span data-stu-id="0da85-255">Yes, when **enableStaging** is set tooTRUE</span></span> |
| <span data-ttu-id="0da85-256">**路徑**</span><span class="sxs-lookup"><span data-stu-id="0da85-256">**path**</span></span> |<span data-ttu-id="0da85-257">指定您想要 toocontain hello 接移資料 hello Blob 儲存體路徑。</span><span class="sxs-lookup"><span data-stu-id="0da85-257">Specify hello Blob storage path that you want toocontain hello staged data.</span></span> <span data-ttu-id="0da85-258">如果您未提供路徑，hello 服務會建立容器 toostore 暫存資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-258">If you do not provide a path, hello service creates a container toostore temporary data.</span></span> <br/><br/> <span data-ttu-id="0da85-259">只有當您使用存放裝置使用共用的存取簽章，或您需要在特定位置的暫存資料 toobe 指定的路徑。</span><span class="sxs-lookup"><span data-stu-id="0da85-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data toobe in a specific location.</span></span> |<span data-ttu-id="0da85-260">N/A</span><span class="sxs-lookup"><span data-stu-id="0da85-260">N/A</span></span> |<span data-ttu-id="0da85-261">否</span><span class="sxs-lookup"><span data-stu-id="0da85-261">No</span></span> |
| <span data-ttu-id="0da85-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="0da85-262">**enableCompression**</span></span> |<span data-ttu-id="0da85-263">指定複製的 toohello 目的地之前，是否應該壓縮資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-263">Specifies whether data should be compressed before it is copied toohello destination.</span></span> <span data-ttu-id="0da85-264">此設定可減少 hello 磁碟區所傳送的資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-264">This setting reduces hello volume of data being transferred.</span></span> |<span data-ttu-id="0da85-265">False</span><span class="sxs-lookup"><span data-stu-id="0da85-265">False</span></span> |<span data-ttu-id="0da85-266">否</span><span class="sxs-lookup"><span data-stu-id="0da85-266">No</span></span> |

<span data-ttu-id="0da85-267">以下是範例的定義複製活動與 hello 屬性 hello 前面表格中所述：</span><span class="sxs-lookup"><span data-stu-id="0da85-267">Here's a sample definition of Copy Activity with hello properties that are described in hello preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="0da85-268">計費影響</span><span class="sxs-lookup"><span data-stu-id="0da85-268">Billing impact</span></span>
<span data-ttu-id="0da85-269">我們將會根據兩個步驟向您收費：複製持續時間和複製類型。</span><span class="sxs-lookup"><span data-stu-id="0da85-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="0da85-270">當您使用暫存期間雲端複製 （資料從雲端資料儲存區 tooanother 雲端資料存放區），您需要付費 hello [步驟 1 和步驟 2 複製的持續時間的加總] x [雲端複製單價]。</span><span class="sxs-lookup"><span data-stu-id="0da85-270">When you use staging during a cloud copy (copying data from a cloud data store tooanother cloud data store), you are charged hello [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="0da85-271">當您使用暫存期間混合式複製 （資料從內部部署資料存放區 tooa 雲端資料存放區），您將支付 [混合式複製持續時間] x [混合式複製單價] + [雲端複製持續時間] x [雲端複製單價]。</span><span class="sxs-lookup"><span data-stu-id="0da85-271">When you use staging during a hybrid copy (copying data from an on-premises data store tooa cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="0da85-272">效能微調步驟</span><span class="sxs-lookup"><span data-stu-id="0da85-272">Performance tuning steps</span></span>
<span data-ttu-id="0da85-273">我們建議您採取下列步驟複製活動的 Data Factory 服務 tootune hello 效能：</span><span class="sxs-lookup"><span data-stu-id="0da85-273">We suggest that you take these steps tootune hello performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="0da85-274">**建立基準**。</span><span class="sxs-lookup"><span data-stu-id="0da85-274">**Establish a baseline**.</span></span> <span data-ttu-id="0da85-275">Hello 開發階段，請針對代表性資料樣本使用複製活動以測試您的管線。</span><span class="sxs-lookup"><span data-stu-id="0da85-275">During hello development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="0da85-276">您可以使用 Data Factory hello[配量模型](data-factory-scheduling-and-execution.md)toolimit hello 您使用的資料量。</span><span class="sxs-lookup"><span data-stu-id="0da85-276">You can use hello Data Factory [slicing model](data-factory-scheduling-and-execution.md) toolimit hello amount of data you work with.</span></span>

   <span data-ttu-id="0da85-277">收集執行時間和效能特性，使用 hello**監視及管理應用程式**。</span><span class="sxs-lookup"><span data-stu-id="0da85-277">Collect execution time and performance characteristics by using hello **Monitoring and Management App**.</span></span> <span data-ttu-id="0da85-278">在 Data Factory 首頁上選擇 [監視及管理]。</span><span class="sxs-lookup"><span data-stu-id="0da85-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="0da85-279">在 hello 樹狀結構檢視中，選擇 hello**輸出資料集**。</span><span class="sxs-lookup"><span data-stu-id="0da85-279">In hello tree view, choose hello **output dataset**.</span></span> <span data-ttu-id="0da85-280">在 hello**活動 Windows**清單中，選擇 hello 複製活動執行。</span><span class="sxs-lookup"><span data-stu-id="0da85-280">In hello **Activity Windows** list, choose hello Copy Activity run.</span></span> <span data-ttu-id="0da85-281">**活動 Windows**列出 hello 複製活動持續時間和 hello hello 複製的資料大小。</span><span class="sxs-lookup"><span data-stu-id="0da85-281">**Activity Windows** lists hello Copy Activity duration and hello size of hello data that's copied.</span></span> <span data-ttu-id="0da85-282">hello 輸送量會列在**活動視窗總管**。</span><span class="sxs-lookup"><span data-stu-id="0da85-282">hello throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="0da85-283">toolearn 進一步了解 hello 應用程式，請參閱[監視和管理 Azure Data Factory 管線使用 hello 監視及管理應用程式](data-factory-monitor-manage-app.md)。</span><span class="sxs-lookup"><span data-stu-id="0da85-283">toolearn more about hello app, see [Monitor and manage Azure Data Factory pipelines by using hello Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![活動執行詳細資料](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="0da85-285">稍後在 hello 文章中，您可以比較 hello 效能和設定您的案例 tooCopy 活動的[效能參考](#performance-reference)從我們的測試。</span><span class="sxs-lookup"><span data-stu-id="0da85-285">Later in hello article, you can compare hello performance and configuration of your scenario tooCopy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="0da85-286">**效能診斷與最佳化**。</span><span class="sxs-lookup"><span data-stu-id="0da85-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="0da85-287">如果您觀察到的 hello 效能不符合您的預期，您會需要 tooidentify 效能瓶頸。</span><span class="sxs-lookup"><span data-stu-id="0da85-287">If hello performance you observe doesn't meet your expectations, you need tooidentify performance bottlenecks.</span></span> <span data-ttu-id="0da85-288">然後，最佳化效能 tooremove 或降低瓶頸的 hello 造成影響。</span><span class="sxs-lookup"><span data-stu-id="0da85-288">Then, optimize performance tooremove or reduce hello effect of bottlenecks.</span></span> <span data-ttu-id="0da85-289">效能診斷的完整說明超出本文的 hello 範圍，但以下是一些常見的考量：</span><span class="sxs-lookup"><span data-stu-id="0da85-289">A full description of performance diagnosis is beyond hello scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="0da85-290">效能功能︰</span><span class="sxs-lookup"><span data-stu-id="0da85-290">Performance features:</span></span>
     * [<span data-ttu-id="0da85-291">平行複製</span><span class="sxs-lookup"><span data-stu-id="0da85-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="0da85-292">雲端資料移動單位</span><span class="sxs-lookup"><span data-stu-id="0da85-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="0da85-293">分段複製</span><span class="sxs-lookup"><span data-stu-id="0da85-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="0da85-294">資料管理閘道延展性</span><span class="sxs-lookup"><span data-stu-id="0da85-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="0da85-295">資料管理閘道</span><span class="sxs-lookup"><span data-stu-id="0da85-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="0da85-296">來源</span><span class="sxs-lookup"><span data-stu-id="0da85-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="0da85-297">接收</span><span class="sxs-lookup"><span data-stu-id="0da85-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="0da85-298">序列化和還原序列化</span><span class="sxs-lookup"><span data-stu-id="0da85-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="0da85-299">壓縮</span><span class="sxs-lookup"><span data-stu-id="0da85-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="0da85-300">資料行對應</span><span class="sxs-lookup"><span data-stu-id="0da85-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="0da85-301">其他考量</span><span class="sxs-lookup"><span data-stu-id="0da85-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="0da85-302">**展開 hello 組態 tooyour 整個資料集**。</span><span class="sxs-lookup"><span data-stu-id="0da85-302">**Expand hello configuration tooyour entire data set**.</span></span> <span data-ttu-id="0da85-303">當您滿意 hello 執行結果及效能時，您可以展開 hello 定義與管線使用中週期 toocover 您整個資料集。</span><span class="sxs-lookup"><span data-stu-id="0da85-303">When you're satisfied with hello execution results and performance, you can expand hello definition and pipeline active period toocover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="0da85-304">資料管理閘道的考量</span><span class="sxs-lookup"><span data-stu-id="0da85-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="0da85-305">**閘道安裝**： 我們建議您使用專用的電腦 toohost 資料管理閘道器。</span><span class="sxs-lookup"><span data-stu-id="0da85-305">**Gateway setup**: We recommend that you use a dedicated machine toohost Data Management Gateway.</span></span> <span data-ttu-id="0da85-306">請參閱[使用資料管理閘道的考量](data-factory-data-management-gateway.md#considerations-for-using-gateway)。</span><span class="sxs-lookup"><span data-stu-id="0da85-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="0da85-307">**監視閘道和向上/外**： 單一邏輯閘道與一或多個閘道節點可以提供多個複製活動就會在 hello 相同時間同時。</span><span class="sxs-lookup"><span data-stu-id="0da85-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at hello same time concurrently.</span></span> <span data-ttu-id="0da85-308">您可以檢視幾乎是即時的資源使用情況 (CPU、 記憶體、 network(in/out) 等) 的快照集，以及執行與 hello Azure 入口網站中限制的並行處理作業的 hello 數目看到在閘道機器上[hello 入口網站中的監視閘道](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="0da85-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as hello number of concurrent jobs running versus limit in hello Azure portal, see [Monitor gateway in hello portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="0da85-309">如果在混合式資料移動使用大量的並行複製活動執行或大量的資料 toocopy 上有大量的需要，請考慮太[向上延展還是向外閘道延展](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations)，toobetter 以利用您的資源或tooprovision 更多資源 tooempower 複製。</span><span class="sxs-lookup"><span data-stu-id="0da85-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data toocopy, consider too[scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as toobetter utilize your resource or tooprovision more resource tooempower copy.</span></span> 

## <a name="considerations-for-hello-source"></a><span data-ttu-id="0da85-310">Hello 來源的考量</span><span class="sxs-lookup"><span data-stu-id="0da85-310">Considerations for hello source</span></span>
### <a name="general"></a><span data-ttu-id="0da85-311">一般</span><span class="sxs-lookup"><span data-stu-id="0da85-311">General</span></span>
<span data-ttu-id="0da85-312">請務必的或對它執行其他工作負載不爆該 hello 基礎資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-312">Be sure that hello underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="0da85-313">Microsoft 資料存放區，請參閱[監視及調整主題](#performance-reference)屬於特定 toodata 存放區和幫助您了解資料存放區效能特性、 回應時間降到最低和最大化輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific toodata stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="0da85-314">如果您將資料複製 Blob 儲存體 tooSQL 資料倉儲時，請考慮使用**PolyBase** tooboost 效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-314">If you copy data from Blob storage tooSQL Data Warehouse, consider using **PolyBase** tooboost performance.</span></span> <span data-ttu-id="0da85-315">請參閱[使用 PolyBase tooload 資料到 Azure SQL 資料倉儲](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)如需詳細資訊。</span><span class="sxs-lookup"><span data-stu-id="0da85-315">See [Use PolyBase tooload data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="0da85-316">如需使用案例的逐步解說，請參閱[使用 Azure Data Factory 在 15 分鐘內將 1 TB 載入至 Azure SQL 資料倉儲](data-factory-load-sql-data-warehouse.md)。</span><span class="sxs-lookup"><span data-stu-id="0da85-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="0da85-317">以檔案為基礎的資料存放區</span><span class="sxs-lookup"><span data-stu-id="0da85-317">File-based data stores</span></span>
<span data-ttu-id="0da85-318">*(包括 Blob 儲存體、Data Lake Store、Amazon S3、內部部署檔案系統及內部部署 HDFS)*</span><span class="sxs-lookup"><span data-stu-id="0da85-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="0da85-319">**平均檔案大小和檔案計數**：複製活動會一次傳送一個檔案的資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="0da85-320">以相同數量的資料 toobe 移動的 hello，hello 整體輸送量較低 hello 資料若包含許多小檔案，而不是因為 toohello 啟動程序階段中的每個檔案的幾個大型檔案。</span><span class="sxs-lookup"><span data-stu-id="0da85-320">With hello same amount of data toobe moved, hello overall throughput is lower if hello data consists of many small files rather than a few large files due toohello bootstrap phase for each file.</span></span> <span data-ttu-id="0da85-321">因此，可能的話，請將小型檔案合併較大檔案 toogain 較高的輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-321">Therefore, if possible, combine small files into larger files toogain higher throughput.</span></span>
* <span data-ttu-id="0da85-322">**檔案格式與壓縮**： 更多方式 tooimprove 效能，請參閱 hello[序列化和還原序列化的考量](#considerations-for-serialization-and-deserialization)和[考量壓縮](#considerations-for-compression)區段。</span><span class="sxs-lookup"><span data-stu-id="0da85-322">**File format and compression**: For more ways tooimprove performance, see hello [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="0da85-323">Hello**在內部部署檔案系統**案例中的，在其中**資料管理閘道器**是必要，請參閱 hello[資料管理閘道器的考量](#considerations-for-data-management-gateway)> 一節。</span><span class="sxs-lookup"><span data-stu-id="0da85-323">For hello **on-premises file system** scenario, in which **Data Management Gateway** is required, see hello [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="0da85-324">關聯式資料存放區</span><span class="sxs-lookup"><span data-stu-id="0da85-324">Relational data stores</span></span>
<span data-ttu-id="0da85-325">*(包括 SQL Database、SQL 資料倉儲、Amazon Redshift、SQL Server 資料庫，以及 Oracle、MySQL、DB2、Teradata、Sybase 和 PostgreSQL 資料庫等)*</span><span class="sxs-lookup"><span data-stu-id="0da85-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="0da85-326">**資料模式**︰資料表結構描述對複製輸送量會有影響。</span><span class="sxs-lookup"><span data-stu-id="0da85-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="0da85-327">大型資料列大小可讓您更佳的效能比小型資料列大小，toocopy hello 相同的資料量。</span><span class="sxs-lookup"><span data-stu-id="0da85-327">A large row size gives you a better performance than small row size, toocopy hello same amount of data.</span></span> <span data-ttu-id="0da85-328">hello 原因是該 hello 資料庫可以更有效率地擷取較少的批次包含較少的資料列的資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-328">hello reason is that hello database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="0da85-329">**查詢或預存程序**： 最佳化 hello 查詢或預存程序更有效率地指定 hello 複製活動來源 toofetch 資料中的 hello 邏輯。</span><span class="sxs-lookup"><span data-stu-id="0da85-329">**Query or stored procedure**: Optimize hello logic of hello query or stored procedure you specify in hello Copy Activity source toofetch data more efficiently.</span></span>
* <span data-ttu-id="0da85-330">如**在內部部署關聯式資料庫**，例如 SQL Server 和 Oracle，需要使用 hello**資料管理閘道器**，請參閱 hello[資料管理閘道器的考量](#considerations-on-data-management-gateway) > 一節。</span><span class="sxs-lookup"><span data-stu-id="0da85-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require hello use of **Data Management Gateway**, see hello [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-hello-sink"></a><span data-ttu-id="0da85-331">Hello 接收的考量</span><span class="sxs-lookup"><span data-stu-id="0da85-331">Considerations for hello sink</span></span>
### <a name="general"></a><span data-ttu-id="0da85-332">一般</span><span class="sxs-lookup"><span data-stu-id="0da85-332">General</span></span>
<span data-ttu-id="0da85-333">請務必的或對它執行其他工作負載不爆該 hello 基礎資料存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-333">Be sure that hello underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="0da85-334">Microsoft 資料存放區，請參閱太[監視及調整主題](#performance-reference)屬於特定 toodata 存放區。</span><span class="sxs-lookup"><span data-stu-id="0da85-334">For Microsoft data stores, refer too[monitoring and tuning topics](#performance-reference) that are specific toodata stores.</span></span> <span data-ttu-id="0da85-335">這些主題可協助您了解資料存放區效能特性，以及如何 toominimize 回應逾時和最大化輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-335">These topics can help you understand data store performance characteristics and how toominimize response times and maximize throughput.</span></span>

<span data-ttu-id="0da85-336">如果您要複製的資料**Blob 儲存體**太**SQL 資料倉儲**，請考慮使用**PolyBase** tooboost 效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-336">If you are copying data from **Blob storage** too**SQL Data Warehouse**, consider using **PolyBase** tooboost performance.</span></span> <span data-ttu-id="0da85-337">請參閱[使用 PolyBase tooload 資料到 Azure SQL 資料倉儲](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)如需詳細資訊。</span><span class="sxs-lookup"><span data-stu-id="0da85-337">See [Use PolyBase tooload data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="0da85-338">如需使用案例的逐步解說，請參閱[使用 Azure Data Factory 在 15 分鐘內將 1 TB 載入至 Azure SQL 資料倉儲](data-factory-load-sql-data-warehouse.md)。</span><span class="sxs-lookup"><span data-stu-id="0da85-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="0da85-339">以檔案為基礎的資料存放區</span><span class="sxs-lookup"><span data-stu-id="0da85-339">File-based data stores</span></span>
<span data-ttu-id="0da85-340">*(包括 Blob 儲存體、Data Lake Store、Amazon S3、內部部署檔案系統及內部部署 HDFS)*</span><span class="sxs-lookup"><span data-stu-id="0da85-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="0da85-341">**複製行為**： 如果您從不同的檔案為基礎的資料存放區複製資料，複製活動有三個選項，透過 hello **copyBehavior**屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via hello **copyBehavior** property.</span></span> <span data-ttu-id="0da85-342">它會保留階層、扁平化階層或合併檔案。</span><span class="sxs-lookup"><span data-stu-id="0da85-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="0da85-343">保留或是扁平化階層有少量或沒有效能額外負荷，但合併檔案會造成效能負擔 tooincrease。</span><span class="sxs-lookup"><span data-stu-id="0da85-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead tooincrease.</span></span>
* <span data-ttu-id="0da85-344">**檔案格式與壓縮**： 請參閱 hello[序列化和還原序列化的考量](#considerations-for-serialization-and-deserialization)和[壓縮的考量](#considerations-for-compression)更方式 tooimprove 高效能的章節.</span><span class="sxs-lookup"><span data-stu-id="0da85-344">**File format and compression**: See hello [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways tooimprove performance.</span></span>
* <span data-ttu-id="0da85-345">**Blob 儲存體**：Blob 儲存體目前只支援以區塊 Blob 來最佳化資料傳送和輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="0da85-346">如**在內部部署檔案系統**需要 hello 使用案例**資料管理閘道器**，請參閱 hello[資料管理閘道器的考量](#considerations-for-data-management-gateway)> 一節。</span><span class="sxs-lookup"><span data-stu-id="0da85-346">For **on-premises file systems** scenarios that require hello use of **Data Management Gateway**, see hello [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="0da85-347">關聯式資料存放區</span><span class="sxs-lookup"><span data-stu-id="0da85-347">Relational data stores</span></span>
<span data-ttu-id="0da85-348">*(包括 SQL Database、SQL 資料倉儲、SQL Server 資料庫及 Oracle 資料庫)*</span><span class="sxs-lookup"><span data-stu-id="0da85-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="0da85-349">**複製行為**： 根據您所設定的 hello 屬性**sqlSink**，複製活動中不同的方式寫入資料 toohello 目的地資料庫。</span><span class="sxs-lookup"><span data-stu-id="0da85-349">**Copy behavior**: Depending on hello properties you've set for **sqlSink**, Copy Activity writes data toohello destination database in different ways.</span></span>
  * <span data-ttu-id="0da85-350">根據預設，hello 資料移動服務會使用中的 hello 大量複製 API tooinsert 資料附加模式中，可提供 hello 達到最佳效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-350">By default, hello data movement service uses hello Bulk Copy API tooinsert data in append mode, which provides hello best performance.</span></span>
  * <span data-ttu-id="0da85-351">如果您在 hello 接收器設定預存程序，hello 資料庫就會套用 hello 資料的一個資料列一次而不是為大量載入。</span><span class="sxs-lookup"><span data-stu-id="0da85-351">If you configure a stored procedure in hello sink, hello database applies hello data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="0da85-352">因此效能會大幅降低。</span><span class="sxs-lookup"><span data-stu-id="0da85-352">Performance drops significantly.</span></span> <span data-ttu-id="0da85-353">如果您的資料集很大，如果適用的話，請考慮切換 toousing hello **sqlWriterCleanupScript**屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-353">If your data set is large, when applicable, consider switching toousing hello **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="0da85-354">如果您設定 hello **sqlWriterCleanupScript**執行每個複製活動的屬性、 hello 服務觸發程序 hello 指令碼，並使用 hello 大量複製 API tooinsert hello 資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-354">If you configure hello **sqlWriterCleanupScript** property for each Copy Activity run, hello service triggers hello script, and then you use hello Bulk Copy API tooinsert hello data.</span></span> <span data-ttu-id="0da85-355">例如，toooverwrite hello 整個資料表 hello 最新的資料，您可以指定指令碼 toofirst hello 來源中刪除大量載入 hello 新資料之前的所有記錄。</span><span class="sxs-lookup"><span data-stu-id="0da85-355">For example, toooverwrite hello entire table with hello latest data, you can specify a script toofirst delete all records before bulk-loading hello new data from hello source.</span></span>
* <span data-ttu-id="0da85-356">**資料模式和批次大小**：</span><span class="sxs-lookup"><span data-stu-id="0da85-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="0da85-357">資料表結構描述對複製輸送量會有影響。</span><span class="sxs-lookup"><span data-stu-id="0da85-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="0da85-358">toocopy hello 相同的資料量，大型資料列大小可讓您更佳的效能比小型資料列大小因為 hello 資料庫可以更有效率地認可的資料較少的批次。</span><span class="sxs-lookup"><span data-stu-id="0da85-358">toocopy hello same amount of data, a large row size gives you better performance than a small row size because hello database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="0da85-359">複製活動會以一系列的批次插入資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="0da85-360">您也可以使用 hello 批次中設定的資料列的 hello 數目**叫用 writeBatchSize**屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-360">You can set hello number of rows in a batch by using hello **writeBatchSize** property.</span></span> <span data-ttu-id="0da85-361">如果您的資料有小型的資料列，您可以設定 hello**叫用 writeBatchSize**屬性與更高的值 toobenefit 從批次額外負荷較低 」 和 「 較高的輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-361">If your data has small rows, you can set hello **writeBatchSize** property with a higher value toobenefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="0da85-362">如果 hello 資料列大小的資料很大，請小心增加**叫用 writeBatchSize**。</span><span class="sxs-lookup"><span data-stu-id="0da85-362">If hello row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="0da85-363">較高的值可能會導致多載 hello 資料庫所致 tooa 複製失敗。</span><span class="sxs-lookup"><span data-stu-id="0da85-363">A high value might lead tooa copy failure caused by overloading hello database.</span></span>
* <span data-ttu-id="0da85-364">如**在內部部署關聯式資料庫**，如 SQL Server 和 Oracle 需要 hello 使用**資料管理閘道器**，請參閱 hello[資料管理閘道器的考量](#considerations-for-data-management-gateway) > 一節。</span><span class="sxs-lookup"><span data-stu-id="0da85-364">For **on-premises relational databases** like SQL Server and Oracle, which require hello use of **Data Management Gateway**, see hello [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="0da85-365">NoSQL 存放區</span><span class="sxs-lookup"><span data-stu-id="0da85-365">NoSQL stores</span></span>
<span data-ttu-id="0da85-366">(包括表格儲存體和 Azure Cosmos DB)</span><span class="sxs-lookup"><span data-stu-id="0da85-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="0da85-367">針對 **表格儲存體**：</span><span class="sxs-lookup"><span data-stu-id="0da85-367">For **Table storage**:</span></span>
  * <span data-ttu-id="0da85-368">**資料分割**： 撰寫資料 toointerleaved 分割大幅降低效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-368">**Partition**: Writing data toointerleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="0da85-369">資料分割索引鍵所排序您的來源資料，使得 hello 資料插入有效率地一個分割區之後，或調整 hello 邏輯 toowrite hello 資料 tooa 單一資料分割。</span><span class="sxs-lookup"><span data-stu-id="0da85-369">Sort your source data by partition key so that hello data is inserted efficiently into one partition after another, or adjust hello logic toowrite hello data tooa single partition.</span></span>
* <span data-ttu-id="0da85-370">針對 **Azure Cosmos DB**：</span><span class="sxs-lookup"><span data-stu-id="0da85-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="0da85-371">**批次大小**: hello**叫用 writeBatchSize**屬性會設定平行要求的 hello 數目 toohello Azure Cosmos DB 服務 toocreate 文件。</span><span class="sxs-lookup"><span data-stu-id="0da85-371">**Batch size**: hello **writeBatchSize** property sets hello number of parallel requests toohello Azure Cosmos DB service toocreate documents.</span></span> <span data-ttu-id="0da85-372">您可以預期更佳的效能，當您增加**叫用 writeBatchSize**因為多個平行的要求會傳送 tooAzure Cosmos DB。</span><span class="sxs-lookup"><span data-stu-id="0da85-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent tooAzure Cosmos DB.</span></span> <span data-ttu-id="0da85-373">不過，當您撰寫 tooAzure Cosmos DB 節流監看 （hello 錯誤訊息為 「 要求率非常大 」）。</span><span class="sxs-lookup"><span data-stu-id="0da85-373">However, watch for throttling when you write tooAzure Cosmos DB (hello error message is "Request rate is large").</span></span> <span data-ttu-id="0da85-374">各種因素會造成節流設定，包括文件大小 hello 詞彙數目的 hello 文件，並且 hello 目標集合的編製索引原則。</span><span class="sxs-lookup"><span data-stu-id="0da85-374">Various factors can cause throttling, including document size, hello number of terms in hello documents, and hello target collection's indexing policy.</span></span> <span data-ttu-id="0da85-375">tooachieve 較高的複製輸送量，請考慮使用較佳的集合，例如 S3。</span><span class="sxs-lookup"><span data-stu-id="0da85-375">tooachieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="0da85-376">序列化和還原序列化的考量</span><span class="sxs-lookup"><span data-stu-id="0da85-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="0da85-377">如果您的輸入資料集或輸出資料集是檔案，就可能發生序列化和還原序列化。</span><span class="sxs-lookup"><span data-stu-id="0da85-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="0da85-378">請參閱[支援的檔案和壓縮格式](data-factory-supported-file-and-compression-formats.md)，其中具有關於複製活動支援檔案格式的詳細資訊。</span><span class="sxs-lookup"><span data-stu-id="0da85-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="0da85-379">**複製行為**：</span><span class="sxs-lookup"><span data-stu-id="0da85-379">**Copy behavior**:</span></span>

* <span data-ttu-id="0da85-380">在以檔案為基礎的資料存放區之間複製檔案：</span><span class="sxs-lookup"><span data-stu-id="0da85-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="0da85-381">當輸入和輸出資料集都有 hello 相同或任何檔案格式設定、 hello 資料移動服務執行的二進位的複本，而不需要任何序列化或還原序列化。</span><span class="sxs-lookup"><span data-stu-id="0da85-381">When input and output data sets both have hello same or no file format settings, hello data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="0da85-382">您會看到較高的輸送量比較 toohello 案例，哪些 hello 來源和接收的檔案格式設定都與彼此不同。</span><span class="sxs-lookup"><span data-stu-id="0da85-382">You see a higher throughput compared toohello scenario, in which hello source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="0da85-383">當輸入和輸出的資料集這兩個是以文字格式只有 hello 編碼類型不同，hello 資料移動服務，才會執行編碼方式轉換。</span><span class="sxs-lookup"><span data-stu-id="0da85-383">When input and output data sets both are in text format and only hello encoding type is different, hello data movement service only does encoding conversion.</span></span> <span data-ttu-id="0da85-384">它不會執行任何序列化和還原序列化時，會導致某些效能額外負荷比較 tooa 二進位複製。</span><span class="sxs-lookup"><span data-stu-id="0da85-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared tooa binary copy.</span></span>
  * <span data-ttu-id="0da85-385">當輸入和輸出資料集這兩個具有不同的檔案格式或不同的組態，分隔符號，例如 hello 資料移動服務還原序列化的來源資料 toostream、 轉換，然後將它序列化成您所指定的 hello 輸出格式。</span><span class="sxs-lookup"><span data-stu-id="0da85-385">When input and output data sets both have different file formats or different configurations, like delimiters, hello data movement service deserializes source data toostream, transform, and then serialize it into hello output format you indicated.</span></span> <span data-ttu-id="0da85-386">此作業會產生額外負荷更顯著的效能比較 tooother 案例。</span><span class="sxs-lookup"><span data-stu-id="0da85-386">This operation results in a much more significant performance overhead compared tooother scenarios.</span></span>
* <span data-ttu-id="0da85-387">當您複製檔案，從資料存放區不是以檔案為基礎 （例如，從檔案型存放區 tooa 關聯式存放區） 時，hello 序列化或還原序列化的步驟需要。</span><span class="sxs-lookup"><span data-stu-id="0da85-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store tooa relational store), hello serialization or deserialization step is required.</span></span> <span data-ttu-id="0da85-388">此步驟會導致很高的效能負荷。</span><span class="sxs-lookup"><span data-stu-id="0da85-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="0da85-389">**檔案格式**: hello 您選擇的檔案格式可能會影響複製效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-389">**File format**: hello file format you choose might affect copy performance.</span></span> <span data-ttu-id="0da85-390">例如，Avro 是一種壓縮二進位格式，可將中繼資料和資料儲存在一起。</span><span class="sxs-lookup"><span data-stu-id="0da85-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="0da85-391">它進行處理和查詢的 hello Hadoop 生態系統中有廣泛的支援。</span><span class="sxs-lookup"><span data-stu-id="0da85-391">It has broad support in hello Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="0da85-392">不過，Avro 是更昂貴的序列化和還原序列化，而這會造成較低的複製輸送量比較 tootext 格式。</span><span class="sxs-lookup"><span data-stu-id="0da85-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared tootext format.</span></span> <span data-ttu-id="0da85-393">讓您選擇的整個 hello 而加以進行歷程處理流程的檔案格式。</span><span class="sxs-lookup"><span data-stu-id="0da85-393">Make your choice of file format throughout hello processing flow holistically.</span></span> <span data-ttu-id="0da85-394">以何種表單 hello 資料會儲存在開頭，而且來源資料存放區或 toobe 擷取自外部系統。儲存體、 分析的處理及查詢; hello 最佳格式並以何種格式 hello 資料應該匯出到資料超市報告和視覺化工具。</span><span class="sxs-lookup"><span data-stu-id="0da85-394">Start with what form hello data is stored in, source data stores or toobe extracted from external systems; hello best format for storage, analytical processing, and querying; and in what format hello data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="0da85-395">有時是次佳的檔案格式讀取和寫入效能可能會很好的選擇，當您考慮 hello 整體分析程序。</span><span class="sxs-lookup"><span data-stu-id="0da85-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider hello overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="0da85-396">壓縮的考量</span><span class="sxs-lookup"><span data-stu-id="0da85-396">Considerations for compression</span></span>
<span data-ttu-id="0da85-397">當您輸入或輸出的資料集是一個檔案時，您可以設定複製活動 tooperform 壓縮或解壓縮，因為它會將資料 toohello 目的地。</span><span class="sxs-lookup"><span data-stu-id="0da85-397">When your input or output data set is a file, you can set Copy Activity tooperform compression or decompression as it writes data toohello destination.</span></span> <span data-ttu-id="0da85-398">當您選擇壓縮時，您必須在輸入/輸出 (I/O) 與 CPU 之間進行取捨。</span><span class="sxs-lookup"><span data-stu-id="0da85-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="0da85-399">壓縮 hello 資料中額外的成本計算資源。</span><span class="sxs-lookup"><span data-stu-id="0da85-399">Compressing hello data costs extra in compute resources.</span></span> <span data-ttu-id="0da85-400">但另一方面卻可降低網路 I/O 和儲存體用量。</span><span class="sxs-lookup"><span data-stu-id="0da85-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="0da85-401">根據您的資料，您可能會看到整體複製輸送量有所提升。</span><span class="sxs-lookup"><span data-stu-id="0da85-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="0da85-402">**轉碼器**︰複製活動支援 gzip、bzip2 和 Deflate 壓縮類型。</span><span class="sxs-lookup"><span data-stu-id="0da85-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="0da85-403">這三種類型都可供 Azure HDInsight 進行處理。</span><span class="sxs-lookup"><span data-stu-id="0da85-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="0da85-404">每種壓縮轉碼器各有優點。</span><span class="sxs-lookup"><span data-stu-id="0da85-404">Each compression codec has advantages.</span></span> <span data-ttu-id="0da85-405">例如，bzip2 hello 最低複製輸送量，但是因為您可以將它分割進行處理，取得 hello 最佳 Hive 查詢的效能與 bzip2。</span><span class="sxs-lookup"><span data-stu-id="0da85-405">For example, bzip2 has hello lowest copy throughput, but you get hello best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="0da85-406">Gzip 是最平衡 hello 選項，以及使用它最常 hello。</span><span class="sxs-lookup"><span data-stu-id="0da85-406">Gzip is hello most balanced option, and it is used hello most often.</span></span> <span data-ttu-id="0da85-407">選擇最適合您的端對端案例的 hello 轉碼器。</span><span class="sxs-lookup"><span data-stu-id="0da85-407">Choose hello codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="0da85-408">**層級**：對於每個壓縮轉碼器，您可以從兩個選項中做選擇：最快速的壓縮和最佳化的壓縮。</span><span class="sxs-lookup"><span data-stu-id="0da85-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="0da85-409">hello 最快速的壓縮的選項 hello 資料壓縮儘快，即使未以最佳方式壓縮 hello 產生的檔案。</span><span class="sxs-lookup"><span data-stu-id="0da85-409">hello fastest compressed option compresses hello data as quickly as possible, even if hello resulting file is not optimally compressed.</span></span> <span data-ttu-id="0da85-410">hello 以最佳方式壓縮的選項壓縮花更多時間，並會產生最少量的資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-410">hello optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="0da85-411">您可以測試這兩個選項 toosee 可提供更佳的整體效能，您的情況。</span><span class="sxs-lookup"><span data-stu-id="0da85-411">You can test both options toosee which provides better overall performance in your case.</span></span>

<span data-ttu-id="0da85-412">**要考量的事項**: toocopy 大量的內部存放區與 hello 雲端之間的資料，請考慮使用壓縮的過渡期的 blob 儲存體。</span><span class="sxs-lookup"><span data-stu-id="0da85-412">**A consideration**: toocopy a large amount of data between an on-premises store and hello cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="0da85-413">使用暫時儲存體時，很有幫助您的公司網路和您的 Azure 服務的 hello 頻寬 hello 限制因素，而且您想 hello 輸入資料集和輸出資料集這兩個 toobe 未壓縮的形式。</span><span class="sxs-lookup"><span data-stu-id="0da85-413">Using interim storage is helpful when hello bandwidth of your corporate network and your Azure services is hello limiting factor, and you want hello input data set and output data set both toobe in uncompressed form.</span></span> <span data-ttu-id="0da85-414">更具體來說，您可以將單一複製活動分成兩個複製活動。</span><span class="sxs-lookup"><span data-stu-id="0da85-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="0da85-415">hello 第一個複製活動會從複製 hello 來源 tooan 暫時的或壓縮格式中的暫存 blob。</span><span class="sxs-lookup"><span data-stu-id="0da85-415">hello first copy activity copies from hello source tooan interim or staging blob in compressed form.</span></span> <span data-ttu-id="0da85-416">第二個複製活動 hello hello 壓縮資料複製從臨時區域，，然後將解壓縮時就會將寫入 toohello 接收。</span><span class="sxs-lookup"><span data-stu-id="0da85-416">hello second copy activity copies hello compressed data from staging, and then decompresses while it writes toohello sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="0da85-417">資料行對應的考量</span><span class="sxs-lookup"><span data-stu-id="0da85-417">Considerations for column mapping</span></span>
<span data-ttu-id="0da85-418">您可以設定 hello **columnMappings**中所有的複製活動 toomap 或子集 hello 屬性輸入資料行 toohello 輸出資料行。</span><span class="sxs-lookup"><span data-stu-id="0da85-418">You can set hello **columnMappings** property in Copy Activity toomap all or a subset of hello input columns toohello output columns.</span></span> <span data-ttu-id="0da85-419">Hello 資料移動服務從 hello 來源讀取 hello 資料之後，它會將寫入 hello 資料 toohello 接收器之前需要 tooperform hello 資料的資料行對應。</span><span class="sxs-lookup"><span data-stu-id="0da85-419">After hello data movement service reads hello data from hello source, it needs tooperform column mapping on hello data before it writes hello data toohello sink.</span></span> <span data-ttu-id="0da85-420">這項額外處理會降低複製輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="0da85-421">如果來源資料存放區可供查詢，比方說，如果是類似 SQL Database 或 SQL Server 關聯式存放區，或者它是 NoSQL 存放區，例如資料表儲存體或 Azure Cosmos DB，請考慮推送 hello 資料行篩選和邏輯 toohello 重新調整順序**查詢**屬性，而不要使用資料行對應。</span><span class="sxs-lookup"><span data-stu-id="0da85-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing hello column filtering and reordering logic toohello **query** property instead of using column mapping.</span></span> <span data-ttu-id="0da85-422">如此一來，hello 來源資料中的資料存放區，會更有效率的 hello 資料移動服務讀取時，就會發生 hello 投影。</span><span class="sxs-lookup"><span data-stu-id="0da85-422">This way, hello projection occurs while hello data movement service reads data from hello source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="0da85-423">其他考量</span><span class="sxs-lookup"><span data-stu-id="0da85-423">Other considerations</span></span>
<span data-ttu-id="0da85-424">如果 hello 大小想 toocopy 大，您可以調整的資料的商務邏輯 toofurther 分割 hello 資料使用 hello Data Factory 中切割機制。</span><span class="sxs-lookup"><span data-stu-id="0da85-424">If hello size of data you want toocopy is large, you can adjust your business logic toofurther partition hello data using hello slicing mechanism in Data Factory.</span></span> <span data-ttu-id="0da85-425">然後，排程複製活動 toorun 更頻繁地執行每個複製活動 tooreduce hello 資料大小。</span><span class="sxs-lookup"><span data-stu-id="0da85-425">Then, schedule Copy Activity toorun more frequently tooreduce hello data size for each Copy Activity run.</span></span>

<span data-ttu-id="0da85-426">能謹慎 hello 數目的資料集和複製活動需要 Data Factory tooconnector toohello 相同的資料儲存在 hello 相同的時間。</span><span class="sxs-lookup"><span data-stu-id="0da85-426">Be cautious about hello number of data sets and copy activities requiring Data Factory tooconnector toohello same data store at hello same time.</span></span> <span data-ttu-id="0da85-427">許多並行的複製作業可能會進行節流資料存放區和導致 toodegraded 效能，複製作業內部重試次數，在某些情況下，執行失敗數目。</span><span class="sxs-lookup"><span data-stu-id="0da85-427">Many concurrent copy jobs might throttle a data store and lead toodegraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-tooblob-storage"></a><span data-ttu-id="0da85-428">範例案例： 從內部部署 SQL Server 的 tooBlob 存放區的複本</span><span class="sxs-lookup"><span data-stu-id="0da85-428">Sample scenario: Copy from an on-premises SQL Server tooBlob storage</span></span>
<span data-ttu-id="0da85-429">**案例**： 在管線內建 toocopy 資料從內部部署 SQL Server 的 tooBlob 存放區以 CSV 格式。</span><span class="sxs-lookup"><span data-stu-id="0da85-429">**Scenario**: A pipeline is built toocopy data from an on-premises SQL Server tooBlob storage in CSV format.</span></span> <span data-ttu-id="0da85-430">toomake hello 複製作業更快、 hello CSV 檔案應該壓縮成 bzip2 格式。</span><span class="sxs-lookup"><span data-stu-id="0da85-430">toomake hello copy job faster, hello CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="0da85-431">**測試和分析**: hello 輸送量，複製活動是小於 2 MBps，也就是比 hello 效能基準測試變得很慢。</span><span class="sxs-lookup"><span data-stu-id="0da85-431">**Test and analysis**: hello throughput of Copy Activity is less than 2 MBps, which is much slower than hello performance benchmark.</span></span>

<span data-ttu-id="0da85-432">**效能分析和微調**: tootroubleshoot hello 效能問題，讓我們看看如何處理及移動 hello 資料。</span><span class="sxs-lookup"><span data-stu-id="0da85-432">**Performance analysis and tuning**: tootroubleshoot hello performance issue, let’s look at how hello data is processed and moved.</span></span>

1. <span data-ttu-id="0da85-433">**讀取資料**： 閘道會開啟連接 tooSQL 伺服器，並傳送 hello 查詢。</span><span class="sxs-lookup"><span data-stu-id="0da85-433">**Read data**: Gateway opens a connection tooSQL Server and sends hello query.</span></span> <span data-ttu-id="0da85-434">SQL Server 回應傳送嗨資料資料流 tooGateway 透過 hello 內部網路。</span><span class="sxs-lookup"><span data-stu-id="0da85-434">SQL Server responds by sending hello data stream tooGateway via hello intranet.</span></span>
2. <span data-ttu-id="0da85-435">**序列化和壓縮資料**： 閘道序列化 hello 資料資料流 tooCSV 格式，並壓縮 hello 資料 tooa bzip2 資料流。</span><span class="sxs-lookup"><span data-stu-id="0da85-435">**Serialize and compress data**: Gateway serializes hello data stream tooCSV format, and compresses hello data tooa bzip2 stream.</span></span>
3. <span data-ttu-id="0da85-436">**將資料寫入**： 閘道上傳 hello bzip2 資料流 tooBlob 儲存體透過 hello 網際網路。</span><span class="sxs-lookup"><span data-stu-id="0da85-436">**Write data**: Gateway uploads hello bzip2 stream tooBlob storage via hello Internet.</span></span>

<span data-ttu-id="0da85-437">如您所見，hello 資料正在處理，而且移動資料流的循序方式： SQL Server > LAN > 閘道 > WAN > Blob 儲存體。</span><span class="sxs-lookup"><span data-stu-id="0da85-437">As you can see, hello data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="0da85-438">**hello 整體效能閘道 hello 輸送量最小值由整個 hello 管線**。</span><span class="sxs-lookup"><span data-stu-id="0da85-438">**hello overall performance is gated by hello minimum throughput across hello pipeline**.</span></span>

![資料流](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="0da85-440">一或多個 hello 下列因素可能會導致 hello 效能瓶頸：</span><span class="sxs-lookup"><span data-stu-id="0da85-440">One or more of hello following factors might cause hello performance bottleneck:</span></span>

* <span data-ttu-id="0da85-441">**來源**：SQL Server 本身的輸送量偏低，因為負載過重。</span><span class="sxs-lookup"><span data-stu-id="0da85-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="0da85-442">**資料管理閘道**：</span><span class="sxs-lookup"><span data-stu-id="0da85-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="0da85-443">**LAN**： 閘道遠 hello SQL Server 電腦，並且具有低頻寬連線。</span><span class="sxs-lookup"><span data-stu-id="0da85-443">**LAN**: Gateway is located far from hello SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="0da85-444">**閘道**： 閘道已達到下列作業其負載限制 tooperform hello:</span><span class="sxs-lookup"><span data-stu-id="0da85-444">**Gateway**: Gateway has reached its load limitations tooperform hello following operations:</span></span>
    * <span data-ttu-id="0da85-445">**序列化**： 序列化 hello 資料資料流 tooCSV 格式具有慢速的輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-445">**Serialization**: Serializing hello data stream tooCSV format has slow throughput.</span></span>
    * <span data-ttu-id="0da85-446">**壓縮**：您選擇了緩慢的壓縮轉碼器 (例如 bzip2，其採用 Core i7，速度為 2.8 MBps)。</span><span class="sxs-lookup"><span data-stu-id="0da85-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="0da85-447">**WAN**: hello hello 公司網路與您的 Azure 服務之間的頻寬太低 (例如，T1 = 1,544 kbps。T2 = 6,312 kbps)。</span><span class="sxs-lookup"><span data-stu-id="0da85-447">**WAN**: hello bandwidth between hello corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="0da85-448">**接收**：Blob 儲存體的輸送量低 </span><span class="sxs-lookup"><span data-stu-id="0da85-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="0da85-449">(但不太可能發生，因為其 SLA 保證至少有 60 MBps)。</span><span class="sxs-lookup"><span data-stu-id="0da85-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="0da85-450">在此情況下，bzip2 資料壓縮可能會減緩 hello 整個管線使用。</span><span class="sxs-lookup"><span data-stu-id="0da85-450">In this case, bzip2 data compression might be slowing down hello entire pipeline.</span></span> <span data-ttu-id="0da85-451">切換 tooa gzip 壓縮轉碼器，可能會簡化此瓶頸。</span><span class="sxs-lookup"><span data-stu-id="0da85-451">Switching tooa gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="0da85-452">範例案例︰使用平行複本</span><span class="sxs-lookup"><span data-stu-id="0da85-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="0da85-453">**案例 i:** 1,000 1 MB 的檔案複製 hello 在內部部署檔案系統 tooBlob 儲存體。</span><span class="sxs-lookup"><span data-stu-id="0da85-453">**Scenario I:** Copy 1,000 1-MB files from hello on-premises file system tooBlob storage.</span></span>

<span data-ttu-id="0da85-454">**分析和效能調整**： 例如，如果您有四核心電腦上安裝閘道 Data Factory 會使用 hello 檔案系統 tooBlob 儲存體從 16 toomove 檔案平行複製同時。</span><span class="sxs-lookup"><span data-stu-id="0da85-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies toomove files from hello file system tooBlob storage concurrently.</span></span> <span data-ttu-id="0da85-455">此平行執行應該會導致高輸送量。</span><span class="sxs-lookup"><span data-stu-id="0da85-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="0da85-456">您也可以明確指定 hello 平行複本計數。</span><span class="sxs-lookup"><span data-stu-id="0da85-456">You also can explicitly specify hello parallel copies count.</span></span> <span data-ttu-id="0da85-457">在複製許多小型檔案時，平行複製可藉由更有效率地使用資源，而對輸送量大有幫助。</span><span class="sxs-lookup"><span data-stu-id="0da85-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![案例 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="0da85-459">**案例 II**: 20 的 500 MB 的 blob 複製 Blob 儲存體 tooData 湖存放區分析，並再調整效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage tooData Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="0da85-460">**分析和效能調整**： 在此案例中，Data Factory hello 將資料複製從 Blob 儲存體 tooData 湖存放區使用單一複本 (**parallelCopies**設定 too1) 及單一雲端資料移動的單位。</span><span class="sxs-lookup"><span data-stu-id="0da85-460">**Analysis and performance tuning**: In this scenario, Data Factory copies hello data from Blob storage tooData Lake Store by using single-copy (**parallelCopies** set too1) and single-cloud data movement units.</span></span> <span data-ttu-id="0da85-461">hello 輸送量您觀察就會關閉 toothat 述 hello[效能參考章節](#performance-reference)。</span><span class="sxs-lookup"><span data-stu-id="0da85-461">hello throughput you observe will be close toothat described in hello [performance reference section](#performance-reference).</span></span>   

![案例 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="0da85-463">**案例 III**︰個別檔案大小大於數十 MB 且總數量很大。</span><span class="sxs-lookup"><span data-stu-id="0da85-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="0da85-464">**分析和效能微調**： 增加**parallelCopies**由於的單一雲端 DMU hello 資源限制並不會造成複製更好的效能。</span><span class="sxs-lookup"><span data-stu-id="0da85-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of hello resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="0da85-465">相反地，您應該指定多個雲端 DMUs tooget 更多資源 tooperform hello 資料移動。</span><span class="sxs-lookup"><span data-stu-id="0da85-465">Instead, you should specify more cloud DMUs tooget more resources tooperform hello data movement.</span></span> <span data-ttu-id="0da85-466">未指定的值為 hello **parallelCopies**屬性。</span><span class="sxs-lookup"><span data-stu-id="0da85-466">Do not specify a value for hello **parallelCopies** property.</span></span> <span data-ttu-id="0da85-467">Data Factory 會為您處理 hello 平行處理原則。</span><span class="sxs-lookup"><span data-stu-id="0da85-467">Data Factory handles hello parallelism for you.</span></span> <span data-ttu-id="0da85-468">在此情況下，如果您設定**cloudDataMovementUnits** too4，關於輸送量四次，就會發生。</span><span class="sxs-lookup"><span data-stu-id="0da85-468">In this case, if you set **cloudDataMovementUnits** too4, a throughput of about four times occurs.</span></span>

![案例 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="0da85-470">參考</span><span class="sxs-lookup"><span data-stu-id="0da85-470">Reference</span></span>
<span data-ttu-id="0da85-471">以下是效能監視及微調參考某些 hello 支援資料存放區：</span><span class="sxs-lookup"><span data-stu-id="0da85-471">Here are performance monitoring and tuning references for some of hello supported data stores:</span></span>

* <span data-ttu-id="0da85-472">Azure 儲存體 (包括 Blob 儲存體和表格儲存體)：[Azure 儲存體的擴充性目標](../storage/common/storage-scalability-targets.md)和 [Azure 儲存體效能和擴充性檢查清單](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="0da85-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="0da85-473">Azure SQL Database： 您可以[監視 hello 效能](../sql-database/sql-database-single-database-monitor.md)並檢查 hello 資料庫交易單位 (DTU) 百分比</span><span class="sxs-lookup"><span data-stu-id="0da85-473">Azure SQL Database: You can [monitor hello performance](../sql-database/sql-database-single-database-monitor.md) and check hello database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="0da85-474">Azure SQL 資料倉儲：其能力會以資料倉儲單位 (DWU) 來測量；請參閱 [管理 Azure SQL 資料倉儲中的計算能力 (概觀)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="0da85-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="0da85-475">Azure Cosmos DB：[Azure Cosmos DB 中的效能等級](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="0da85-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="0da85-476">內部部署 SQL Server： [效能的監視與微調](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="0da85-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="0da85-477">內部部署檔案伺服器： [檔案伺服器的效能微調](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="0da85-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
