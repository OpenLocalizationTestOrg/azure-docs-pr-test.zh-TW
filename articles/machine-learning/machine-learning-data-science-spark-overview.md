---
title: "使用 Azure HDInsight 上的 Spark 資料科學的其中一個 aaaOverview |Microsoft 文件"
description: "hello Spark MLlib toolkit 帶來相當大的機器學習模型化功能 toohello 分散式 HDInsight 環境。"
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 515705684a46917c2741bf063d439b1cda016abb
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/06/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="ac3cf-103">在 Azure HDInsight 上使用 Spark 的資料科學概觀</span><span class="sxs-lookup"><span data-stu-id="ac3cf-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="ac3cf-104">此套件的主題示範如何 toouse HDInsight Spark toocomplete 一般資料科學工作例如擷取資料、 特徵設計、 模型和模型評估。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-104">This suite of topics shows how toouse HDInsight Spark toocomplete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="ac3cf-105">使用 hello 資料是 hello 2013 NYC 計程車行程及價位資料集的範例。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-105">hello data used is a sample of hello 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="ac3cf-106">內建的 hello 模型包括羅吉斯和線性迴歸、 隨機樹系和梯度促進式樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-106">hello models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="ac3cf-107">hello 主題也顯示如何 toostore 這些模型在 Azure blob 儲存體 (WASB) 以及 tooscore 並評估其預測的效能。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-107">hello topics also show how toostore these models in Azure blob storage (WASB) and how tooscore and evaluate their predictive performance.</span></span> <span data-ttu-id="ac3cf-108">更進階的主題會討論如何使用交叉驗證和超參數掃掠來訓練模型。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="ac3cf-109">這個概觀主題也會參考 hello 主題描述如何設定 tooset hello 需要 toocomplete hello 步驟提供的 hello 逐步解說中的 Spark 叢集。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-109">This overview topic also references hello topics that describe how tooset up hello Spark cluster that you need toocomplete hello steps in hello walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="ac3cf-110">Spark 及 MLlib</span><span class="sxs-lookup"><span data-stu-id="ac3cf-110">Spark and MLlib</span></span>
<span data-ttu-id="ac3cf-111">[Spark](http://spark.apache.org/)開放原始碼的平行處理架構，可支援記憶體中處理 tooboost hello 巨量資料分析的應用程式效能。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="ac3cf-112">hello Spark 處理引擎內建的速度、 容易使用，且複雜的分析。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-112">hello Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="ac3cf-113">Spark 的記憶體中分散式的計算功能讓您更好的選擇 hello 反覆演算法用於機器學習及圖形的計算。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-113">Spark's in-memory distributed computation capabilities make it a good choice for hello iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="ac3cf-114">[MLlib](http://spark.apache.org/mllib/) Spark 的可調整的機器學習文件庫，讓演算法 hello 模型化功能 toothis 分散式的環境。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings hello algorithmic modeling capabilities toothis distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="ac3cf-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="ac3cf-115">HDInsight Spark</span></span>
<span data-ttu-id="ac3cf-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) hello Azure 裝載的開放原始碼 Spark 供應項目。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="ac3cf-117">它也包含支援**Jupyter PySpark 筆記本**hello Spark 叢集，可以執行轉換、 篩選和視覺化資料儲存在 Azure Blob (WASB) 的 Spark SQL 互動式查詢。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-117">It also includes support for **Jupyter PySpark notebooks** on hello Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="ac3cf-118">PySpark 為 hello Spark API Python。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-118">PySpark is hello Python API for Spark.</span></span> <span data-ttu-id="ac3cf-119">hello 程式碼的程式碼片段提供 hello 解決方案，並顯示 hello 相關繪圖 toovisualize hello 資料這裡 Jupyter 筆記本 hello Spark 叢集上安裝中執行。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-119">hello code snippets that provide hello solutions and show hello relevant plots toovisualize hello data here run in Jupyter notebooks installed on hello Spark clusters.</span></span> <span data-ttu-id="ac3cf-120">這些主題中的 hello 模型步驟包含顯示 tootrain，如何評估、 儲存和取用每種模型類型的程式碼。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-120">hello modeling steps in these topics contain code that shows how tootrain, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="ac3cf-121">設定：Spark 叢集和 Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="ac3cf-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="ac3cf-122">此逐步解說所提供的設定步驟和程式碼適用於使用 HDInsight Spark 1.6。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="ac3cf-123">不過 Jupyter Notebook 可供 HDInsight Spark 1.6 版和 Spark 2.0 叢集兩者使用。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="ac3cf-124">Hello 中提供的 hello 筆記本與連結 toothem 描述[Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) hello GitHub 儲存機制包含它們。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-124">A description of hello notebooks and links toothem are provided in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for hello GitHub repository containing them.</span></span> <span data-ttu-id="ac3cf-125">此外，hello 程式碼及連結的 hello 筆記本為泛型，應該在任何 Spark 叢集上運作。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-125">Moreover, hello code here and in hello linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="ac3cf-126">如果您未使用 HDInsight Spark，hello 叢集中設定和管理步驟可能稍有不同於這裡所顯示。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-126">If you are not using HDInsight Spark, hello cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="ac3cf-127">為了方便起見，以下是 hello 的 hello 的 hello 連結 toohello Jupyter 筆記本 Spark 1.6 (執行中 Jupyter 筆記本伺服器 hello pySpark 核心 toobe) 和 Spark 2.0 (執行中 Jupyter 筆記本伺服器 hello pySpark3 核心 toobe):</span><span class="sxs-lookup"><span data-stu-id="ac3cf-127">For convenience, here are hello links toohello Jupyter notebooks for Spark 1.6 (toobe run in hello pySpark kernel of hello Jupyter Notebook server) and  Spark 2.0 (toobe run in hello pySpark3 kernel of hello Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="ac3cf-128">Spark 1.6 Notebook</span><span class="sxs-lookup"><span data-stu-id="ac3cf-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="ac3cf-129">這些筆記型電腦有 toobe 的 Jupyter 筆記本伺服器 hello pySpark 核心中執行。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-129">These notebooks are toobe run in hello pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="ac3cf-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb)： 提供有關如何 tooperform 資料瀏覽、 建立模型及計分具有數個不同的演算法。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how tooperform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="ac3cf-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb)：包含Notebook #1 中的主題，以及使用超參數微調和交叉驗證的模型開發。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="ac3cf-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb)： 示範如何 toooperationalize 已儲存的模型使用 Python HDInsight 上的叢集。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how toooperationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="ac3cf-133">Spark 2.0 Notebook</span><span class="sxs-lookup"><span data-stu-id="ac3cf-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="ac3cf-134">這些筆記型電腦有 toobe 的 Jupyter 筆記本伺服器 hello pySpark3 核心中執行。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-134">These notebooks are toobe run in hello pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="ac3cf-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb)： 這個檔案提供如何 tooperform 資料瀏覽、 建立模型及計分 Spark 2.0 中使用叢集 hello NYC 計程車路線資訊和價位資料集描述[這裡](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data)。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how tooperform data exploration, modeling, and scoring in Spark 2.0 clusters using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="ac3cf-136">筆記本可能會快速瀏覽我們的 Spark 2.0 所提供的 hello 程式碼很好的起點。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-136">This notebook may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> <span data-ttu-id="ac3cf-137">更詳細的筆記本分析 hello NYC 計程車資料時，請參閱這份清單中的 hello 下一步筆記型電腦。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-137">For a more detailed notebook analyzes hello NYC Taxi data, see hello next notebook in this list.</span></span> <span data-ttu-id="ac3cf-138">請參閱此清單後面，比較這些筆記本 hello 備註。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-138">See hello notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="ac3cf-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb)： 此檔案會顯示如何 tooperform 資料 wrangling （Spark SQL 和資料框架作業），瀏覽模型及計分使用 hello NYC 計程車行程及價位資料集描述[這裡](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data)。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="ac3cf-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb)： 此檔案會顯示如何 tooperform 資料 wrangling （Spark SQL 和資料框架作業），瀏覽模型及計分使用 hello 已知 Airline 準時離開從 2011年和 2012年的資料集。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="ac3cf-141">我們整合 hello airline 資料集與 hello 機場天氣資料 （例如 windspeed、 溫度、 海拔高度等） 之前 toomodeling，因此這些天氣功能可以包含在 hello 模型中。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-141">We integrated hello airline dataset with hello airport weather data (e.g. windspeed, temperature, altitude etc.) prior toomodeling, so these weather features can be included in hello model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="ac3cf-142">hello airline 資料集加入 toohello Spark 2.0 筆記本 toobetter 說明 hello 使用分類演算法。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-142">hello airline dataset was added toohello Spark 2.0 notebooks toobetter illustrate hello use of classification algorithms.</span></span> <span data-ttu-id="ac3cf-143">請參閱下列連結查看有關 airline 準時出發，資料集和天氣資料集的 hello:</span><span class="sxs-lookup"><span data-stu-id="ac3cf-143">See hello following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="ac3cf-144">航班準時出發資料：[http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="ac3cf-145">機場天氣資料：[https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="ac3cf-146">在 hello NYC 計程車的 hello Spark 2.0 筆記本與 airline 飛行延遲資料集可能需要 10 分鐘或更多 toorun （取決於 hello HDI 叢集大小）。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-146">hello Spark 2.0 notebooks on hello NYC taxi and airline flight delay data-sets can take 10 mins or more toorun (depending on hello size of your HDI cluster).</span></span> <span data-ttu-id="ac3cf-147">hello hello 上述清單中的第一個筆記本會顯示 hello 資料瀏覽的許多層面，視覺效果和 ML 模型定型中採用較少的時間 toorun 下取樣 NYC 資料集中的 hello 計程車行程及價位檔案都已預先已加入的筆記本： [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb)筆記本會採用更短時間 toofinish （2-3 分鐘為單位），並可能不錯的起點快速瀏覽 hello 程式碼我們有提供 Spark 2.0。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-147">hello first notebook in hello above list shows many aspects of hello data exploration, visualization and ML model training in a notebook that takes less time toorun with down-sampled NYC data set, in which hello taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time toofinish (2-3 mins) and may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="ac3cf-148">如需 hello 實施 Spark 2.0 模型及計分模型耗用量的指引，請參閱 hello[耗用量的 Spark 1.6 文件](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb)例如大綱 hello 所需的步驟。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-148">For guidance on hello operationalization of a Spark 2.0 model and model consumption for scoring, see hello [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining hello steps required.</span></span> <span data-ttu-id="ac3cf-149">toouse 上的 Spark 2.0 中，這會取代 hello Python 程式碼包含檔案[這個檔案](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py)。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-149">toouse this on Spark 2.0, replace hello Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="ac3cf-150">必要條件</span><span class="sxs-lookup"><span data-stu-id="ac3cf-150">Prerequisites</span></span>
<span data-ttu-id="ac3cf-151">下列程序的 hello 是相關的 tooSpark 1.6。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-151">hello following procedures are related tooSpark 1.6.</span></span> <span data-ttu-id="ac3cf-152">如需 hello Spark 2.0 版本中，使用 hello 筆記本所述，與連結 toopreviously。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-152">For  hello Spark 2.0 version, use hello notebooks described and linked toopreviously.</span></span> 

<span data-ttu-id="ac3cf-153">1. 您必須擁有 Azure 訂用帳戶。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="ac3cf-154">如果還沒有訂用帳戶，請參閱 [取得 Azure 免費試用](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="ac3cf-155">2.您需要 Spark 1.6 叢集 toocomplete 本逐步解說。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-155">2.You need a Spark 1.6 cluster toocomplete this walkthrough.</span></span> <span data-ttu-id="ac3cf-156">toocreate 其中一個，請參閱所提供的 hello 指示[快速入門： 建立 Azure HDInsight 上的 Apache Spark](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md)。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-156">toocreate one, see hello instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="ac3cf-157">hello 叢集類型和版本指定從 hello**選取叢集類型**功能表。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-157">hello cluster type and version is specified from hello **Select Cluster Type** menu.</span></span> 

![設定叢集](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="ac3cf-159">顯示 toouse Scala，而不是 Python toocomplete 端對端資料科學處理程序的工作的主題，請參閱 hello [Scala 使用 Azure 上的 Spark 資料科學](machine-learning-data-science-process-scala-walkthrough.md)。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-159">For a topic that shows how toouse Scala rather than Python toocomplete tasks for an end-to-end data science process, see hello [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="hello-nyc-2013-taxi-data"></a><span data-ttu-id="ac3cf-160">hello NYC 2013 計程車資料</span><span class="sxs-lookup"><span data-stu-id="ac3cf-160">hello NYC 2013 Taxi data</span></span>
<span data-ttu-id="ac3cf-161">hello NYC 計程車路線資料約 20 GB 的壓縮以逗號分隔值 (CSV) 檔案 (~ 48 GB 未壓縮)，可包含多個 173 百萬個個別的往返和 hello fares 支付每往返作業。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-161">hello NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and hello fares paid for each trip.</span></span> <span data-ttu-id="ac3cf-162">每個往返記錄包含 hello 收取和下車地點和時間、 匿名的 hack (driver) 授權編號和 medallion (計程車的唯一 id) 數目。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-162">Each trip record includes hello pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="ac3cf-163">hello 資料涵蓋所有往返 hello 年份 2013年中，並提供下列兩個資料集的每個月的 hello:</span><span class="sxs-lookup"><span data-stu-id="ac3cf-163">hello data covers all trips in hello year 2013 and is provided in hello following two datasets for each month:</span></span>

1. <span data-ttu-id="ac3cf-164">hello 'trip_data' CSV 檔案包含路線的詳細資訊，例如乘客數目、 收取和持續時間和路線長度 dropoff 點、 中斷。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-164">hello 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="ac3cf-165">以下是一些範例記錄：</span><span class="sxs-lookup"><span data-stu-id="ac3cf-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="ac3cf-166">hello 'trip_fare' CSV 檔案包含 hello 價位支付每個路線，例如付款類型、 價位量、 產生額外負荷及稅金、 秘訣和 tolls，以及 hello 總容量付費的詳細資料。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-166">hello 'trip_fare' CSV files contain details of hello fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and hello total amount paid.</span></span> <span data-ttu-id="ac3cf-167">以下是一些範例記錄：</span><span class="sxs-lookup"><span data-stu-id="ac3cf-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="ac3cf-168">我們已經建立這些檔案和聯結的 hello 路線 0.1%範例\_資料和路線\_成單一資料集 toouse 再見 CSV 檔案，做為此逐步解說中的 hello 輸入資料集。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-168">We have taken a 0.1% sample of these files and joined hello trip\_data and trip\_fare CVS files into a single dataset toouse as hello input dataset for this walkthrough.</span></span> <span data-ttu-id="ac3cf-169">hello 唯一索引鍵 toojoin 路線\_資料和路線\_價位組成 hello 欄位： medallion 具 「 可回復\_授權與收取\_日期時間。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-169">hello unique key toojoin trip\_data and trip\_fare is composed of hello fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="ac3cf-170">Hello 資料集的每一筆記錄會包含下列屬性代表 NYC 計程車路線 hello:</span><span class="sxs-lookup"><span data-stu-id="ac3cf-170">Each record of hello dataset contains hello following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="ac3cf-171">欄位</span><span class="sxs-lookup"><span data-stu-id="ac3cf-171">Field</span></span> | <span data-ttu-id="ac3cf-172">簡短描述</span><span class="sxs-lookup"><span data-stu-id="ac3cf-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="ac3cf-173">medallion</span><span class="sxs-lookup"><span data-stu-id="ac3cf-173">medallion</span></span> |<span data-ttu-id="ac3cf-174">匿名的計程車圓形徽章 (唯一的計程車識別碼)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="ac3cf-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="ac3cf-175">hack_license</span></span> |<span data-ttu-id="ac3cf-176">匿名的 Hackney 歸位字元駕照號碼</span><span class="sxs-lookup"><span data-stu-id="ac3cf-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="ac3cf-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="ac3cf-177">vendor_id</span></span> |<span data-ttu-id="ac3cf-178">計程車廠商識別碼</span><span class="sxs-lookup"><span data-stu-id="ac3cf-178">Taxi vendor id</span></span> |
| <span data-ttu-id="ac3cf-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="ac3cf-179">rate_code</span></span> |<span data-ttu-id="ac3cf-180">NYC 計程車費率</span><span class="sxs-lookup"><span data-stu-id="ac3cf-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="ac3cf-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="ac3cf-181">store_and_fwd_flag</span></span> |<span data-ttu-id="ac3cf-182">儲存和轉寄旗標</span><span class="sxs-lookup"><span data-stu-id="ac3cf-182">Store and forward flag</span></span> |
| <span data-ttu-id="ac3cf-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="ac3cf-183">pickup_datetime</span></span> |<span data-ttu-id="ac3cf-184">上車日期和時間</span><span class="sxs-lookup"><span data-stu-id="ac3cf-184">Pick up date & time</span></span> |
| <span data-ttu-id="ac3cf-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="ac3cf-185">dropoff_datetime</span></span> |<span data-ttu-id="ac3cf-186">下車日期和時間</span><span class="sxs-lookup"><span data-stu-id="ac3cf-186">Dropoff date & time</span></span> |
| <span data-ttu-id="ac3cf-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="ac3cf-187">pickup_hour</span></span> |<span data-ttu-id="ac3cf-188">於幾點上車</span><span class="sxs-lookup"><span data-stu-id="ac3cf-188">Pick up hour</span></span> |
| <span data-ttu-id="ac3cf-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="ac3cf-189">pickup_week</span></span> |<span data-ttu-id="ac3cf-190">挑選 hello 當年第幾週</span><span class="sxs-lookup"><span data-stu-id="ac3cf-190">Pick up week of hello year</span></span> |
| <span data-ttu-id="ac3cf-191">weekday</span><span class="sxs-lookup"><span data-stu-id="ac3cf-191">weekday</span></span> |<span data-ttu-id="ac3cf-192">工作日 (範圍 1-7)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="ac3cf-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="ac3cf-193">passenger_count</span></span> |<span data-ttu-id="ac3cf-194">計程車車程的乘客數目</span><span class="sxs-lookup"><span data-stu-id="ac3cf-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="ac3cf-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="ac3cf-195">trip_time_in_secs</span></span> |<span data-ttu-id="ac3cf-196">往返時間 (秒)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-196">Trip time in seconds</span></span> |
| <span data-ttu-id="ac3cf-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="ac3cf-197">trip_distance</span></span> |<span data-ttu-id="ac3cf-198">以英哩計的車程距離</span><span class="sxs-lookup"><span data-stu-id="ac3cf-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="ac3cf-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="ac3cf-199">pickup_longitude</span></span> |<span data-ttu-id="ac3cf-200">上車處經度</span><span class="sxs-lookup"><span data-stu-id="ac3cf-200">Pick up longitude</span></span> |
| <span data-ttu-id="ac3cf-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="ac3cf-201">pickup_latitude</span></span> |<span data-ttu-id="ac3cf-202">上車處緯度</span><span class="sxs-lookup"><span data-stu-id="ac3cf-202">Pick up latitude</span></span> |
| <span data-ttu-id="ac3cf-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="ac3cf-203">dropoff_longitude</span></span> |<span data-ttu-id="ac3cf-204">下車經度</span><span class="sxs-lookup"><span data-stu-id="ac3cf-204">Dropoff longitude</span></span> |
| <span data-ttu-id="ac3cf-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="ac3cf-205">dropoff_latitude</span></span> |<span data-ttu-id="ac3cf-206">下車緯度</span><span class="sxs-lookup"><span data-stu-id="ac3cf-206">Dropoff latitude</span></span> |
| <span data-ttu-id="ac3cf-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="ac3cf-207">direct_distance</span></span> |<span data-ttu-id="ac3cf-208">上車與下車位置之間的直線距離</span><span class="sxs-lookup"><span data-stu-id="ac3cf-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="ac3cf-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="ac3cf-209">payment_type</span></span> |<span data-ttu-id="ac3cf-210">付款類型 (cas、信用卡等)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="ac3cf-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="ac3cf-211">fare_amount</span></span> |<span data-ttu-id="ac3cf-212">費用金額</span><span class="sxs-lookup"><span data-stu-id="ac3cf-212">Fare amount in</span></span> |
| <span data-ttu-id="ac3cf-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="ac3cf-213">surcharge</span></span> |<span data-ttu-id="ac3cf-214">額外費用</span><span class="sxs-lookup"><span data-stu-id="ac3cf-214">Surcharge</span></span> |
| <span data-ttu-id="ac3cf-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="ac3cf-215">mta_tax</span></span> |<span data-ttu-id="ac3cf-216">Mta 稅額</span><span class="sxs-lookup"><span data-stu-id="ac3cf-216">Mta tax</span></span> |
| <span data-ttu-id="ac3cf-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="ac3cf-217">tip_amount</span></span> |<span data-ttu-id="ac3cf-218">小費金額</span><span class="sxs-lookup"><span data-stu-id="ac3cf-218">Tip amount</span></span> |
| <span data-ttu-id="ac3cf-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="ac3cf-219">tolls_amount</span></span> |<span data-ttu-id="ac3cf-220">收費金額</span><span class="sxs-lookup"><span data-stu-id="ac3cf-220">Tolls amount</span></span> |
| <span data-ttu-id="ac3cf-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="ac3cf-221">total_amount</span></span> |<span data-ttu-id="ac3cf-222">總金額</span><span class="sxs-lookup"><span data-stu-id="ac3cf-222">Total amount</span></span> |
| <span data-ttu-id="ac3cf-223">tipped</span><span class="sxs-lookup"><span data-stu-id="ac3cf-223">tipped</span></span> |<span data-ttu-id="ac3cf-224">已收到小費 (用 0 或 1 表示否或是)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="ac3cf-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="ac3cf-225">tip_class</span></span> |<span data-ttu-id="ac3cf-226">小費類別 (0：$0、1：$0-5、2：$6-10、3：$11-20、4：> $20)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-hello-spark-cluster"></a><span data-ttu-id="ac3cf-227">從 Jupyter 筆記本 hello Spark 叢集上執行程式碼</span><span class="sxs-lookup"><span data-stu-id="ac3cf-227">Execute code from a Jupyter notebook on hello Spark cluster</span></span>
<span data-ttu-id="ac3cf-228">您可以啟動 hello Jupyter 筆記本從 hello Azure 入口網站。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-228">You can launch hello Jupyter Notebook from hello Azure portal.</span></span> <span data-ttu-id="ac3cf-229">尋找您儀表板上的 Spark 叢集，然後按一下它 tooenter 管理頁面，為您的叢集。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-229">Find your Spark cluster on your dashboard and click it tooenter management page for your cluster.</span></span> <span data-ttu-id="ac3cf-230">按一下 tooopen hello 筆記本 hello Spark 叢集，相關聯**叢集儀表板** -> **Jupyter 筆記本**。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-230">tooopen hello notebook associated with hello Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![叢集儀表板](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="ac3cf-232">您也可以瀏覽過***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter 筆記本。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-232">You can also browse too***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter Notebooks.</span></span> <span data-ttu-id="ac3cf-233">此 URL 的 hello CLUSTERNAME 一部分取代為您自己的叢集 hello 名稱。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-233">Replace hello CLUSTERNAME part of this URL with hello name of your own cluster.</span></span> <span data-ttu-id="ac3cf-234">您需要系統管理員帳戶 tooaccess hello 筆記本 hello 密碼。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-234">You need hello password for your admin account tooaccess hello notebooks.</span></span>

![瀏覽 Jupyter Notebooks](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="ac3cf-236">選取 PySpark toosee 目錄，其中包含的一些範例使用的 hello PySpark API.hello 筆記本包含此套件的 Spark 主題的 hello 程式碼範例時使用的預先封裝筆記本[GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-236">Select PySpark toosee a directory that contains a few examples of pre-packaged notebooks that use hello PySpark API.hello notebooks that contain hello code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="ac3cf-237">您可以上傳 hello 筆記本，直接從[GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter 筆記本伺服器上的 Spark 叢集。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-237">You can upload hello notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="ac3cf-238">在您 Jupyter 的 hello 首頁上，按一下 hello**上傳**hello 權限屬於囉 」 畫面上的按鈕。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-238">On hello home page of your Jupyter, click hello **Upload** button on hello right part of hello screen.</span></span> <span data-ttu-id="ac3cf-239">[檔案總管] 隨即開啟。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-239">It opens a file explorer.</span></span> <span data-ttu-id="ac3cf-240">這裡貼上 hello GitHub （未經處理的內容） URL hello 筆記本，然後按一下**開啟**。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-240">Here you can paste hello GitHub (raw content) URL of hello Notebook and click **Open**.</span></span> 

<span data-ttu-id="ac3cf-241">您看到與您 Jupyter 檔案清單中的 hello 檔案名稱**上傳**按鈕一次。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-241">You see hello file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="ac3cf-242">按一下此 [上傳]  按鈕。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-242">Click this **Upload** button.</span></span> <span data-ttu-id="ac3cf-243">現在您已匯入 hello 筆記型電腦。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-243">Now you have imported hello notebook.</span></span> <span data-ttu-id="ac3cf-244">本逐步解說中的其他筆記本重複這些步驟 tooupload hello。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-244">Repeat these steps tooupload hello other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="ac3cf-245">您可以以滑鼠右鍵按一下 hello 連結您的瀏覽器，並選取**複製連結**tooget hello github 未經處理內容的 URL。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-245">You can right-click hello links on your browser and select **Copy Link** tooget hello github raw content URL.</span></span> <span data-ttu-id="ac3cf-246">您可以將此 URL 貼到 hello Jupyter 上傳檔案總管 對話方塊。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-246">You can paste this URL into hello Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="ac3cf-247">現在您可以：</span><span class="sxs-lookup"><span data-stu-id="ac3cf-247">Now you can:</span></span>

* <span data-ttu-id="ac3cf-248">依序按一下 hello 筆記型電腦，請參閱 hello 程式碼。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-248">See hello code by clicking hello notebook.</span></span>
* <span data-ttu-id="ac3cf-249">按 **SHIFT-ENTER** 執行每個儲存格。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="ac3cf-250">按一下以執行 hello 整個筆記本**儲存格** -> **執行**。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-250">Run hello entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="ac3cf-251">使用 hello 自動視覺效果的查詢。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-251">Use hello automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="ac3cf-252">hello PySpark 核心自動視覺化 hello 的 SQL (HiveQL) 查詢的輸出。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-252">hello PySpark kernel automatically visualizes hello output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="ac3cf-253">您可以在多種不同類型的視覺效果 （資料表、 圓形圖、 線條、 區域或列） 之間的 hello 選項 tooselect 使用 hello**類型**hello 筆記本中的功能表按鈕：</span><span class="sxs-lookup"><span data-stu-id="ac3cf-253">You are given hello option tooselect among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using hello **Type** menu buttons in hello notebook:</span></span>
> 
> 

![泛型方法的羅吉斯迴歸 ROC 曲線](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="ac3cf-255">後續步驟</span><span class="sxs-lookup"><span data-stu-id="ac3cf-255">What's next?</span></span>
<span data-ttu-id="ac3cf-256">現在您使用 HDInsight Spark 叢集設定，並已上傳 hello Jupyter 筆記本，您就準備好 toowork 透過對應 toohello 三個 PySpark 筆記本的 hello 主題。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-256">Now that you are set up with an HDInsight Spark cluster and have uploaded hello Jupyter notebooks, you are ready toowork through hello topics that correspond toohello three PySpark notebooks.</span></span> <span data-ttu-id="ac3cf-257">它們會顯示如何 tooexplore 您的資料，然後如何 toocreate 和取用模型。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-257">They show how tooexplore your data and then how toocreate and consume models.</span></span> <span data-ttu-id="ac3cf-258">進階資料瀏覽以及如何模型化筆記本顯示 hello tooinclude 交叉驗證，超參數牽涉和模型評估。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-258">hello advanced data exploration and modeling notebook shows how tooinclude cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="ac3cf-259">**資料探索和模型使用 Spark:**探索 hello 資料集以及建立、 計分，和透過 hello 工作來評估 hello 機器學習模型[以 hello Spark 中建立資料的二元分類和迴歸模型MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md)主題。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-259">**Data Exploration and modeling with Spark:** Explore hello dataset and create, score, and evaluate hello machine learning models by working through hello [Create binary classification and regression models for data with hello Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="ac3cf-260">**模型耗用量：** toolearn 如何 tooscore hello 分類和迴歸模型建立本主題中，請參閱[分數及評估 Spark 建立機器學習模型](machine-learning-data-science-spark-model-consumption.md)。</span><span class="sxs-lookup"><span data-stu-id="ac3cf-260">**Model consumption:** toolearn how tooscore hello classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="ac3cf-261">**交叉驗證和超參數掃掠**：如需如何使用交叉驗證和超參數掃掠訓練模型的相關資訊，請參閱 [使用 Spark 進階資料探索和模型化](machine-learning-data-science-spark-advanced-data-exploration-modeling.md)</span><span class="sxs-lookup"><span data-stu-id="ac3cf-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

