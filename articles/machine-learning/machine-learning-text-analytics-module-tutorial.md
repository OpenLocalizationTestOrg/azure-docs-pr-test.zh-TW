---
title: "Azure Machine Learning Studio 中的 aaaCreate 文字分析模型 |Microsoft 文件"
description: "在 Azure Machine Learning Studio 模組對文字的前置處理、 N 字母組或使用特徵雜湊 toocreate 文字分析模型的方式"
services: machine-learning
documentationcenter: 
author: rastala
manager: jhubbard
editor: 
ms.assetid: 08cd6723-3ae6-4e99-a924-e650942e461b
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/06/2016
ms.author: roastala
ms.openlocfilehash: e3799f37ba54bb2ec8815ecf5ed34e145ffb20e9
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/06/2017
---
# <a name="create-text-analytics-models-in-azure-machine-learning-studio"></a><span data-ttu-id="ea154-103">在 Azure Machine Learning Studio 中建立文字分析模型</span><span class="sxs-lookup"><span data-stu-id="ea154-103">Create text analytics models in Azure Machine Learning Studio</span></span>
<span data-ttu-id="ea154-104">您可以使用 Azure Machine Learning toobuild 並實施文字分析模型。</span><span class="sxs-lookup"><span data-stu-id="ea154-104">You can use Azure Machine Learning toobuild and operationalize text analytics models.</span></span> <span data-ttu-id="ea154-105">這些模型可協助您解決問題，例如，文件分類或情緒分析問題。</span><span class="sxs-lookup"><span data-stu-id="ea154-105">These models can help you solve, for example, document classification or sentiment analysis problems.</span></span>

<span data-ttu-id="ea154-106">在文字分析實驗中，您通常需要︰</span><span class="sxs-lookup"><span data-stu-id="ea154-106">In a text analytics experiment, you would typically:</span></span>

1. <span data-ttu-id="ea154-107">清理和前置處理文字資料集</span><span class="sxs-lookup"><span data-stu-id="ea154-107">Clean and preprocess text dataset</span></span>
2. <span data-ttu-id="ea154-108">從已前置處理的文字擷取數值特徵向量</span><span class="sxs-lookup"><span data-stu-id="ea154-108">Extract numeric feature vectors from pre-processed text</span></span>
3. <span data-ttu-id="ea154-109">定型分類或迴歸模型</span><span class="sxs-lookup"><span data-stu-id="ea154-109">Train classification or regression model</span></span>
4. <span data-ttu-id="ea154-110">計分，並驗證 hello 模型</span><span class="sxs-lookup"><span data-stu-id="ea154-110">Score and validate hello model</span></span>
5. <span data-ttu-id="ea154-111">部署 hello 模型 tooproduction</span><span class="sxs-lookup"><span data-stu-id="ea154-111">Deploy hello model tooproduction</span></span>

<span data-ttu-id="ea154-112">在此教學課程中，當我們使用「Amazon 書籍評論」資料集逐步解說情緒分析模型時，您會學到這些步驟 (請參閱研究報告 “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification”，作者：Association of Computational Linguistics (ACL) 的 John Blitzer、Mark Dredze 和 Fernando Pereira，2007 年)。此資料集是由評論分數 (1-2 或 4-5) 和自由格式文字所組成。</span><span class="sxs-lookup"><span data-stu-id="ea154-112">In this tutorial, you learn these steps as we walk through a sentiment analysis model using Amazon Book Reviews dataset (see this research paper “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” by John Blitzer, Mark Dredze, and Fernando Pereira; Association of Computational Linguistics (ACL), 2007.) This dataset consists of review scores (1-2 or 4-5) and a free-form text.</span></span> <span data-ttu-id="ea154-113">hello 的目標是 toopredict hello 檢閱分數： 低 (1-2） 或 high (4-5)。</span><span class="sxs-lookup"><span data-stu-id="ea154-113">hello goal is toopredict hello review score: low (1-2) or high (4-5).</span></span>

<span data-ttu-id="ea154-114">您可以在 Cortana Intelligence Gallery 找到本教學課程中涵蓋的實驗︰</span><span class="sxs-lookup"><span data-stu-id="ea154-114">You can find experiments covered in this tutorial at Cortana Intelligence Gallery:</span></span>

[<span data-ttu-id="ea154-115">預測書籍評論</span><span class="sxs-lookup"><span data-stu-id="ea154-115">Predict Book Reviews</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-1)

[<span data-ttu-id="ea154-116">預測書籍評論 - 預測性實驗</span><span class="sxs-lookup"><span data-stu-id="ea154-116">Predict Book Reviews - Predictive Experiment</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-Predictive-Experiment-1)

## <a name="step-1-clean-and-preprocess-text-dataset"></a><span data-ttu-id="ea154-117">步驟 1：清理和前置處理文字資料集</span><span class="sxs-lookup"><span data-stu-id="ea154-117">Step 1: Clean and preprocess text dataset</span></span>
<span data-ttu-id="ea154-118">我們先 hello 實驗將 hello 檢閱分數分割成兩個類別分類的類別低和高的值區 tooformulate hello 問題。</span><span class="sxs-lookup"><span data-stu-id="ea154-118">We begin hello experiment by dividing hello review scores into categorical low and high buckets tooformulate hello problem as two-class classification.</span></span> <span data-ttu-id="ea154-119">我們使用[編輯中繼資料](https://msdn.microsoft.com/library/azure/dn905986.aspx)和[群組類別值](https://msdn.microsoft.com/library/azure/dn906014.aspx)模組。</span><span class="sxs-lookup"><span data-stu-id="ea154-119">We use [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) and [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) modules.</span></span>

![建立標籤](./media/machine-learning-text-analytics-module-tutorial/create-label.png)

<span data-ttu-id="ea154-121">然後，我們可以清除 hello 文字使用[前置處理文字](https://msdn.microsoft.com/library/azure/mt762915.aspx)模組。</span><span class="sxs-lookup"><span data-stu-id="ea154-121">Then, we clean hello text using [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) module.</span></span> <span data-ttu-id="ea154-122">hello 清除可減少 hello 資料集中的 hello 雜訊，可協助您找出 hello 最重要的功能，並改善 hello hello 最終模型的精確度。</span><span class="sxs-lookup"><span data-stu-id="ea154-122">hello cleaning reduces hello noise in hello dataset, help you find hello most important features, and improve hello accuracy of hello final model.</span></span> <span data-ttu-id="ea154-123">我們會移除停用字詞 (例如 "the" 或 "a" 等常見單字)、數字、特殊字元、重複字元、電子郵件地址和 URL。</span><span class="sxs-lookup"><span data-stu-id="ea154-123">We remove stopwords - common words such as "the" or "a" - and numbers, special characters, duplicated characters, email addresses, and URLs.</span></span> <span data-ttu-id="ea154-124">我們也轉換 hello 文字 toolowercase、 lemmatize hello 文字的方式，以及偵測句子界限，然後以"| | |"符號，以預先處理過的文字。</span><span class="sxs-lookup"><span data-stu-id="ea154-124">We also convert hello text toolowercase, lemmatize hello words, and detect sentence boundaries that are then indicated by "|||" symbol in pre-processed text.</span></span>

![前置處理文字](./media/machine-learning-text-analytics-module-tutorial/preprocess-text.png)

<span data-ttu-id="ea154-126">如果您想 toouse 自訂停用字詞的清單？</span><span class="sxs-lookup"><span data-stu-id="ea154-126">What if you want toouse a custom list of stopwords?</span></span> <span data-ttu-id="ea154-127">您可以將它傳入做為選擇性的輸入。</span><span class="sxs-lookup"><span data-stu-id="ea154-127">You can pass it in as optional input.</span></span> <span data-ttu-id="ea154-128">您也可以使用自訂 C# 語法規則運算式 tooreplace 子字串，並移除文字的一部份： 名詞、 動詞或形容詞。</span><span class="sxs-lookup"><span data-stu-id="ea154-128">You can also use custom C# syntax regular expression tooreplace substrings, and remove words by part of speech: nouns, verbs, or adjectives.</span></span>

<span data-ttu-id="ea154-129">Hello 前置處理完成之後，我們將 hello 資料分割成定型和測試集。</span><span class="sxs-lookup"><span data-stu-id="ea154-129">After hello preprocessing is complete, we split hello data into train and test sets.</span></span>

## <a name="step-2-extract-numeric-feature-vectors-from-pre-processed-text"></a><span data-ttu-id="ea154-130">步驟 2：從已前置處理的文字擷取數值特徵向量</span><span class="sxs-lookup"><span data-stu-id="ea154-130">Step 2: Extract numeric feature vectors from pre-processed text</span></span>
<span data-ttu-id="ea154-131">toobuild 文字資料的模型，您通常有 tooconvert 自由格式文字插入數字特徵向量。</span><span class="sxs-lookup"><span data-stu-id="ea154-131">toobuild a model for text data, you typically have tooconvert free-form text into numeric feature vectors.</span></span> <span data-ttu-id="ea154-132">在此範例中，我們使用[從文字擷取 N 字母組功能](https://msdn.microsoft.com/library/azure/mt762916.aspx)模組 tootransform hello 文字資料 toosuch 格式。</span><span class="sxs-lookup"><span data-stu-id="ea154-132">In this example, we use [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) module tootransform hello text data toosuch format.</span></span> <span data-ttu-id="ea154-133">此模組會採用以空格分隔單字的資料行，並計算出現在您資料集中的單字字典或單字的 N-Gram。</span><span class="sxs-lookup"><span data-stu-id="ea154-133">This module takes a column of whitespace-separated words and computes a dictionary of words, or N-grams of words, that appear in your dataset.</span></span> <span data-ttu-id="ea154-134">然後，它會計算每個單字或 N-Gram 出現在每筆記錄的次數，並從這些計數建立特徵向量。</span><span class="sxs-lookup"><span data-stu-id="ea154-134">Then, it counts how many times each word, or N-gram, appears in each record, and creates feature vectors from those counts.</span></span> <span data-ttu-id="ea154-135">在本教學課程中，我們會設定 N 字母組大小 too2，因此我們特徵向量包括單字和句子的兩個後續。</span><span class="sxs-lookup"><span data-stu-id="ea154-135">In this tutorial, we set N-gram size too2, so our feature vectors include single words and combinations of two subsequent words.</span></span>

![擷取 N-Gram](./media/machine-learning-text-analytics-module-tutorial/extract-ngrams.png)

<span data-ttu-id="ea154-137">我們套用 TF * 加權 tooN 字母組 IDF （詞彙頻率反向文件頻率） 計算。</span><span class="sxs-lookup"><span data-stu-id="ea154-137">We apply TF*IDF (Term Frequency Inverse Document Frequency) weighting tooN-gram counts.</span></span> <span data-ttu-id="ea154-138">這種方式新增之單字的單一記錄中經常出現，但 hello 整個資料集很少的權重。</span><span class="sxs-lookup"><span data-stu-id="ea154-138">This approach adds weight of words that appear frequently in a single record but are rare across hello entire dataset.</span></span> <span data-ttu-id="ea154-139">其他選項包括二進位、TF 及圖形加權。</span><span class="sxs-lookup"><span data-stu-id="ea154-139">Other options include binary, TF, and graph weighing.</span></span>

<span data-ttu-id="ea154-140">這類文字特徵通常具有高維度。</span><span class="sxs-lookup"><span data-stu-id="ea154-140">Such text features often have high dimensionality.</span></span> <span data-ttu-id="ea154-141">比方說，如果您的語言資料庫有 100,000 個唯一的單字，特徵空間會有 100,000 個維度，或使用更多的 N-Gram。</span><span class="sxs-lookup"><span data-stu-id="ea154-141">For example, if your corpus has 100,000 unique words, your feature space would have 100,000 dimensions, or more if N-grams are used.</span></span> <span data-ttu-id="ea154-142">hello 擷取 N 字母組功能模組會提供一組選項 tooreduce hello 維度性。</span><span class="sxs-lookup"><span data-stu-id="ea154-142">hello Extract N-Gram Features module gives you a set of options tooreduce hello dimensionality.</span></span> <span data-ttu-id="ea154-143">您可以選擇 tooexclude 字詞是短或長或太常見或太頻繁 toohave 重要的預測值。</span><span class="sxs-lookup"><span data-stu-id="ea154-143">You can choose tooexclude words that are short or long, or too uncommon or too frequent toohave significant predictive value.</span></span> <span data-ttu-id="ea154-144">在本教學課程中，我們會排除出現在少於 5 筆記錄或超過 80% 的記錄的 N-Gram。</span><span class="sxs-lookup"><span data-stu-id="ea154-144">In this tutorial, we exclude N-grams that appear in fewer than 5 records or in more than 80% of records.</span></span>

<span data-ttu-id="ea154-145">此外，您可以使用相互關聯的 hello 最這些功能的功能選取項目 tooselect 預測目標。</span><span class="sxs-lookup"><span data-stu-id="ea154-145">Also, you can use feature selection tooselect only those features that are hello most correlated with your prediction target.</span></span> <span data-ttu-id="ea154-146">我們使用卡方功能選取項目 tooselect 1000 功能。</span><span class="sxs-lookup"><span data-stu-id="ea154-146">We use Chi-Squared feature selection tooselect 1000 features.</span></span> <span data-ttu-id="ea154-147">您可以檢視所選的字詞或 N 字母組的 hello 詞彙擷取 N 字母組模組 hello 正確輸出，即可。</span><span class="sxs-lookup"><span data-stu-id="ea154-147">You can view hello vocabulary of selected words or N-grams by clicking hello right output of Extract N-grams module.</span></span>

<span data-ttu-id="ea154-148">替代方法 toousing 擷取 N 字母組功能，您可以使用特徵雜湊模組。</span><span class="sxs-lookup"><span data-stu-id="ea154-148">As an alternative approach toousing Extract N-Gram Features, you can use Feature Hashing module.</span></span> <span data-ttu-id="ea154-149">但請注意， [特徵雜湊](https://msdn.microsoft.com/library/azure/dn906018.aspx) 沒有內建的特徵選取功能或 TF*IDF 加權。</span><span class="sxs-lookup"><span data-stu-id="ea154-149">Note though that [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) does not have build-in feature selection capabilities, or TF*IDF weighing.</span></span>

## <a name="step-3-train-classification-or-regression-model"></a><span data-ttu-id="ea154-150">步驟 3：定型分類或迴歸模型</span><span class="sxs-lookup"><span data-stu-id="ea154-150">Step 3: Train classification or regression model</span></span>
<span data-ttu-id="ea154-151">現在的 hello 文字已轉換的 toonumeric 特徵資料行。</span><span class="sxs-lookup"><span data-stu-id="ea154-151">Now hello text has been transformed toonumeric feature columns.</span></span> <span data-ttu-id="ea154-152">hello 資料集仍然包含字串資料行，從上一個階段，因此我們使用選取的資料行中資料集 tooexclude 它們。</span><span class="sxs-lookup"><span data-stu-id="ea154-152">hello dataset still contains string columns from previous stages, so we use Select Columns in Dataset tooexclude them.</span></span>

<span data-ttu-id="ea154-153">然後使用[二級羅吉斯迴歸](https://msdn.microsoft.com/library/azure/dn905994.aspx)toopredict 我們的目標： 高或過低的檢閱分數。</span><span class="sxs-lookup"><span data-stu-id="ea154-153">We then use [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) toopredict our target: high or low review score.</span></span> <span data-ttu-id="ea154-154">此時，hello 文字分析問題已轉換成一般分類問題。</span><span class="sxs-lookup"><span data-stu-id="ea154-154">At this point, hello text analytics problem has been transformed into a regular classification problem.</span></span> <span data-ttu-id="ea154-155">您可以使用 Azure Machine Learning tooimprove hello 模型中可用的 hello 工具。</span><span class="sxs-lookup"><span data-stu-id="ea154-155">You can use hello tools available in Azure Machine Learning tooimprove hello model.</span></span> <span data-ttu-id="ea154-156">比方說，您可以試驗不同的分類器 toofind 出如何精確的結果所提供，或使用 hyperparameter 微調 tooimprove hello 精確度。</span><span class="sxs-lookup"><span data-stu-id="ea154-156">For example, you can experiment with different classifiers toofind out how accurate results they give, or use hyperparameter tuning tooimprove hello accuracy.</span></span>

![定型和評分](./media/machine-learning-text-analytics-module-tutorial/scoring-text.png)

## <a name="step-4-score-and-validate-hello-model"></a><span data-ttu-id="ea154-158">步驟 4： 計分，並驗證 hello 模型</span><span class="sxs-lookup"><span data-stu-id="ea154-158">Step 4: Score and validate hello model</span></span>
<span data-ttu-id="ea154-159">如何驗證 hello 定型的模型？</span><span class="sxs-lookup"><span data-stu-id="ea154-159">How would you validate hello trained model?</span></span> <span data-ttu-id="ea154-160">我們針對 hello 測試資料集評分它，並評估 hello 精確度。</span><span class="sxs-lookup"><span data-stu-id="ea154-160">We score it against hello test dataset and evaluate hello accuracy.</span></span> <span data-ttu-id="ea154-161">不過，hello 模型學到 N 字母組和其加權 hello 定型資料集從 hello 的詞彙。</span><span class="sxs-lookup"><span data-stu-id="ea154-161">However, hello model learned hello vocabulary of N-grams and their weights from hello training dataset.</span></span> <span data-ttu-id="ea154-162">因此，我們應該使用該詞彙和這些加權時重新擷取功能，從 測試資料，做為相對於 toocreating hello 詞彙。</span><span class="sxs-lookup"><span data-stu-id="ea154-162">Therefore, we should use that vocabulary and those weights when extracting features from test data, as opposed toocreating hello vocabulary anew.</span></span> <span data-ttu-id="ea154-163">因此，我們加入擷取 N 字母組功能模組 toohello 計分實驗 hello 分支、 從定型分支連接 hello 輸出詞彙及 tooread 僅設定 hello 詞彙模式。</span><span class="sxs-lookup"><span data-stu-id="ea154-163">Therefore, we add Extract N-Gram Features module toohello scoring branch of hello experiment, connect hello output vocabulary from training branch, and set hello vocabulary mode tooread-only.</span></span> <span data-ttu-id="ea154-164">我們也會停用 hello 篩選 N 字母組頻率設定 hello too1 最小執行個體和最大 too100%並關閉 hello 特徵選取。</span><span class="sxs-lookup"><span data-stu-id="ea154-164">We also disable hello filtering of N-grams by frequency by setting hello minimum too1 instance and maximum too100%, and turn off hello feature selection.</span></span>

<span data-ttu-id="ea154-165">Hello 資料已經過的測試中的文字資料行轉換 toonumeric 特徵資料行之後，我們會排除資料行，從上一個階段喜歡訓練分支中的 hello 字串。</span><span class="sxs-lookup"><span data-stu-id="ea154-165">After hello text column in test data has been transformed toonumeric feature columns, we exclude hello string columns from previous stages like in training branch.</span></span> <span data-ttu-id="ea154-166">然後我們使用分數模型模組 toomake 預測和評估模型模組 tooevaluate hello 精確度。</span><span class="sxs-lookup"><span data-stu-id="ea154-166">We then use Score Model module toomake predictions and Evaluate Model module tooevaluate hello accuracy.</span></span>

## <a name="step-5-deploy-hello-model-tooproduction"></a><span data-ttu-id="ea154-167">步驟 5： 部署的 hello 模型 tooproduction</span><span class="sxs-lookup"><span data-stu-id="ea154-167">Step 5: Deploy hello model tooproduction</span></span>
<span data-ttu-id="ea154-168">部署就緒 toobe tooproduction hello 模型。</span><span class="sxs-lookup"><span data-stu-id="ea154-168">hello model is almost ready toobe deployed tooproduction.</span></span> <span data-ttu-id="ea154-169">部署為 Web 服務時，它會採用自由格式的文字字串做為輸入，並傳回「高」或「低」的預測。</span><span class="sxs-lookup"><span data-stu-id="ea154-169">When deployed as web service, it takes free-form text string as input, and return a prediction "high" or "low."</span></span> <span data-ttu-id="ea154-170">它使用學到的 hello N 字母組詞彙 tootransform hello 文字 toofeatures，，並訓練羅吉斯迴歸模型 toomake 從這些功能的預測。</span><span class="sxs-lookup"><span data-stu-id="ea154-170">It uses hello learned N-gram vocabulary tootransform hello text toofeatures, and trained logistic regression model toomake a prediction from those features.</span></span> 

<span data-ttu-id="ea154-171">tooset 向上 hello 預測實驗，我們先儲存 hello N 字母組詞彙做為資料集，並 hello 定型 hello 訓練分支的 hello 實驗羅吉斯迴歸模型。</span><span class="sxs-lookup"><span data-stu-id="ea154-171">tooset up hello predictive experiment, we first save hello N-gram vocabulary as dataset, and hello trained logistic regression model from hello training branch of hello experiment.</span></span> <span data-ttu-id="ea154-172">然後，我們將儲存 hello 實驗使用 另存新檔 」 toocreate 預測實驗實驗圖形。</span><span class="sxs-lookup"><span data-stu-id="ea154-172">Then, we save hello experiment using "Save As" toocreate an experiment graph for predictive experiment.</span></span> <span data-ttu-id="ea154-173">我們從 hello 實驗移除 hello 分割資料的模組和 hello 訓練分支。</span><span class="sxs-lookup"><span data-stu-id="ea154-173">We remove hello Split Data module and hello training branch from hello experiment.</span></span> <span data-ttu-id="ea154-174">我們再連接先前儲存的 hello N 字母組詞彙和模型 tooExtract N 字母組功能分數模型模組分別。</span><span class="sxs-lookup"><span data-stu-id="ea154-174">We then connect hello previously saved N-gram vocabulary and model tooExtract N-Gram Features and Score Model modules, respectively.</span></span> <span data-ttu-id="ea154-175">我們也會移除 hello 評估模型 」 模組。</span><span class="sxs-lookup"><span data-stu-id="ea154-175">We also remove hello Evaluate Model module.</span></span>

<span data-ttu-id="ea154-176">我們之前前置處理文字模組 tooremove hello 的標籤資料行的資料集模組中插入選取的資料行，並取消選取分數模組中的 「 附加分數資料行 toodataset 」 選項。</span><span class="sxs-lookup"><span data-stu-id="ea154-176">We insert Select Columns in Dataset module before Preprocess Text module tooremove hello label column, and unselect "Append score column toodataset" option in Score Module.</span></span> <span data-ttu-id="ea154-177">這樣一來，hello web 服務不要求它正嘗試 toopredict，並不回應 hello 輸入的功能，以回應 hello 標籤。</span><span class="sxs-lookup"><span data-stu-id="ea154-177">That way, hello web service does not request hello label it is trying toopredict, and does not echo hello input features in response.</span></span>

![預測性實驗](./media/machine-learning-text-analytics-module-tutorial/predictive-text.png)

<span data-ttu-id="ea154-179">現在我們有一個實驗可以發行為 Web 服務，並使用要求-回應或批次執行 API 進行呼叫。</span><span class="sxs-lookup"><span data-stu-id="ea154-179">Now we have an experiment that can be published as a web service and called using request-response or batch execution APIs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="ea154-180">後續步驟</span><span class="sxs-lookup"><span data-stu-id="ea154-180">Next Steps</span></span>
<span data-ttu-id="ea154-181">從 [MSDN 文件](https://msdn.microsoft.com/library/azure/dn905886.aspx)深入了解文字分析模組。</span><span class="sxs-lookup"><span data-stu-id="ea154-181">Learn about text analytics modules from [MSDN documentation](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span></span>

