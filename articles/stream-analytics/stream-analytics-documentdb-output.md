---
title: "串流分析的 JSON 輸出 | Microsoft Docs"
description: "了解「串流分析」如何將 Azure Cosmos DB 設定為 JSON 輸出的目標，以針對非結構化 JSON 資料進行資料封存和低延遲查詢。"
keywords: "JSON 輸出"
documentationcenter: 
services: stream-analytics,documentdb
author: samacha
manager: jhubbard
editor: cgronlun
ms.assetid: 5d2a61a6-0dbf-4f1b-80af-60a80eb25dd1
ms.service: stream-analytics
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 03/28/2017
ms.author: samacha
ms.openlocfilehash: cc80b0080c806541362a1ef2d71b95862bd51ca2
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/29/2017
---
# <a name="target-azure-cosmos-db-for-json-output-from-stream-analytics"></a><span data-ttu-id="34117-104">將 Azure Cosmos DB 設定為串流分析的 JSON 輸出目標</span><span class="sxs-lookup"><span data-stu-id="34117-104">Target Azure Cosmos DB for JSON output from Stream Analytics</span></span>
<span data-ttu-id="34117-105">「串流分析」可以將 [Azure Cosmos DB](https://azure.microsoft.com/services/documentdb/) 設定為 JSON 輸出的目標，讓您能夠針對非結構化的 JSON 資料進行資料封存和低延遲查詢。</span><span class="sxs-lookup"><span data-stu-id="34117-105">Stream Analytics can target [Azure Cosmos DB](https://azure.microsoft.com/services/documentdb/) for JSON output, enabling data archiving and low-latency queries on unstructured JSON data.</span></span> <span data-ttu-id="34117-106">本文件涵蓋實作這種組態的一些最佳作法。</span><span class="sxs-lookup"><span data-stu-id="34117-106">This document covers some best practices for implementing this configuration.</span></span>

<span data-ttu-id="34117-107">如果您不熟悉 Cosmos DB，請參閱 [Azure Cosmos DB 的學習路徑](https://azure.microsoft.com/documentation/learning-paths/documentdb/)來開始著手。</span><span class="sxs-lookup"><span data-stu-id="34117-107">For those who are unfamiliar with Cosmos DB, take a look at [Azure Cosmos DB’s learning path](https://azure.microsoft.com/documentation/learning-paths/documentdb/) to get started.</span></span> 

<span data-ttu-id="34117-108">注意：目前不支援 Mongo DB API 架構的 Cosmos DB 集合。</span><span class="sxs-lookup"><span data-stu-id="34117-108">Note: Mongo DB API based Cosmos DB collections is currently not supported.</span></span> 

## <a name="basics-of-cosmos-db-as-an-output-target"></a><span data-ttu-id="34117-109">將 Cosmos DB 設定為輸出目標的基本概念</span><span class="sxs-lookup"><span data-stu-id="34117-109">Basics of Cosmos DB as an output target</span></span>
<span data-ttu-id="34117-110">「串流分析」中的 Azure Cosmos DB 輸出可將串流處理結果以 JSON 輸出的形式寫入到您的 Cosmos DB 集合中。</span><span class="sxs-lookup"><span data-stu-id="34117-110">The Azure Cosmos DB output in Stream Analytics enables writing your stream processing results as JSON output into your Cosmos DB collection(s).</span></span> <span data-ttu-id="34117-111">串流分析不會在資料庫中建立集合，而是需要您預先建立集合。</span><span class="sxs-lookup"><span data-stu-id="34117-111">Stream Analytics does not create collections in your database, instead requiring you to create them upfront.</span></span> <span data-ttu-id="34117-112">如此一來，Cosmos DB 集合的計費成本對您來說就很透明，而您也能直接使用 [Cosmos DB API](https://msdn.microsoft.com/library/azure/dn781481.aspx) 來微調集合的效能、一致性及容量。</span><span class="sxs-lookup"><span data-stu-id="34117-112">This is so that the billing costs of Cosmos DB collections are transparent to you, and so that you can tune the performance, consistency and capacity of your collections directly using the [Cosmos DB APIs](https://msdn.microsoft.com/library/azure/dn781481.aspx).</span></span> <span data-ttu-id="34117-113">建議您讓每個串流作業使用一個 Cosmos DB 資料庫，以透過邏輯方式分隔串流作業的集合。</span><span class="sxs-lookup"><span data-stu-id="34117-113">We recommend using one Cosmos DB Database per streaming job to logically separate your collections for a streaming job.</span></span>

<span data-ttu-id="34117-114">以下詳細說明一些 Cosmos DB 集合選項。</span><span class="sxs-lookup"><span data-stu-id="34117-114">Some of the Cosmos DB collection options are detailed below.</span></span>

## <a name="tune-consistency-availability-and-latency"></a><span data-ttu-id="34117-115">微調一致性、 可用性及延遲</span><span class="sxs-lookup"><span data-stu-id="34117-115">Tune consistency, availability, and latency</span></span>
<span data-ttu-id="34117-116">為了符合應用程式需求，Cosmos DB 允許您微調資料庫與集合，並在一致性、可用性及延遲之間進行取捨。</span><span class="sxs-lookup"><span data-stu-id="34117-116">To match your application requirements, Cosmos DB allows you to fine tune the database and collections and make trade-offs between consistency, availability and latency.</span></span> <span data-ttu-id="34117-117">您可以視案例針對讀取與寫入延遲所需的讀取一致性層級，來選擇資料庫帳戶上的一致性層級。</span><span class="sxs-lookup"><span data-stu-id="34117-117">Depending on what levels of read consistency your scenario needs against read and write latency, you can choose a consistency level on your database account.</span></span> <span data-ttu-id="34117-118">此外，Cosmos DB 預設會在對您集合進行的每個 CRUD 作業進行同步索引編製。</span><span class="sxs-lookup"><span data-stu-id="34117-118">Also by default, Cosmos DB enables synchronous indexing on each CRUD operation to your collection.</span></span> <span data-ttu-id="34117-119">這是另一個可在 Cosmos DB 中控制寫入/讀取效能的實用選項。</span><span class="sxs-lookup"><span data-stu-id="34117-119">This is another useful option to control the write/read performance in Cosmos DB.</span></span> <span data-ttu-id="34117-120">如需深入了解這個主題，請參閱 [變更資料庫及查詢的一致性層級](../documentdb/documentdb-consistency-levels.md) 。</span><span class="sxs-lookup"><span data-stu-id="34117-120">For further information on this topic, review the [change your database and query consistency levels](../documentdb/documentdb-consistency-levels.md) article.</span></span>

## <a name="upserts-from-stream-analytics"></a><span data-ttu-id="34117-121">來自串流分析的 Upsert</span><span class="sxs-lookup"><span data-stu-id="34117-121">Upserts from Stream Analytics</span></span>
<span data-ttu-id="34117-122">「串流分析」與 Cosmos DB 的整合可讓您根據指定的「文件識別碼」資料行，在 Cosmos DB 集合中插入或更新記錄。</span><span class="sxs-lookup"><span data-stu-id="34117-122">Stream Analytics integration with Cosmos DB allows you to insert or update records in your Cosmos DB collection based on a given Document ID column.</span></span> <span data-ttu-id="34117-123">這也稱為「Upsert」 。</span><span class="sxs-lookup"><span data-stu-id="34117-123">This is also referred to as an *Upsert*.</span></span>

<span data-ttu-id="34117-124">串流分析可利用最佳化的更新插入方法，而此方法只會在因為 Document ID 發生衝突而插入失敗時，才進行更新。</span><span class="sxs-lookup"><span data-stu-id="34117-124">Stream Analytics utilizes an optimistic Upsert approach, where updates are only done when insert fails due to a Document ID conflict.</span></span> <span data-ttu-id="34117-125">串流分析會將更新作為修補程式執行，以部分更新文件，也就是以漸進方式新增新屬性或取代現有屬性。</span><span class="sxs-lookup"><span data-stu-id="34117-125">This update is performed by Stream Analytics as a PATCH, so it enables partial updates to the document, i.e. addition of new properties or replacing an existing property is performed incrementally.</span></span> <span data-ttu-id="34117-126">請注意，變更 JSON 文件中陣列屬性的值，會造成整個陣列遭到覆寫，也就是不會合併陣列。</span><span class="sxs-lookup"><span data-stu-id="34117-126">Note that changes in the values of array properties in your JSON document result in the entire array getting overwritten, i.e. the array is not merged.</span></span>

## <a name="data-partitioning-in-cosmos-db"></a><span data-ttu-id="34117-127">Cosmos DB 中的資料分割</span><span class="sxs-lookup"><span data-stu-id="34117-127">Data partitioning in Cosmos DB</span></span>
<span data-ttu-id="34117-128">Cosmos DB [分割集合](../cosmos-db/partition-data.md)是建議的資料分割方法。</span><span class="sxs-lookup"><span data-stu-id="34117-128">Cosmos DB [partitioned collections](../cosmos-db/partition-data.md) are the recommended approach for partitioning your data.</span></span> 

<span data-ttu-id="34117-129">針對單一 Cosmos DB 集合，串流分析仍可讓您根據查詢模式和應用程式的效能需求來分割資料。</span><span class="sxs-lookup"><span data-stu-id="34117-129">For single Cosmos DB collections, Stream Analytics still allows you to partition your data based on both the query patterns and performance needs of your application.</span></span> <span data-ttu-id="34117-130">每個集合最多可包含 10GB 的資料 (上限)，且目前還無法相應增加 (或溢位) 集合。</span><span class="sxs-lookup"><span data-stu-id="34117-130">Each collection may contain up to 10GB of data (maximum) and currently there is no way to scale up (or overflow) a collection.</span></span> <span data-ttu-id="34117-131">如需相應放大，串流分析允許您使用指定的前置詞寫入多個集合 (請參閱下方的使用方式詳細資料)。</span><span class="sxs-lookup"><span data-stu-id="34117-131">For scaling out, Stream Analytics allows you to write to multiple collections with a given prefix (see usage details below).</span></span> <span data-ttu-id="34117-132">串流分析會根據使用者提供的 PartitionKey 欄，使用一致的 [雜湊分割解析程式](https://msdn.microsoft.com/library/azure/microsoft.azure.documents.partitioning.hashpartitionresolver.aspx) 策略來分割其輸出記錄。</span><span class="sxs-lookup"><span data-stu-id="34117-132">Stream Analytics uses the consistent [Hash Partition Resolver](https://msdn.microsoft.com/library/azure/microsoft.azure.documents.partitioning.hashpartitionresolver.aspx) strategy based on the user provided PartitionKey column to partition its output records.</span></span> <span data-ttu-id="34117-133">系統會使用在串流作業開始時具有所指定前置詞的集合數量，作為該作業會同時寫入的輸出分割區計數 (Cosmos DB 集合數 = 輸出分割區數)。</span><span class="sxs-lookup"><span data-stu-id="34117-133">The number of collections with the given prefix at the streaming job’s start time is used as the output partition count, to which the job writes to in parallel (Cosmos DB Collections = Output Partitions).</span></span> <span data-ttu-id="34117-134">對於延遲索引只進行插入的單一集合，預期會有約每秒 0.4 MB 的寫入輸送量。</span><span class="sxs-lookup"><span data-stu-id="34117-134">For a single collection with lazy indexing doing only inserts, about 0.4 MB/s write throughput can be expected.</span></span> <span data-ttu-id="34117-135">使用多個集合可允許您達成更高的輸送量及增加容量。</span><span class="sxs-lookup"><span data-stu-id="34117-135">Using multiple collections can allow you to achieve higher throughput and increased capacity.</span></span>

<span data-ttu-id="34117-136">如果您計劃在未來增加分割計數，您可能需要停止工作、將現有集合中的資料重新分割至新的集合，然後重新啟動串流分析工作。</span><span class="sxs-lookup"><span data-stu-id="34117-136">If you intend to increase the partition count in the future, you may need to stop your job, repartition the data from your existing collections into new collections and then restart the Stream Analytics job.</span></span> <span data-ttu-id="34117-137">有關使用 PartitionResolver 與重新分割的詳細資料，以及範例程式碼，都會包含在後續的文章中。</span><span class="sxs-lookup"><span data-stu-id="34117-137">More details on using PartitionResolver and re-partitioning along with sample code, will be included in a follow-up post.</span></span> <span data-ttu-id="34117-138">[Cosmos DB 中的分割與調整](../documentdb/documentdb-partition-data.md)一文也提供該主題的詳細說明。</span><span class="sxs-lookup"><span data-stu-id="34117-138">The article [Partitioning and scaling in Cosmos DB](../documentdb/documentdb-partition-data.md) also provides details on this.</span></span>

## <a name="cosmos-db-settings-for-json-output"></a><span data-ttu-id="34117-139">適用於 JSON 輸出的 Cosmos DB 設定</span><span class="sxs-lookup"><span data-stu-id="34117-139">Cosmos DB settings for JSON output</span></span>
<span data-ttu-id="34117-140">如果在「串流分析」中建立 Cosmos DB 作為輸出，將會產生如以下所示的資訊提示。</span><span class="sxs-lookup"><span data-stu-id="34117-140">Creating Cosmos DB as an output in Stream Analytics generates a prompt for information as seen below.</span></span> <span data-ttu-id="34117-141">本節說明屬性定義。</span><span class="sxs-lookup"><span data-stu-id="34117-141">This section provides an explanation of the properties definition.</span></span>

<span data-ttu-id="34117-142">資料分割的集合</span><span class="sxs-lookup"><span data-stu-id="34117-142">Partitioned Collection</span></span> | <span data-ttu-id="34117-143">多個「單一資料分割」集合</span><span class="sxs-lookup"><span data-stu-id="34117-143">Multiple “Single Partition” collections</span></span>
---|---
![documentdb 串流分析輸出畫面](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-1.png) |  ![documentdb 串流分析輸出畫面](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-2.png)


  
> [!NOTE]
> <span data-ttu-id="34117-146">**多個「單一資料分割 」集合**案例需要資料分割索引鍵，而且是支援的組態。</span><span class="sxs-lookup"><span data-stu-id="34117-146">The **Multiple “Single Partition” collections** scenario requires a partition key and is a supported configuration.</span></span> 

* <span data-ttu-id="34117-147">**輸出別名**：在您的 ASA 查詢中參照此輸出時所用的別名。</span><span class="sxs-lookup"><span data-stu-id="34117-147">**Output Alias** – An alias to refer this output in your ASA query</span></span>  
* <span data-ttu-id="34117-148">**帳戶名稱**：Cosmos DB 帳戶的名稱或端點 URI。</span><span class="sxs-lookup"><span data-stu-id="34117-148">**Account Name** – The name or endpoint URI of the Cosmos DB account.</span></span>  
* <span data-ttu-id="34117-149">**帳戶金鑰**：Cosmos DB 帳戶的共用存取金鑰。</span><span class="sxs-lookup"><span data-stu-id="34117-149">**Account Key** – The shared access key for the Cosmos DB account.</span></span>  
* <span data-ttu-id="34117-150">**資料庫**：Cosmos DB 資料庫名稱。</span><span class="sxs-lookup"><span data-stu-id="34117-150">**Database** – The Cosmos DB database name.</span></span>  
* <span data-ttu-id="34117-151">**集合名稱模式**：要使用之集合的集合名稱或其模式。</span><span class="sxs-lookup"><span data-stu-id="34117-151">**Collection Name Pattern** – The collection name or their pattern for the collections to be used.</span></span> <span data-ttu-id="34117-152">您可以使用選用的 {partition} 語彙基元來建構集合名稱的格式，其中的資料分割會從 0 開始。</span><span class="sxs-lookup"><span data-stu-id="34117-152">The collection name format can be constructed using the optional {partition} token, where partitions start from 0.</span></span> <span data-ttu-id="34117-153">以下是有效的範例輸入：</span><span class="sxs-lookup"><span data-stu-id="34117-153">Following are sample valid inputs:</span></span>  
  <span data-ttu-id="34117-154">1\) MyCollection – 必須要有一個名為 “MyCollection” 的集合存在。</span><span class="sxs-lookup"><span data-stu-id="34117-154">1\) MyCollection – One collection named “MyCollection” must exist.</span></span>  
  <span data-ttu-id="34117-155">2\) MyCollection{partition} – 這些集合必須存在 – "MyCollection0”、“MyCollection1”、“MyCollection2” 等，依此類推。</span><span class="sxs-lookup"><span data-stu-id="34117-155">2\) MyCollection{partition} – Such collections must exist– "MyCollection0”, “MyCollection1”, “MyCollection2” and so on.</span></span>  
* <span data-ttu-id="34117-156">**資料分割索引鍵** - 選擇性。</span><span class="sxs-lookup"><span data-stu-id="34117-156">**Partition Key** – Optional.</span></span> <span data-ttu-id="34117-157">只有當您在集合名稱模式中使用 {parition} 語彙基元時，才需要此索引鍵。</span><span class="sxs-lookup"><span data-stu-id="34117-157">This is only needed if you are using a {parition} token in your collection name pattern.</span></span> <span data-ttu-id="34117-158">輸出事件中的欄位名稱會用來為跨集合的資料分割輸出指定索引鍵。</span><span class="sxs-lookup"><span data-stu-id="34117-158">The name of the field in output events used to specify the key for partitioning output across collections.</span></span> <span data-ttu-id="34117-159">若為單一集合輸出，則可使用任何任意的輸出欄，例如 PartitionId。</span><span class="sxs-lookup"><span data-stu-id="34117-159">For single collection output, any arbitrary output column can be used e.g. PartitionId.</span></span>  
* <span data-ttu-id="34117-160">**文件識別碼** ：可省略。</span><span class="sxs-lookup"><span data-stu-id="34117-160">**Document ID** – Optional.</span></span> <span data-ttu-id="34117-161">輸出事件中的欄位名稱會用來指定主索引鍵，此為插入或更新作業的依據。</span><span class="sxs-lookup"><span data-stu-id="34117-161">The name of the field in output events used to specify the primary key on which insert or update operations are based.</span></span>  
