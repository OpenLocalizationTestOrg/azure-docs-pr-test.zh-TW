---
title: "Azure 進階儲存體：專為效能而設計 | Microsoft Docs"
description: "使用 Azure 進階儲存體設計高效能應用程式。 「進階儲存體」可針對在「Azure 虛擬機器」上執行且需要大量 I/O 的工作負載，提供高效能、低延遲的磁碟支援。"
services: storage
documentationcenter: na
author: aungoo-msft
manager: tadb
editor: tysonn
ms.assetid: e6a409c3-d31a-4704-a93c-0a04fdc95960
ms.service: storage
ms.workload: storage
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 06/27/2017
ms.author: aungoo
ms.openlocfilehash: dde3e60ae4c8387150b65f0715166b5d549891e3
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/06/2017
---
# <a name="azure-premium-storage-design-for-high-performance"></a><span data-ttu-id="ffeb7-104">Azure 進階儲存體：專為高效能而設計</span><span class="sxs-lookup"><span data-stu-id="ffeb7-104">Azure Premium Storage: Design for High Performance</span></span>
## <a name="overview"></a><span data-ttu-id="ffeb7-105">Overview</span><span class="sxs-lookup"><span data-stu-id="ffeb7-105">Overview</span></span>
<span data-ttu-id="ffeb7-106">這篇文章提供使用 Azure 進階儲存體來建置高效能應用程式的指導方針。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-106">This article provides guidelines for building high performance applications using Azure Premium Storage.</span></span> <span data-ttu-id="ffeb7-107">您可以使用 hello 結合效能最佳作法適用於 tootechnologies 應用程式使用本文件中提供的指示。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-107">You can use hello instructions provided in this document combined with performance best practices applicable tootechnologies used by your application.</span></span> <span data-ttu-id="ffeb7-108">tooillustrate hello 指導方針，我們也可以使用 SQL Server 進階儲存體上執行做為整份文件的範例。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-108">tooillustrate hello guidelines, we have used SQL Server running on Premium Storage as an example throughout this document.</span></span>

<span data-ttu-id="ffeb7-109">雖然我們解決本文章中的 hello 儲存層的效能案例，您將需要 toooptimize hello 應用程式層。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-109">While we address performance scenarios for hello Storage layer in this article, you will need toooptimize hello application layer.</span></span> <span data-ttu-id="ffeb7-110">比方說，如果您裝載 SharePoint 伺服器陣列在 Azure 高階儲存體上，您可以使用 hello 從這個發行項 toooptimize hello 資料庫伺服器的 SQL Server 範例。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-110">For example, if you are hosting a SharePoint Farm on Azure Premium Storage, you can use hello SQL Server examples from this article toooptimize hello database server.</span></span> <span data-ttu-id="ffeb7-111">此外，最佳化 hello SharePoint 伺服器陣列的 Web 伺服器和應用程式伺服器 tooget hello 最高效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-111">Additionally, optimize hello SharePoint Farm's Web server and Application server tooget hello most performance.</span></span>

<span data-ttu-id="ffeb7-112">關於在 Azure 進階儲存體上將應用程式效能最佳化方面，本文有助於回答以下常見的問題。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-112">This article will help answer following common questions about optimizing application performance on Azure Premium Storage,</span></span>

* <span data-ttu-id="ffeb7-113">如何 toomeasure 您應用程式的效能？</span><span class="sxs-lookup"><span data-stu-id="ffeb7-113">How toomeasure your application performance?</span></span>  
* <span data-ttu-id="ffeb7-114">為什麼看不到預期的高效能？</span><span class="sxs-lookup"><span data-stu-id="ffeb7-114">Why are you not seeing expected high performance?</span></span>  
* <span data-ttu-id="ffeb7-115">哪些因素會影響進階儲存體上的應用程式效能？</span><span class="sxs-lookup"><span data-stu-id="ffeb7-115">Which factors influence your application performance on Premium Storage?</span></span>  
* <span data-ttu-id="ffeb7-116">這些因素如何影響進階儲存體上的應用程式效能？</span><span class="sxs-lookup"><span data-stu-id="ffeb7-116">How do these factors influence performance of your application on Premium Storage?</span></span>  
* <span data-ttu-id="ffeb7-117">如何最佳化 IOPS、頻寬和延遲？</span><span class="sxs-lookup"><span data-stu-id="ffeb7-117">How can you optimize for IOPS, Bandwidth and Latency?</span></span>  

<span data-ttu-id="ffeb7-118">我們特別針對進階儲存體提供這些指導方針，因為進階儲存體上執行的工作負載非常重視效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-118">We have provided these guidelines specifically for Premium Storage because workloads running on Premium Storage are highly performance sensitive.</span></span> <span data-ttu-id="ffeb7-119">我們在適當的地方都提供範例。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-119">We have provided examples where appropriate.</span></span> <span data-ttu-id="ffeb7-120">您也可以套用標準儲存體磁碟與 IaaS Vm 上執行這些指導方針 tooapplications 部分。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-120">You can also apply some of these guidelines tooapplications running on IaaS VMs with Standard Storage disks.</span></span>

<span data-ttu-id="ffeb7-121">在開始，如果您是新 tooPremium 儲存體之前，先閱讀 hello[高階儲存體： Azure 虛擬機器工作負載的高效能儲存體](../storage-premium-storage.md)和[Azure 儲存體延展性和效能目標](storage-scalability-targets.md)文件。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-121">Before you begin, if you are new tooPremium Storage, first read hello [Premium Storage: High-Performance Storage for Azure Virtual Machine Workloads](../storage-premium-storage.md) and [Azure Storage Scalability and Performance Targets](storage-scalability-targets.md) articles.</span></span>

## <a name="application-performance-indicators"></a><span data-ttu-id="ffeb7-122">應用程式效能指標</span><span class="sxs-lookup"><span data-stu-id="ffeb7-122">Application Performance Indicators</span></span>
<span data-ttu-id="ffeb7-123">我們會評估是否正在執行應用程式，或不使用指標類似的效能、 速度應用程式會處理使用者要求時，應用程式正在處理每個要求的資料量、 多少要求正在處理中特定的應用程式停留多久，使用者擁有 toowait tooget 回應在提交要求之後的期間。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-123">We assess whether an application is performing well or not using performance indicators like, how fast an application is processing a user request, how much data an application is processing per request, how many requests is an application processing in a specific period of time, how long a user has toowait tooget a response after submitting their request.</span></span> <span data-ttu-id="ffeb7-124">IOPS、 輸送量或頻寬和延遲是這些效能指標 hello 術語。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-124">hello technical terms for these performance indicators are, IOPS, Throughput or Bandwidth, and Latency.</span></span>

<span data-ttu-id="ffeb7-125">在本節中，我們將討論中的進階儲存體的 hello 內容 hello 一般效能指標。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-125">In this section, we will discuss hello common performance indicators in hello context of Premium Storage.</span></span> <span data-ttu-id="ffeb7-126">在 hello 下列區段中，收集應用程式的需求，您將學習如何 toomeasure 這些應用程式的效能指標。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-126">In hello following section, Gathering Application Requirements, you will learn how toomeasure these performance indicators for your application.</span></span> <span data-ttu-id="ffeb7-127">在最佳化應用程式效能，稍後您將了解 hello 因素會影響這些效能指標和建議 toooptimize 它們。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-127">Later in Optimizing Application Performance, you will learn about hello factors affecting these performance indicators and recommendations toooptimize them.</span></span>

## <a name="iops"></a><span data-ttu-id="ffeb7-128">IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-128">IOPS</span></span>
<span data-ttu-id="ffeb7-129">IOPS 是數目，您的應用程式正在傳送 toohello 存放磁碟每秒的要求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-129">IOPS is number of requests that your application is sending toohello storage disks in one second.</span></span> <span data-ttu-id="ffeb7-130">輸入/輸出作業可能是讀取或寫入、循序或隨機。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-130">An input/output operation could be read or write, sequential or random.</span></span> <span data-ttu-id="ffeb7-131">像線上零售網站的 OLTP 應用程式需要許多並行使用者要求立即 tooprocess。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-131">OLTP applications like an online retail website need tooprocess many concurrent user requests immediately.</span></span> <span data-ttu-id="ffeb7-132">hello 使用者插入和要求更新大量的資料庫交易，哪一個 hello 應用程式必須快速處理。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-132">hello user requests are insert and update intensive database transactions, which hello application must process quickly.</span></span> <span data-ttu-id="ffeb7-133">因此，OLTP 應用程式需要極高的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-133">Therefore, OLTP applications require very high IOPS.</span></span> <span data-ttu-id="ffeb7-134">這類應用程式處理數百萬個小型和隨機的 IO 要求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-134">Such applications handle millions of small and random IO requests.</span></span> <span data-ttu-id="ffeb7-135">如果您有這樣的應用程式，您必須設計 hello 應用程式基礎結構 toooptimize 的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-135">If you have such an application, you must design hello application infrastructure toooptimize for IOPS.</span></span> <span data-ttu-id="ffeb7-136">在 hello 稍後區段，*最佳化應用程式效能*，我們探討所有 hello 因素，您必須考慮 tooget 高 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-136">In hello later section, *Optimizing Application Performance*, we discuss in detail all hello factors that you must consider tooget high IOPS.</span></span>

<span data-ttu-id="ffeb7-137">當您附加 premium 儲存體磁碟 tooyour 高擴充能力 VM，Azure 會佈建，讓您根據 hello 磁碟規格保證的 IOPS 數字。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-137">When you attach a premium storage disk tooyour high scale VM, Azure provisions for you a guaranteed number of IOPS as per hello disk specification.</span></span> <span data-ttu-id="ffeb7-138">例如，P50 磁碟會佈建 7500 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-138">For example, a P50 disk provisions 7500 IOPS.</span></span> <span data-ttu-id="ffeb7-139">每個高延展性 VM 大小也有它可承受的特定 IOPS 限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-139">Each high scale VM size also has a specific IOPS limit that it can sustain.</span></span> <span data-ttu-id="ffeb7-140">例如，標準 GS5 VM 以 80,000 IOPS 為限。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-140">For example, a Standard GS5 VM has 80,000 IOPS limit.</span></span>

## <a name="throughput"></a><span data-ttu-id="ffeb7-141">Throughput</span><span class="sxs-lookup"><span data-stu-id="ffeb7-141">Throughput</span></span>
<span data-ttu-id="ffeb7-142">輸送量或頻寬是 hello 的資料量，您的應用程式正在傳送 toohello 存放磁碟中指定的時間間隔。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-142">Throughput or Bandwidth is hello amount of data that your application is sending toohello storage disks in a specified interval.</span></span> <span data-ttu-id="ffeb7-143">如果應用程式以較大 IO 單位大小執行輸入/輸出作業，則需要較高輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-143">If your application is performing input/output operations with large IO unit sizes, it requires high Throughput.</span></span> <span data-ttu-id="ffeb7-144">資料倉儲應用程式通常 tooissue 掃描需要大量的作業，一次存取大型的資料部分，並經常執行大量作業。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-144">Data warehouse applications tend tooissue scan intensive operations that access large portions of data at a time and commonly perform bulk operations.</span></span> <span data-ttu-id="ffeb7-145">換句話說，這類應用程式需要較高的輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-145">In other words, such applications require higher Throughput.</span></span> <span data-ttu-id="ffeb7-146">如果您有這樣的應用程式，您必須設計其基礎結構 toooptimize 的輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-146">If you have such an application, you must design its infrastructure toooptimize for Throughput.</span></span> <span data-ttu-id="ffeb7-147">我們討論詳細 hello 因數 hello 下一節，您必須此微調 tooachieve。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-147">In hello next section, we discuss in detail hello factors you must tune tooachieve this.</span></span>

<span data-ttu-id="ffeb7-148">當您附加 premium 儲存體磁碟 tooa 高擴充能力 VM，Azure 會佈建輸送量根據該磁碟規格。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-148">When you attach a premium storage disk tooa high scale VM, Azure provisions Throughput as per that disk specification.</span></span> <span data-ttu-id="ffeb7-149">例如，P50 磁碟會佈建每秒 250 MB 的磁碟輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-149">For example, a P50 disk provisions 250 MB per second disk Throughput.</span></span> <span data-ttu-id="ffeb7-150">每個高延展性 VM 大小也有它可承受的特定輸送量限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-150">Each high scale VM size also has as specific Throughput limit that it can sustain.</span></span> <span data-ttu-id="ffeb7-151">例如，標準 GS5 VM 的輸送量上限為每秒 2,000 MB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-151">For example, Standard GS5 VM has a maximum throughput of 2,000 MB per second.</span></span> 

<span data-ttu-id="ffeb7-152">沒有之間的輸送量和 IOPS hello 公式以下所示的關聯。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-152">There is a relation between Throughput and IOPS as shown in hello formula below.</span></span>

![](media/storage-premium-storage-performance/image1.png)

<span data-ttu-id="ffeb7-153">因此，它是重要的 toodetermine hello 最佳輸送量和 IOPS 值應用程式所需。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-153">Therefore, it is important toodetermine hello optimal Throughput and IOPS values that your application requires.</span></span> <span data-ttu-id="ffeb7-154">其中一個 toooptimize 再試一次，因為其他 hello 也取得受影響。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-154">As you try toooptimize one, hello other also gets affected.</span></span> <span data-ttu-id="ffeb7-155">在稍後的 *最佳化應用程式效能*一節中，我們將更詳細討論最佳化 IOPS 和輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-155">In a later section, *Optimizing Application Performance*, we will discuss in more details about optimizing IOPS and Throughput.</span></span>

## <a name="latency"></a><span data-ttu-id="ffeb7-156">Latency</span><span class="sxs-lookup"><span data-stu-id="ffeb7-156">Latency</span></span>
<span data-ttu-id="ffeb7-157">延遲是 hello 花費的時間的應用程式 tooreceive 單一要求、 將它送出 toohello 存放磁碟和傳送 hello 回應 toohello 用戶端。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-157">Latency is hello time it takes an application tooreceive a single request, send it toohello storage disks and send hello response toohello client.</span></span> <span data-ttu-id="ffeb7-158">這是效能的重要的量值的加法 tooIOPS 和輸送量的應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-158">This is a critical measure of an application's performance in addition tooIOPS and Throughput.</span></span> <span data-ttu-id="ffeb7-159">hello premium 儲存體磁碟的延遲是 hello 時間 tooretrieve hello 資訊要求並傳達回 tooyour 應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-159">hello Latency of a premium storage disk is hello time it takes tooretrieve hello information for a request and communicate it back tooyour application.</span></span> <span data-ttu-id="ffeb7-160">進階儲存體提供一致的低延遲。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-160">Premium Storage provides consistent low latencies.</span></span> <span data-ttu-id="ffeb7-161">如果在進階儲存體磁碟上啟用 ReadOnly 主機快取，讀取延遲會非常低。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-161">If you enable ReadOnly host caching on premium storage disks, you can get much lower read latency.</span></span> <span data-ttu-id="ffeb7-162">在稍後的 *最佳化應用程式效能*一節中，我們將更詳細討論磁碟快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-162">We will discuss Disk Caching in more detail in later section on *Optimizing Application Performance*.</span></span>

<span data-ttu-id="ffeb7-163">當您要最佳化您的應用程式 tooget 更高的 IOPS 及輸送量，它會影響您的應用程式的延遲 hello。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-163">When you are optimizing your application tooget higher IOPS and Throughput, it will affect hello Latency of your application.</span></span> <span data-ttu-id="ffeb7-164">微調之後 hello 應用程式效能，一定要評估 hello 的 hello 應用程式 tooavoid 延遲預期有高度延遲的行為。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-164">After tuning hello application performance, always evaluate hello Latency of hello application tooavoid unexpected high latency behavior.</span></span>

## <a name="gather-application-performance-requirements"></a><span data-ttu-id="ffeb7-165">收集應用程式效能需求</span><span class="sxs-lookup"><span data-stu-id="ffeb7-165">Gather Application Performance Requirements</span></span>
<span data-ttu-id="ffeb7-166">hello 中設計高效能應用程式在 Azure 高階儲存體上執行的第一個步驟是 toounderstand hello 應用程式的效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-166">hello first step in designing high performance applications running on Azure Premium Storage is, toounderstand hello performance requirements of your application.</span></span> <span data-ttu-id="ffeb7-167">您收集的效能需求後，您可以最佳化應用程式 tooachieve hello 最佳效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-167">After you gather performance requirements, you can optimize your application tooachieve hello most optimal performance.</span></span>

<span data-ttu-id="ffeb7-168">Hello 前一節，我們將說明 hello 一般效能指標，IOPS、 輸送量和延遲。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-168">In hello previous section, we explained hello common performance indicators, IOPS, Throughput and Latency.</span></span> <span data-ttu-id="ffeb7-169">您必須識別哪些這些效能指標是重大 tooyour 應用程式 toodeliver hello 預期使用者體驗。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-169">You must identify which of these performance indicators are critical tooyour application toodeliver hello desired user experience.</span></span> <span data-ttu-id="ffeb7-170">例如，高 IOPS 重要大部分 tooOLTP 應用程式的每秒處理數百萬筆的交易。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-170">For example, high IOPS matters most tooOLTP applications processing millions of transactions in a second.</span></span> <span data-ttu-id="ffeb7-171">然而，就每秒處理大量資料的資料倉儲應用程式而言，高輸送量很重要。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-171">Whereas, high Throughput is critical for Data Warehouse applications processing large amounts of data in a second.</span></span> <span data-ttu-id="ffeb7-172">就即時視訊串流處理網站之類的即時應用程式而言，極低的延遲非常重要。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-172">Extremely low Latency is crucial for real-time applications like live video streaming websites.</span></span>

<span data-ttu-id="ffeb7-173">接下來，測量您的應用程式在其存留期 hello 最大的效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-173">Next, measure hello maximum performance requirements of your application throughout its lifetime.</span></span> <span data-ttu-id="ffeb7-174">使用下面 hello 範例檢查清單是個起點。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-174">Use hello sample checklist below as a start.</span></span> <span data-ttu-id="ffeb7-175">在一般記錄 hello 最大的效能需求，尖峰和離峰時間的工作負載期間。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-175">Record hello maximum performance requirements during normal, peak and off-hours workload periods.</span></span> <span data-ttu-id="ffeb7-176">藉由識別所有工作負載層級的需求，您將無法 toodetermine hello 應用程式的整體效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-176">By identifying requirements for all workloads levels, you will be able toodetermine hello overall performance requirement of your application.</span></span> <span data-ttu-id="ffeb7-177">比方說，hello 電子商務網站的一般工作負載將會是一年中大部分的指定天數內的 hello 交易。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-177">For example, hello normal workload of an e-commerce website will be hello transactions it serves during most days in a year.</span></span> <span data-ttu-id="ffeb7-178">hello 尖峰工作負載的 hello 網站將會是假日季節或特殊銷售事件期間的 hello 交易。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-178">hello peak workload of hello website will be hello transactions it serves during holiday season or special sale events.</span></span> <span data-ttu-id="ffeb7-179">hello 尖峰工作負載通常有經驗的一段有限，但可能會要求您的應用程式 tooscale 兩個或多其正常作業。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-179">hello peak workload is typically experienced for a limited period, but can require your application tooscale two or more times its normal operation.</span></span> <span data-ttu-id="ffeb7-180">了解 hello 50 個百分位數，90 個百分位數以及 99 個百分位數的需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-180">Find out hello 50 percentile, 90 percentile and 99 percentile requirements.</span></span> <span data-ttu-id="ffeb7-181">這有助於篩選掉任何極端值，在 hello 效能需求，您可以專注於最佳化 hello 正確的值。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-181">This helps filter out any outliers in hello performance requirements and you can focus your efforts on optimizing for hello right values.</span></span>

<span data-ttu-id="ffeb7-182">**應用程式效能需求檢查清單**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-182">**Application Performance Requirements Checklist**</span></span>

| <span data-ttu-id="ffeb7-183">**效能需求**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-183">**Performance requirements**</span></span> | <span data-ttu-id="ffeb7-184">**50 百分位數**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-184">**50 Percentile**</span></span> | <span data-ttu-id="ffeb7-185">**90 百分位數**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-185">**90 Percentile**</span></span> | <span data-ttu-id="ffeb7-186">**99 百分位數**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-186">**99  Percentile**</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-187">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-187">Max.</span></span> <span data-ttu-id="ffeb7-188">每秒交易</span><span class="sxs-lookup"><span data-stu-id="ffeb7-188">Transactions per second</span></span> | | | |
| <span data-ttu-id="ffeb7-189">% 讀取作業</span><span class="sxs-lookup"><span data-stu-id="ffeb7-189">% Read operations</span></span> | | | |
| <span data-ttu-id="ffeb7-190">% 寫入作業</span><span class="sxs-lookup"><span data-stu-id="ffeb7-190">% Write operations</span></span> | | | |
| <span data-ttu-id="ffeb7-191">% 隨機作業</span><span class="sxs-lookup"><span data-stu-id="ffeb7-191">% Random operations</span></span> | | | |
| <span data-ttu-id="ffeb7-192">% 循序作業</span><span class="sxs-lookup"><span data-stu-id="ffeb7-192">% Sequential operations</span></span> | | | |
| <span data-ttu-id="ffeb7-193">IO 要求大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-193">IO request size</span></span> | | | |
| <span data-ttu-id="ffeb7-194">平均輸送量</span><span class="sxs-lookup"><span data-stu-id="ffeb7-194">Average Throughput</span></span> | | | |
| <span data-ttu-id="ffeb7-195">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-195">Max.</span></span> <span data-ttu-id="ffeb7-196">輸送量</span><span class="sxs-lookup"><span data-stu-id="ffeb7-196">Throughput</span></span> | | | |
| <span data-ttu-id="ffeb7-197">最小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-197">Min.</span></span> <span data-ttu-id="ffeb7-198">延遲</span><span class="sxs-lookup"><span data-stu-id="ffeb7-198">Latency</span></span> | | | |
| <span data-ttu-id="ffeb7-199">平均延遲</span><span class="sxs-lookup"><span data-stu-id="ffeb7-199">Average Latency</span></span> | | | |
| <span data-ttu-id="ffeb7-200">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-200">Max.</span></span> <span data-ttu-id="ffeb7-201">CPU</span><span class="sxs-lookup"><span data-stu-id="ffeb7-201">CPU</span></span> | | | |
| <span data-ttu-id="ffeb7-202">平均 CPU</span><span class="sxs-lookup"><span data-stu-id="ffeb7-202">Average CPU</span></span> | | | |
| <span data-ttu-id="ffeb7-203">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-203">Max.</span></span> <span data-ttu-id="ffeb7-204">記憶體</span><span class="sxs-lookup"><span data-stu-id="ffeb7-204">Memory</span></span> | | | |
| <span data-ttu-id="ffeb7-205">平均記憶體</span><span class="sxs-lookup"><span data-stu-id="ffeb7-205">Average Memory</span></span> | | | |
| <span data-ttu-id="ffeb7-206">佇列深度</span><span class="sxs-lookup"><span data-stu-id="ffeb7-206">Queue Depth</span></span> | | | |

> [!NOTE]
> <span data-ttu-id="ffeb7-207">您應該預期應用程式未來的成長，據以調整這些數字。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-207">You should consider scaling these numbers based on expected future growth of your application.</span></span> <span data-ttu-id="ffeb7-208">因為它可能不容易 toochange hello 基礎結構，以改善之後的效能是個不錯的主意 tooplan 事先，成長。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-208">It is a good idea tooplan for growth ahead of time, because it could be harder toochange hello infrastructure for improving performance later.</span></span>
>
>

<span data-ttu-id="ffeb7-209">如果您有現有的應用程式，並想 toomove tooPremium 存放裝置，請先建立 hello 的檢查清單上方 hello 現有應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-209">If you have an existing application and want toomove tooPremium Storage, first build hello checklist above for hello existing application.</span></span> <span data-ttu-id="ffeb7-210">接著，建立根據所述的指導方針的進階儲存體和設計 hello 應用程式上的應用程式的原型*最佳化應用程式效能*在本文件稍後的章節。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-210">Then, build a prototype of your application on Premium Storage and design hello application based on guidelines described in *Optimizing Application Performance* in a later section of this document.</span></span> <span data-ttu-id="ffeb7-211">hello 下一節描述您可以使用 toogather hello 效能度量的 hello 工具。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-211">hello next section describes hello tools you can use toogather hello performance measurements.</span></span>

<span data-ttu-id="ffeb7-212">建立的檢查清單類似 tooyour 現有應用程式 hello 原型。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-212">Create a checklist similar tooyour existing application for hello prototype.</span></span> <span data-ttu-id="ffeb7-213">您可以使用 Benchmarking 工具模擬 hello 工作負載及測量 hello 原型應用程式的效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-213">Using Benchmarking tools you can simulate hello workloads and measure performance on hello prototype application.</span></span> <span data-ttu-id="ffeb7-214">請參閱 hello 章節[Benchmarking](#benchmarking) toolearn 更多。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-214">See hello section on [Benchmarking](#benchmarking) toolearn more.</span></span> <span data-ttu-id="ffeb7-215">這樣做可讓您判斷進階儲存體是否符合或超越應用程式效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-215">By doing so you can determine whether Premium Storage can match or surpass your application performance requirements.</span></span> <span data-ttu-id="ffeb7-216">然後您可以實作 hello 實際執行應用程式的相同指導方針。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-216">Then you can implement hello same guidelines for your production application.</span></span>

### <a name="counters-toomeasure-application-performance-requirements"></a><span data-ttu-id="ffeb7-217">計數器 toomeasure 應用程式效能需求</span><span class="sxs-lookup"><span data-stu-id="ffeb7-217">Counters toomeasure application performance requirements</span></span>
<span data-ttu-id="ffeb7-218">hello 應用程式的最佳方式 toomeasure 效能需求，hello 伺服器 hello 作業系統所提供的 toouse 效能監視工具。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-218">hello best way toomeasure performance requirements of your application, is toouse performance-monitoring tools provided by hello operating system of hello server.</span></span> <span data-ttu-id="ffeb7-219">您可以使用 Windows 的 PerfMon 和 Linux 的 iostat。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-219">You can use PerfMon for Windows and iostat for Linux.</span></span> <span data-ttu-id="ffeb7-220">這些工具會擷取對應 tooeach 量值 hello 區段上面所述的計數器。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-220">These tools capture counters corresponding tooeach measure explained in hello above section.</span></span> <span data-ttu-id="ffeb7-221">您的應用程式執行其一般、 尖峰和離峰時間的工作負載時，您必須擷取 hello 這些計數器的值。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-221">You must capture hello values of these counters when your application is running its normal, peak and off-hours workloads.</span></span>

<span data-ttu-id="ffeb7-222">hello PerfMon 計數器可用的處理器、 記憶體和，每個邏輯磁碟和實體磁碟，您的伺服器。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-222">hello PerfMon counters are available for processor, memory and, each logical disk and physical disk of your server.</span></span> <span data-ttu-id="ffeb7-223">當您使用進階儲存體磁碟 vm 時，hello 實體磁碟計數器每個 premium 儲存體磁碟，而邏輯磁碟計數器 hello premium 儲存磁碟上建立的每個磁碟區。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-223">When you use premium storage disks with a VM, hello physical disk counters are for each premium storage disk, and logical disk counters are for each volume created on hello premium storage disks.</span></span> <span data-ttu-id="ffeb7-224">您必須擷取 hello 裝載您的應用程式工作負載的 hello 磁碟的值。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-224">You must capture hello values for hello disks that host your application workload.</span></span> <span data-ttu-id="ffeb7-225">如果有一個 tooone 之間的對應邏輯與實體磁碟，您可以參考 toophysical 磁碟計數器;否則，請參閱 toohello 邏輯磁碟計數器。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-225">If there is a one tooone mapping between logical and physical disks, you can refer toophysical disk counters; otherwise refer toohello logical disk counters.</span></span> <span data-ttu-id="ffeb7-226">在 Linux 上 hello iostat 命令會產生的 CPU 和磁碟使用報告。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-226">On Linux, hello iostat command generates a CPU and disk utilization report.</span></span> <span data-ttu-id="ffeb7-227">hello 磁碟使用量報表會提供每個實體裝置或分割區的統計資料。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-227">hello disk utilization report provides statistics per physical device or partition.</span></span> <span data-ttu-id="ffeb7-228">如果資料庫伺服器的資料和記錄位於不同磁碟上，請同時從這兩個磁碟中收集這項資料。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-228">If you have a database server with its data and log on separate disks, collect this data for both disks.</span></span> <span data-ttu-id="ffeb7-229">下表說明磁碟、處理器和記憶體的計數器：</span><span class="sxs-lookup"><span data-stu-id="ffeb7-229">Below table describes counters for disks, processor and memory:</span></span>

| <span data-ttu-id="ffeb7-230">計數器</span><span class="sxs-lookup"><span data-stu-id="ffeb7-230">Counter</span></span> | <span data-ttu-id="ffeb7-231">說明</span><span class="sxs-lookup"><span data-stu-id="ffeb7-231">Description</span></span> | <span data-ttu-id="ffeb7-232">PerfMon</span><span class="sxs-lookup"><span data-stu-id="ffeb7-232">PerfMon</span></span> | <span data-ttu-id="ffeb7-233">Iostat</span><span class="sxs-lookup"><span data-stu-id="ffeb7-233">Iostat</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-234">**IOPS 或每秒交易數**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-234">**IOPS or Transactions per second**</span></span> |<span data-ttu-id="ffeb7-235">I/O 要求數目發出 toohello 存放裝置磁碟每秒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-235">Number of I/O requests issued toohello storage disk per second.</span></span> |<span data-ttu-id="ffeb7-236">Disk Reads/sec </span><span class="sxs-lookup"><span data-stu-id="ffeb7-236">Disk Reads/sec</span></span> <br> <span data-ttu-id="ffeb7-237">Disk Writes/sec</span><span class="sxs-lookup"><span data-stu-id="ffeb7-237">Disk Writes/sec</span></span> |<span data-ttu-id="ffeb7-238">tps </span><span class="sxs-lookup"><span data-stu-id="ffeb7-238">tps</span></span> <br> <span data-ttu-id="ffeb7-239">r/s </span><span class="sxs-lookup"><span data-stu-id="ffeb7-239">r/s</span></span> <br> <span data-ttu-id="ffeb7-240">w/s</span><span class="sxs-lookup"><span data-stu-id="ffeb7-240">w/s</span></span> |
| <span data-ttu-id="ffeb7-241">**磁碟讀取和寫入**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-241">**Disk Reads and Writes**</span></span> |<span data-ttu-id="ffeb7-242">%的讀取和寫入 hello 磁碟上執行的作業。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-242">% of Reads and Write operations performed on hello disk.</span></span> |<span data-ttu-id="ffeb7-243">% Disk Read Time </span><span class="sxs-lookup"><span data-stu-id="ffeb7-243">% Disk Read Time</span></span> <br> <span data-ttu-id="ffeb7-244">% Disk Write Time</span><span class="sxs-lookup"><span data-stu-id="ffeb7-244">% Disk Write Time</span></span> |<span data-ttu-id="ffeb7-245">r/s </span><span class="sxs-lookup"><span data-stu-id="ffeb7-245">r/s</span></span> <br> <span data-ttu-id="ffeb7-246">w/s</span><span class="sxs-lookup"><span data-stu-id="ffeb7-246">w/s</span></span> |
| <span data-ttu-id="ffeb7-247">**輸送量**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-247">**Throughput**</span></span> |<span data-ttu-id="ffeb7-248">讀取或寫入 toohello 磁碟每秒資料量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-248">Amount of data read from or written toohello disk per second.</span></span> |<span data-ttu-id="ffeb7-249">Disk Read Bytes/sec </span><span class="sxs-lookup"><span data-stu-id="ffeb7-249">Disk Read Bytes/sec</span></span> <br> <span data-ttu-id="ffeb7-250">Disk Write Bytes/sec</span><span class="sxs-lookup"><span data-stu-id="ffeb7-250">Disk Write Bytes/sec</span></span> |<span data-ttu-id="ffeb7-251">kB_read/s</span><span class="sxs-lookup"><span data-stu-id="ffeb7-251">kB_read/s</span></span> <br> <span data-ttu-id="ffeb7-252">kB_wrtn/s</span><span class="sxs-lookup"><span data-stu-id="ffeb7-252">kB_wrtn/s</span></span> |
| <span data-ttu-id="ffeb7-253">**延遲**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-253">**Latency**</span></span> |<span data-ttu-id="ffeb7-254">總時間 toocomplete 磁碟 IO 要求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-254">Total time toocomplete a disk IO request.</span></span> |<span data-ttu-id="ffeb7-255">Average Disk sec/Read </span><span class="sxs-lookup"><span data-stu-id="ffeb7-255">Average Disk sec/Read</span></span> <br> <span data-ttu-id="ffeb7-256">Average disk sec/Write</span><span class="sxs-lookup"><span data-stu-id="ffeb7-256">Average disk sec/Write</span></span> |<span data-ttu-id="ffeb7-257">await </span><span class="sxs-lookup"><span data-stu-id="ffeb7-257">await</span></span> <br> <span data-ttu-id="ffeb7-258">svctm</span><span class="sxs-lookup"><span data-stu-id="ffeb7-258">svctm</span></span> |
| <span data-ttu-id="ffeb7-259">**IO 大小**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-259">**IO size**</span></span> |<span data-ttu-id="ffeb7-260">hello 大小的 I/O 要求發出 toohello 存放磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-260">hello size of I/O requests issues toohello storage disks.</span></span> |<span data-ttu-id="ffeb7-261">Average Disk Bytes/Read </span><span class="sxs-lookup"><span data-stu-id="ffeb7-261">Average Disk Bytes/Read</span></span> <br> <span data-ttu-id="ffeb7-262">Average Disk Bytes/Write</span><span class="sxs-lookup"><span data-stu-id="ffeb7-262">Average Disk Bytes/Write</span></span> |<span data-ttu-id="ffeb7-263">avgrq-sz</span><span class="sxs-lookup"><span data-stu-id="ffeb7-263">avgrq-sz</span></span> |
| <span data-ttu-id="ffeb7-264">**佇列深度**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-264">**Queue Depth**</span></span> |<span data-ttu-id="ffeb7-265">等候 toobe 讀取表單或寫入 toohello 存放裝置磁碟要求的未處理 I/O 數目。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-265">Number of outstanding I/O requests waiting toobe read form or written toohello storage disk.</span></span> |<span data-ttu-id="ffeb7-266">目前磁碟佇列長度</span><span class="sxs-lookup"><span data-stu-id="ffeb7-266">Current Disk Queue Length</span></span> |<span data-ttu-id="ffeb7-267">avgqu-sz</span><span class="sxs-lookup"><span data-stu-id="ffeb7-267">avgqu-sz</span></span> |
| <span data-ttu-id="ffeb7-268">**最大記憶體**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-268">**Max. Memory**</span></span> |<span data-ttu-id="ffeb7-269">所需記憶體數量 toorun 應用程式順暢</span><span class="sxs-lookup"><span data-stu-id="ffeb7-269">Amount of memory required toorun application smoothly</span></span> |<span data-ttu-id="ffeb7-270">% Committed Bytes in Use</span><span class="sxs-lookup"><span data-stu-id="ffeb7-270">% Committed Bytes in Use</span></span> |<span data-ttu-id="ffeb7-271">Use vmstat</span><span class="sxs-lookup"><span data-stu-id="ffeb7-271">Use vmstat</span></span> |
| <span data-ttu-id="ffeb7-272">**最大CPU**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-272">**Max. CPU**</span></span> |<span data-ttu-id="ffeb7-273">CPU 數量順暢需要 toorun 應用程式</span><span class="sxs-lookup"><span data-stu-id="ffeb7-273">Amount CPU required toorun application smoothly</span></span> |<span data-ttu-id="ffeb7-274">% Processor time</span><span class="sxs-lookup"><span data-stu-id="ffeb7-274">% Processor time</span></span> |<span data-ttu-id="ffeb7-275">%util</span><span class="sxs-lookup"><span data-stu-id="ffeb7-275">%util</span></span> |

<span data-ttu-id="ffeb7-276">深入了解 [iostat](http://linuxcommand.org/man_pages/iostat1.html) 和 [PerfMon](https://msdn.microsoft.com/library/aa645516.aspx)。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-276">Learn more about [iostat](http://linuxcommand.org/man_pages/iostat1.html) and [PerfMon](https://msdn.microsoft.com/library/aa645516.aspx).</span></span>

## <a name="optimizing-application-performance"></a><span data-ttu-id="ffeb7-277">最佳化應用程式效能</span><span class="sxs-lookup"><span data-stu-id="ffeb7-277">Optimizing Application Performance</span></span>
<span data-ttu-id="ffeb7-278">hello 影響效能的高階儲存體上執行的應用程式的主要因素是本質的 IO 要求，VM 大小、 磁碟大小、 磁碟、 磁碟快取、 執行緒和佇列深度的數字。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-278">hello main factors that influence performance of an application running on Premium Storage are Nature of IO Requests, VM size, Disk size, Number of disks, Disk Caching, Multithreading and Queue Depth.</span></span> <span data-ttu-id="ffeb7-279">您可以控制這些因素與 hello 系統所提供的參數。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-279">You can control some of these factors with knobs provided by hello system.</span></span> <span data-ttu-id="ffeb7-280">大部分的應用程式可能無法提供您選項 tooalter hello IO 大小和佇列深度直接。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-280">Most applications may not give you an option tooalter hello IO size and Queue Depth directly.</span></span> <span data-ttu-id="ffeb7-281">例如，如果您使用 SQL Server，您無法選擇 hello IO 大小和佇列深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-281">For example, if you are using SQL Server, you cannot choose hello IO size and queue depth.</span></span> <span data-ttu-id="ffeb7-282">SQL Server 會選擇 hello 最佳 IO 大小和佇列深度值 tooget hello 最高效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-282">SQL Server chooses hello optimal IO size and queue depth values tooget hello most performance.</span></span> <span data-ttu-id="ffeb7-283">它是重要 toounderstand hello 這兩種因素對效能的影響您應用程式，以便您可以提供適當的資源 toomeet 效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-283">It is important toounderstand hello effects of both types of factors on your application performance, so that you can provision appropriate resources toomeet performance needs.</span></span>

<span data-ttu-id="ffeb7-284">在本章節中，請參閱 toohello 應用程式需求檢查清單，讓您建立，tooidentify 需要多少 toooptimize 應用程式效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-284">Throughout this section, refer toohello application requirements checklist that you created, tooidentify how much you need toooptimize your application performance.</span></span> <span data-ttu-id="ffeb7-285">為基礎，您將會無法 toodetermine 其中的因素本節中您將需要 tootune。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-285">Based on that, you will be able toodetermine which factors from this section you will need tootune.</span></span> <span data-ttu-id="ffeb7-286">toowitness hello 每個因素對效能的影響您應用程式，執行效能評定，在您的應用程式設定的工具。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-286">toowitness hello effects of each factor on your application performance, run benchmarking tools on your application setup.</span></span> <span data-ttu-id="ffeb7-287">請參閱 toohello [Benchmarking](#Benchmarking) hello 本文章最後的步驟 toorun 一般效能評定工具在 Windows 和 Linux Vm 上的一節。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-287">Refer toohello [Benchmarking](#Benchmarking) section at hello end of this article for steps toorun common benchmarking tools on Windows and Linux VMs.</span></span>

### <a name="optimizing-iops-throughput-and-latency-at-a-glance"></a><span data-ttu-id="ffeb7-288">最佳化 IOPS、輸送量和延遲的速覽</span><span class="sxs-lookup"><span data-stu-id="ffeb7-288">Optimizing IOPS, Throughput and Latency at a glance</span></span>
<span data-ttu-id="ffeb7-289">hello 下表摘要列出所有 hello 效能因素和 hello 步驟 toooptimize IOPS、 輸送量和延遲。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-289">hello table below summarizes all hello performance factors and hello steps toooptimize IOPS, Throughput and Latency.</span></span> <span data-ttu-id="ffeb7-290">hello 後面此摘要的章節將說明每個因素是更深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-290">hello sections following this summary will describe each factor is much more depth.</span></span>

| &nbsp; | <span data-ttu-id="ffeb7-291">**IOPS**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-291">**IOPS**</span></span> | <span data-ttu-id="ffeb7-292">**輸送量**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-292">**Throughput**</span></span> | <span data-ttu-id="ffeb7-293">**延遲**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-293">**Latency**</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-294">**範例案例**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-294">**Example Scenario**</span></span> |<span data-ttu-id="ffeb7-295">需要極高每秒交易速率的企業 OLTP 應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-295">Enterprise OLTP application requiring very high transactions per second rate.</span></span> |<span data-ttu-id="ffeb7-296">處理大量資料的企業資料倉儲應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-296">Enterprise Data warehousing application processing large amounts of data.</span></span> |<span data-ttu-id="ffeb7-297">接近即時的應用程式需要即時回應 toouser 要求，例如線上遊戲。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-297">Near real-time applications requiring instant responses toouser requests, like online gaming.</span></span> |
| <span data-ttu-id="ffeb7-298">效能因素</span><span class="sxs-lookup"><span data-stu-id="ffeb7-298">Performance factors</span></span> | &nbsp; | &nbsp; | &nbsp; |
| <span data-ttu-id="ffeb7-299">**IO 大小**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-299">**IO size**</span></span> |<span data-ttu-id="ffeb7-300">較小 IO 大小會產生較高的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-300">Smaller IO size yields higher IOPS.</span></span> |<span data-ttu-id="ffeb7-301">較大 IO 大小 tooyields 較高的輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-301">Larger IO size tooyields higher Throughput.</span></span> | &nbsp;|
| <span data-ttu-id="ffeb7-302">**VM 大小**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-302">**VM size**</span></span> |<span data-ttu-id="ffeb7-303">使用 IOPS 大於應用程式需求的 VM 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-303">Use a VM size that offers IOPS greater than your application requirement.</span></span> <span data-ttu-id="ffeb7-304">請參閱這裡的 VM 大小及其 IOPS 限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-304">See VM sizes and their IOPS limits here.</span></span> |<span data-ttu-id="ffeb7-305">使用輸送量限制大於應用程式需求的 VM 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-305">Use a VM size with Throughput limit greater than your application requirement.</span></span> <span data-ttu-id="ffeb7-306">請參閱這裡的 VM 大小及其輸送量限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-306">See VM sizes and their Throughput limits here.</span></span> |<span data-ttu-id="ffeb7-307">使用調整限制大於應用程式需求的 VM 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-307">Use a VM size that offers scale limits greater than your application requirement.</span></span> <span data-ttu-id="ffeb7-308">請參閱這裡的 VM 大小及其限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-308">See VM sizes and their limits here.</span></span> |
| <span data-ttu-id="ffeb7-309">**磁碟大小**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-309">**Disk size**</span></span> |<span data-ttu-id="ffeb7-310">使用 IOPS 大於應用程式需求的磁碟大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-310">Use a disk size that offers IOPS greater than your application requirement.</span></span> <span data-ttu-id="ffeb7-311">請參閱這裡的磁碟大小及其 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-311">See disk sizes and their IOPS limits here.</span></span> |<span data-ttu-id="ffeb7-312">使用輸送量限制大於應用程式需求的磁碟大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-312">Use a disk size with Throughput limit greater than your application requirement.</span></span> <span data-ttu-id="ffeb7-313">請參閱這裡的磁碟大小及其輸送量限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-313">See disk sizes and their Throughput limits here.</span></span> |<span data-ttu-id="ffeb7-314">使用調整限制大於應用程式需求的磁碟大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-314">Use a disk size that offers scale limits greater than your application requirement.</span></span> <span data-ttu-id="ffeb7-315">請參閱這裡的磁碟大小及其限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-315">See disk sizes and their limits here.</span></span> |
| <span data-ttu-id="ffeb7-316">**VM 和磁碟調整限制**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-316">**VM and Disk Scale Limits**</span></span> |<span data-ttu-id="ffeb7-317">應大於驅動的高階儲存體磁碟的 IOPS 總數附加 tooit hello VM 大小所選的 IOPS 限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-317">IOPS limit of hello VM size chosen should be greater than total IOPS driven by premium storage disks attached tooit.</span></span> |<span data-ttu-id="ffeb7-318">應大於總輸送量受到高階儲存體磁碟附加 tooit hello VM 大小所選的輸送量限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-318">Throughput limit of hello VM size chosen should be greater than total Throughput driven by premium storage disks attached tooit.</span></span> |<span data-ttu-id="ffeb7-319">Hello VM 大小所選的小數位數限制必須大於附加的高階儲存體磁碟的總小數位數限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-319">Scale limits of hello VM size chosen must be greater than total scale limits of attached premium storage disks.</span></span> |
| <span data-ttu-id="ffeb7-320">**磁碟快取**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-320">**Disk Caching**</span></span> |<span data-ttu-id="ffeb7-321">與讀取大量作業 tooget 高階儲存體磁碟上啟用唯讀快取較高的讀取 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-321">Enable ReadOnly Cache on premium storage disks with Read heavy operations tooget higher Read IOPS.</span></span> | &nbsp; |<span data-ttu-id="ffeb7-322">啟用 premium 準備的大量作業 tooget 非常低的讀取延遲的儲存磁碟上的唯讀快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-322">Enable ReadOnly Cache on premium storage disks with Ready heavy operations tooget very low Read latencies.</span></span> |
| <span data-ttu-id="ffeb7-323">**磁碟串接**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-323">**Disk Striping**</span></span> |<span data-ttu-id="ffeb7-324">使用多個磁碟和等量磁碟區它們一起 tooget 合併的更高 IOPS 及輸送量限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-324">Use multiple disks and stripe them together tooget a combined higher IOPS and Throughput limit.</span></span> <span data-ttu-id="ffeb7-325">請注意，hello 結合的限制每個 VM 應高於 hello 附加的高階磁碟的結合的限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-325">Note that hello combined limit per VM should be higher than hello combined limits of attached premium disks.</span></span> | &nbsp; | &nbsp; |
| <span data-ttu-id="ffeb7-326">**等量大小**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-326">**Stripe Size**</span></span> |<span data-ttu-id="ffeb7-327">在 OLTP 應用程式中，隨機小型 IO 模式使用較小的等量大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-327">Smaller stripe size for random small IO pattern seen in OLTP applications.</span></span> <span data-ttu-id="ffeb7-328">例如，SQL Server OLTP 應用程式使用等量大小 64KB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-328">E.g., use stripe size of 64KB for SQL Server OLTP application.</span></span> |<span data-ttu-id="ffeb7-329">在資料倉儲應用程式中，循序大型 IO 模式使用較大的等量大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-329">Larger stripe size for sequential large IO pattern seen in Data Warehouse applications.</span></span> <span data-ttu-id="ffeb7-330">例如，SQL Server 資料倉儲應用程式使用 256KB 等量大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-330">E.g., use 256KB stripe size for SQL Server Data warehouse application.</span></span> | &nbsp; |
| <span data-ttu-id="ffeb7-331">**多執行緒處理**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-331">**Multithreading**</span></span> |<span data-ttu-id="ffeb7-332">使用多執行緒 toopush 高的數字的要求 tooPremium 存放裝置，將會導致 toohigher IOPS 及輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-332">Use multithreading toopush higher number of requests tooPremium Storage that will lead toohigher IOPS and Throughput.</span></span> <span data-ttu-id="ffeb7-333">例如，SQL Server 上設定高的 MAXDOP 值 tooallocate 更多的 Cpu tooSQL 伺服器。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-333">For example, on SQL Server set a high MAXDOP value tooallocate more CPUs tooSQL Server.</span></span> | &nbsp; | &nbsp; |
| <span data-ttu-id="ffeb7-334">**佇列深度**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-334">**Queue Depth**</span></span> |<span data-ttu-id="ffeb7-335">較大佇列深度會產生較高的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-335">Larger Queue Depth yields higher IOPS.</span></span> |<span data-ttu-id="ffeb7-336">較大佇列深度會產生較高的輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-336">Larger Queue Depth yields higher Throughput.</span></span> |<span data-ttu-id="ffeb7-337">較小佇列深度會產生較低的延遲。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-337">Smaller Queue Depth yields lower latencies.</span></span> |

## <a name="nature-of-io-requests"></a><span data-ttu-id="ffeb7-338">IO 要求的本質</span><span class="sxs-lookup"><span data-stu-id="ffeb7-338">Nature of IO Requests</span></span>
<span data-ttu-id="ffeb7-339">IO 要求是指應用程式執行的輸入/輸出作業單位。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-339">An IO request is a unit of input/output operation that your application will be performing.</span></span> <span data-ttu-id="ffeb7-340">識別 hello 本質的 IO 要求，隨機或循序讀取或寫入，小型或大型的可協助您判斷 hello 應用程式的效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-340">Identifying hello nature of IO requests, random or sequential, read or write, small or large, will help you determine hello performance requirements of your application.</span></span> <span data-ttu-id="ffeb7-341">它是非常重要的 toounderstand hello 性質的 IO 要求，toomake hello 正確決策設計您的應用程式基礎結構時。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-341">It is very important toounderstand hello nature of IO requests, toomake hello right decisions when designing your application infrastructure.</span></span>

<span data-ttu-id="ffeb7-342">IO 大小是 hello 的其中一個更重要的因素。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-342">IO size is one of hello more important factors.</span></span> <span data-ttu-id="ffeb7-343">hello IO 大小是由您的應用程式所產生的 hello 輸入/輸出作業要求 hello 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-343">hello IO size is hello size of hello input/output operation request generated by your application.</span></span> <span data-ttu-id="ffeb7-344">hello IO 大小會影響效能，尤其是在 hello IOPS 和 hello 應用程式的頻寬能夠 tooachieve。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-344">hello IO size has a significant impact on performance especially on hello IOPS and Bandwidth that hello application is able tooachieve.</span></span> <span data-ttu-id="ffeb7-345">hello 下列公式會顯示 hello 關係 IOPS、 IO 大小和頻寬/輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-345">hello following formula shows hello relationship between IOPS, IO size and Bandwidth/Throughput.</span></span>  
    ![](media/storage-premium-storage-performance/image1.png)

<span data-ttu-id="ffeb7-346">某些應用程式可讓您 tooalter 其 IO 大小，但在某些應用程式不需要。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-346">Some applications allow you tooalter their IO size, while some applications do not.</span></span> <span data-ttu-id="ffeb7-347">例如，SQL Server 判斷 hello 最佳 IO 大小本身，和不為使用者提供任何參數 toochange 它。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-347">For example, SQL Server determines hello optimal IO size itself, and does not provide users with any knobs toochange it.</span></span> <span data-ttu-id="ffeb7-348">在 hello 另一方面，Oracle 提供呼叫的參數[DB\_封鎖\_大小](https://docs.oracle.com/cd/B19306_01/server.102/b14211/iodesign.htm#i28815)使用您可以設定 hello hello 資料庫的 I/O 要求的大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-348">On hello other hand, Oracle provides a parameter called [DB\_BLOCK\_SIZE](https://docs.oracle.com/cd/B19306_01/server.102/b14211/iodesign.htm#i28815) using which you can configure hello I/O request size of hello database.</span></span>

<span data-ttu-id="ffeb7-349">如果您使用的應用程式不允許您 toochange hello IO 大小，用於這個發行項 toooptimize hello 效能是最相關的 tooyour 應用程式的 KPI hello 指導方針。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-349">If you are using an application, which does not allow you toochange hello IO size, use hello guidelines in this article toooptimize hello performance KPI that is most relevant tooyour application.</span></span> <span data-ttu-id="ffeb7-350">例如，</span><span class="sxs-lookup"><span data-stu-id="ffeb7-350">For example,</span></span>

* <span data-ttu-id="ffeb7-351">OLTP 應用程式會產生數百萬個小型和隨機的 IO 要求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-351">An OLTP application generates millions of small and random IO requests.</span></span> <span data-ttu-id="ffeb7-352">toohandle 這些類型的 IO 要求，您必須設計您的應用程式基礎結構 tooget 高 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-352">toohandle these type of IO requests, you must design your application infrastructure tooget higher IOPS.</span></span>  
* <span data-ttu-id="ffeb7-353">資料倉儲應用程式會產生大型和循序的 IO 要求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-353">A data warehousing application generates large and sequential IO requests.</span></span> <span data-ttu-id="ffeb7-354">toohandle 這些類型的 IO 要求，您必須設計您的應用程式基礎結構 tooget 較高的頻寬或輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-354">toohandle these type of IO requests, you must design your application infrastructure tooget higher Bandwidth or Throughput.</span></span>

<span data-ttu-id="ffeb7-355">如果您使用應用程式，可讓您 toochange hello IO 大小、 使用此規則的捲動方塊的 hello IO 此外大小 tooother 效能指導方針，</span><span class="sxs-lookup"><span data-stu-id="ffeb7-355">If you are using an application, which allows you toochange hello IO size, use this rule of thumb for hello IO size in addition tooother performance guidelines,</span></span>

* <span data-ttu-id="ffeb7-356">較小 IO 大小 tooget 高 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-356">Smaller IO size tooget higher IOPS.</span></span> <span data-ttu-id="ffeb7-357">例如，OLTP 應用程式使用 8 KB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-357">For example, 8 KB for an OLTP application.</span></span>  
* <span data-ttu-id="ffeb7-358">較大 IO 大小 tooget 較高的頻寬輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-358">Larger IO size tooget higher Bandwidth/Throughput.</span></span> <span data-ttu-id="ffeb7-359">例如，資料倉儲應用程式使用 1024 KB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-359">For example, 1024 KB for a data warehouse application.</span></span>

<span data-ttu-id="ffeb7-360">以下是範例上如何計算 hello IOPS 及輸送量/頻寬應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-360">Here is an example on how you can calculate hello IOPS and Throughput/Bandwidth for your application.</span></span> <span data-ttu-id="ffeb7-361">假設應用程式使用 P30 磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-361">Consider an application using a P30 disk.</span></span> <span data-ttu-id="ffeb7-362">hello 的最大 IOPS 及輸送量/頻寬 P30 磁碟可以達到是 5000 IOPS 和 200 MB 秒分別。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-362">hello maximum IOPS and Throughput/Bandwidth a P30 disk can achieve is 5000 IOPS and 200 MB per second respectively.</span></span> <span data-ttu-id="ffeb7-363">現在，如果您的應用程式需要的 hello 的 hello P30 磁碟和您的最大 IOPS 使用 IO 小 8 kb 為單位，例如 hello 產生的頻寬，您將會無法 tooget 會是 40 MB 每秒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-363">Now, if your application requires hello maximum IOPS from hello P30 disk and you use a smaller IO size like 8 KB, hello resulting Bandwidth you will be able tooget is 40 MB per second.</span></span> <span data-ttu-id="ffeb7-364">不過，如果您的應用程式需要 hello 最大輸送量/頻寬從 P30 磁碟，而且您使用較大的 IO 大小類似 1024 KB，hello 產生 IOPS 將會更少 200 的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-364">However, if your application requires hello maximum Throughput/Bandwidth from P30 disk, and you use a larger IO size like 1024 KB, hello resulting IOPS will be less, 200 IOPS.</span></span> <span data-ttu-id="ffeb7-365">因此，微調 hello IO 大小，使其符合這兩個應用程式的 IOPS 及輸送量/頻寬需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-365">Therefore, tune hello IO size such that it meets both your application's IOPS and Throughput/Bandwidth requirement.</span></span> <span data-ttu-id="ffeb7-366">下表摘要說明不同 IO 大小 hello 和其相對應 IOPS 及輸送量 P30 磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-366">Table below summarizes hello different IO sizes and their corresponding IOPS and Throughput for a P30 disk.</span></span>

| <span data-ttu-id="ffeb7-367">應用程式需求</span><span class="sxs-lookup"><span data-stu-id="ffeb7-367">Application Requirement</span></span> | <span data-ttu-id="ffeb7-368">I/O 大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-368">I/O size</span></span> | <span data-ttu-id="ffeb7-369">IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-369">IOPS</span></span> | <span data-ttu-id="ffeb7-370">輸送量/頻寬</span><span class="sxs-lookup"><span data-stu-id="ffeb7-370">Throughput/Bandwidth</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-371">最大 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-371">Max IOPS</span></span> |<span data-ttu-id="ffeb7-372">8 KB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-372">8 KB</span></span> |<span data-ttu-id="ffeb7-373">5,000</span><span class="sxs-lookup"><span data-stu-id="ffeb7-373">5,000</span></span> |<span data-ttu-id="ffeb7-374">每秒 40 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-374">40 MB per second</span></span> |
| <span data-ttu-id="ffeb7-375">最大輸送量</span><span class="sxs-lookup"><span data-stu-id="ffeb7-375">Max Throughput</span></span> |<span data-ttu-id="ffeb7-376">1024 KB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-376">1024 KB</span></span> |<span data-ttu-id="ffeb7-377">200</span><span class="sxs-lookup"><span data-stu-id="ffeb7-377">200</span></span> |<span data-ttu-id="ffeb7-378">每秒 200 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-378">200 MB per second</span></span> |
| <span data-ttu-id="ffeb7-379">最大輸送量 + 高 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-379">Max Throughput + high IOPS</span></span> |<span data-ttu-id="ffeb7-380">64 KB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-380">64 KB</span></span> |<span data-ttu-id="ffeb7-381">3,200</span><span class="sxs-lookup"><span data-stu-id="ffeb7-381">3,200</span></span> |<span data-ttu-id="ffeb7-382">每秒 200 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-382">200 MB per second</span></span> |
| <span data-ttu-id="ffeb7-383">最大 IOPS + 高輸送量</span><span class="sxs-lookup"><span data-stu-id="ffeb7-383">Max IOPS + high Throughput</span></span> |<span data-ttu-id="ffeb7-384">32 KB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-384">32 KB</span></span> |<span data-ttu-id="ffeb7-385">5,000</span><span class="sxs-lookup"><span data-stu-id="ffeb7-385">5,000</span></span> |<span data-ttu-id="ffeb7-386">每秒 160 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-386">160 MB per second</span></span> |

<span data-ttu-id="ffeb7-387">tooget IOPS 與頻寬高於 hello 最大值的單一高階儲存體磁碟時，使用多個一起的高階磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-387">tooget IOPS and Bandwidth higher than hello maximum value of a single premium storage disk, use multiple premium disks striped together.</span></span> <span data-ttu-id="ffeb7-388">例如，等量分割兩個 P30 磁碟 tooget 10000 IOPS 結合的 IOPS 或合併的輸送量為 400 MB 每秒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-388">For example, stripe two P30 disks tooget a combined IOPS of 10,000 IOPS or a combined Throughput of 400 MB per second.</span></span> <span data-ttu-id="ffeb7-389">Hello 下一節所述，您必須使用支援 hello 結合磁碟 IOPS 及輸送量的 VM 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-389">As explained in hello next section, you must use a VM size that supports hello combined disk IOPS and Throughput.</span></span>

> [!NOTE]
> <span data-ttu-id="ffeb7-390">隨著您增加任一 IOPS 或輸送量 hello 其他也會增加，請確定您不觸及輸送量或 hello 磁碟或 VM 的 IOPS 限制時增加其中一個。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-390">As you increase either IOPS or Throughput hello other also increases, make sure you do not hit throughput or IOPS limits of hello disk or VM when increasing either one.</span></span>
>
>

<span data-ttu-id="ffeb7-391">toowitness hello 的 IO 大小對應用程式效能的影響，您可以執行您的 VM 和磁碟上的效能評定工具。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-391">toowitness hello effects of IO size on application performance, you can run benchmarking tools on your VM and disks.</span></span> <span data-ttu-id="ffeb7-392">建立多個測試回合，並針對每個執行的 toosee hello 影響使用不同的 IO 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-392">Create multiple test runs and use different IO size for each run toosee hello impact.</span></span> <span data-ttu-id="ffeb7-393">請參閱 toohello [Benchmarking](#Benchmarking) hello 結尾這篇文章以取得詳細資料 > 一節。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-393">Refer toohello [Benchmarking](#Benchmarking) section at hello end of this article for more details.</span></span>

## <a name="high-scale-vm-sizes"></a><span data-ttu-id="ffeb7-394">高延展性 VM 大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-394">High Scale VM Sizes</span></span>
<span data-ttu-id="ffeb7-395">當您開始設計的應用程式時，其中第一個項目 toodo hello 是，選擇您的應用程式的 VM toohost。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-395">When you start designing an application, one of hello first things toodo is, choose a VM toohost your application.</span></span> <span data-ttu-id="ffeb7-396">進階儲存體提供高延展性 VM 大小，可以執行需要更高計算能力和較高本機磁碟 I/O 效能的應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-396">Premium Storage comes with High Scale VM sizes that can run applications requiring higher compute power and a high local disk I/O performance.</span></span> <span data-ttu-id="ffeb7-397">這些 Vm 提供更快的處理器、 記憶體-核心比率較高，以及 Solid-State 磁碟機 (SSD) hello 本機磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-397">These VMs provide faster processors, a higher memory-to-core ratio, and a Solid-State Drive (SSD) for hello local disk.</span></span> <span data-ttu-id="ffeb7-398">高比例 Vm 支援進階儲存體的範例包括 hello DS、 DSv2 及 GS 系列 Vm。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-398">Examples of High Scale VMs supporting Premium Storage are hello DS, DSv2 and GS series VMs.</span></span>

<span data-ttu-id="ffeb7-399">高延展性 VM 有各種不同大小，以及不同數目的 CPU 核心、記憶體、作業系統和暫存磁碟大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-399">High Scale VMs are available in different sizes with a different number of CPU cores, memory, OS and temporary disk size.</span></span> <span data-ttu-id="ffeb7-400">每個 VM 的大小也會有資料磁碟，您可以連接 toohello VM 的最大數目。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-400">Each VM size also has maximum number of data disks that you can attach toohello VM.</span></span> <span data-ttu-id="ffeb7-401">因此，選擇 hello VM 大小會影響多少處理、 記憶體和儲存體容量可供您的應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-401">Therefore, hello chosen VM size will affect how much processing, memory, and storage capacity is available for your application.</span></span> <span data-ttu-id="ffeb7-402">它也會影響 hello 計算和儲存成本。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-402">It also affects hello Compute and Storage cost.</span></span> <span data-ttu-id="ffeb7-403">例如，以下是 hello 最大 VM 大小 DS 系列、 DSv2 系列和 GS 系列中的 hello 規格：</span><span class="sxs-lookup"><span data-stu-id="ffeb7-403">For example, below are hello specifications of hello largest VM size in a DS series, DSv2 series and a GS series:</span></span>

| <span data-ttu-id="ffeb7-404">VM 大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-404">VM size</span></span> | <span data-ttu-id="ffeb7-405">CPU 核心</span><span class="sxs-lookup"><span data-stu-id="ffeb7-405">CPU cores</span></span> | <span data-ttu-id="ffeb7-406">記憶體</span><span class="sxs-lookup"><span data-stu-id="ffeb7-406">Memory</span></span> | <span data-ttu-id="ffeb7-407">VM 磁碟大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-407">VM disk sizes</span></span> | <span data-ttu-id="ffeb7-408">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-408">Max.</span></span> <span data-ttu-id="ffeb7-409">資料磁碟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-409">data disks</span></span> | <span data-ttu-id="ffeb7-410">快取大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-410">Cache size</span></span> | <span data-ttu-id="ffeb7-411">IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-411">IOPS</span></span> | <span data-ttu-id="ffeb7-412">頻寬快取 IO 限制</span><span class="sxs-lookup"><span data-stu-id="ffeb7-412">Bandwidth Cache IO limits</span></span> |
| --- | --- | --- | --- | --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-413">Standard_DS14</span><span class="sxs-lookup"><span data-stu-id="ffeb7-413">Standard_DS14</span></span> |<span data-ttu-id="ffeb7-414">16</span><span class="sxs-lookup"><span data-stu-id="ffeb7-414">16</span></span> |<span data-ttu-id="ffeb7-415">112 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-415">112 GB</span></span> |<span data-ttu-id="ffeb7-416">作業系統 = 1023 GB </span><span class="sxs-lookup"><span data-stu-id="ffeb7-416">OS = 1023 GB</span></span> <br> <span data-ttu-id="ffeb7-417">本機 SSD = 224 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-417">Local SSD = 224 GB</span></span> |<span data-ttu-id="ffeb7-418">32</span><span class="sxs-lookup"><span data-stu-id="ffeb7-418">32</span></span> |<span data-ttu-id="ffeb7-419">576 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-419">576 GB</span></span> |<span data-ttu-id="ffeb7-420">50,000 IOPS </span><span class="sxs-lookup"><span data-stu-id="ffeb7-420">50,000 IOPS</span></span> <br> <span data-ttu-id="ffeb7-421">每秒 512 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-421">512 MB per second</span></span> |<span data-ttu-id="ffeb7-422">4,000 IOPS 和每秒 33 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-422">4,000 IOPS and 33 MB per second</span></span> |
| <span data-ttu-id="ffeb7-423">Standard_GS5</span><span class="sxs-lookup"><span data-stu-id="ffeb7-423">Standard_GS5</span></span> |<span data-ttu-id="ffeb7-424">32</span><span class="sxs-lookup"><span data-stu-id="ffeb7-424">32</span></span> |<span data-ttu-id="ffeb7-425">448 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-425">448 GB</span></span> |<span data-ttu-id="ffeb7-426">作業系統 = 1023 GB </span><span class="sxs-lookup"><span data-stu-id="ffeb7-426">OS = 1023 GB</span></span> <br> <span data-ttu-id="ffeb7-427">本機 SSD = 896 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-427">Local SSD = 896 GB</span></span> |<span data-ttu-id="ffeb7-428">64</span><span class="sxs-lookup"><span data-stu-id="ffeb7-428">64</span></span> |<span data-ttu-id="ffeb7-429">4224 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-429">4224 GB</span></span> |<span data-ttu-id="ffeb7-430">80,000 IOPS </span><span class="sxs-lookup"><span data-stu-id="ffeb7-430">80,000 IOPS</span></span> <br> <span data-ttu-id="ffeb7-431">每秒 2,000 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-431">2,000 MB per second</span></span> |<span data-ttu-id="ffeb7-432">5,000 IOPS 和每秒 50 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-432">5,000 IOPS and 50 MB per second</span></span> |

<span data-ttu-id="ffeb7-433">tooview 的所有可用的 Azure VM 大小，完整清單，請參閱太[Windows VM 大小](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json)或[Linux VM 大小](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json)。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-433">tooview a complete list of all available Azure VM sizes, refer too[Windows VM sizes](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) or [Linux VM sizes](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json).</span></span> <span data-ttu-id="ffeb7-434">選擇符合的 VM 大小和小數位數 tooyour 預期應用程式效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-434">Choose a VM size that can meet and scale tooyour desired application performance requirements.</span></span> <span data-ttu-id="ffeb7-435">此外 toothis，考慮下列情況選擇 VM 大小的重要考量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-435">In addition toothis, take into account following important considerations when choosing VM sizes.</span></span>

<span data-ttu-id="ffeb7-436">*調整限制*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-436">*Scale Limits*</span></span>  
<span data-ttu-id="ffeb7-437">hello 最大 IOPS 限制每個 VM 和每個磁碟都不同，且彼此獨立。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-437">hello maximum IOPS limits per VM and per disk are different and independent of each other.</span></span> <span data-ttu-id="ffeb7-438">請確定 hello 應用程式正在推動 IOPS，hello VM 以及 hello premium 磁碟附加的 tooit hello 限制範圍內。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-438">Make sure that hello application is driving IOPS within hello limits of hello VM as well as hello premium disks attached tooit.</span></span> <span data-ttu-id="ffeb7-439">否則，應用程式效能會發生節流現象。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-439">Otherwise, application performance will experience throttling.</span></span>

<span data-ttu-id="ffeb7-440">例如，假設應用程式需求是最高 4,000 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-440">As an example, suppose an application requirement is a maximum of 4,000 IOPS.</span></span> <span data-ttu-id="ffeb7-441">tooachieve 此，您佈建 P30 磁碟 DS1 VM 上。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-441">tooachieve this, you provision a P30 disk on a DS1 VM.</span></span> <span data-ttu-id="ffeb7-442">hello P30 磁碟可以 too5，000 IOPS 向上傳遞。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-442">hello P30 disk can deliver up too5,000 IOPS.</span></span> <span data-ttu-id="ffeb7-443">不過，hello DS1 VM 是有限的 too3，200 的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-443">However, hello DS1 VM is limited too3,200 IOPS.</span></span> <span data-ttu-id="ffeb7-444">因此，hello 應用程式的效能會受到 hello VM 3,200 IOPS 限制，而且會降低的效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-444">Consequently, hello application performance will be constrained by hello VM limit at 3,200 IOPS and there will be degraded performance.</span></span> <span data-ttu-id="ffeb7-445">tooprevent 這種情況下，選擇 VM 和磁碟大小，將這兩個符合應用程式的需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-445">tooprevent this situation, choose a VM and disk size that will both meet application requirements.</span></span>

<span data-ttu-id="ffeb7-446">*作業成本*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-446">*Cost of Operation*</span></span>  
<span data-ttu-id="ffeb7-447">在許多情況下，使用進階儲存體的整體作業成本，可能會低於使用標準儲存體。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-447">In many cases, it is possible that your overall cost of operation using Premium Storage is lower than using Standard Storage.</span></span>

<span data-ttu-id="ffeb7-448">例如，假設應用程式需要 16,000 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-448">For example, consider an application requiring 16,000 IOPS.</span></span> <span data-ttu-id="ffeb7-449">tooachieve 這種效能，您將需要標準\_D14 Azure IaaS VM，而可再提供使用 32 標準儲存體 1 TB 磁碟 16000 最大值 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-449">tooachieve this performance, you will need a Standard\_D14 Azure IaaS VM, which can give a maximum IOPS of 16,000 using 32 standard storage 1TB disks.</span></span> <span data-ttu-id="ffeb7-450">每個 1TB 標準儲存體磁碟最高可達到 500 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-450">Each 1TB standard storage disk can achieve a maximum of 500 IOPS.</span></span> <span data-ttu-id="ffeb7-451">hello 估計 $1,570 進行的每月 VM 的成本。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-451">hello estimated cost of this VM per month will be $1,570.</span></span> <span data-ttu-id="ffeb7-452">$1,638 進行 hello 32 個標準儲存體磁碟的每月成本。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-452">hello monthly cost of 32 standard storage disks will be $1,638.</span></span> <span data-ttu-id="ffeb7-453">hello 預估每月成本的總計會是 $3,208。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-453">hello estimated total monthly cost will be $3,208.</span></span>

<span data-ttu-id="ffeb7-454">相同但是 hello 如果您裝載高階儲存體上的應用程式，您將需要較小的 VM 大小和較少的高階儲存體磁碟，進而降低整體成本的 hello。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-454">However, if you hosted hello same application on Premium Storage, you will need a smaller VM size and fewer premium storage disks, thus reducing hello overall cost.</span></span> <span data-ttu-id="ffeb7-455">標準\_DS13 VM 可以符合 hello 16000 IOPS 需求使用四個 P30 磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-455">A Standard\_DS13 VM can meet hello 16,000 IOPS requirement using four P30 disks.</span></span> <span data-ttu-id="ffeb7-456">hello DS13 VM 25,600 最大 IOPS，每個 P30 磁碟 5,000 最大值 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-456">hello DS13 VM has a maximum IOPS of 25,600 and each P30 disk has a maximum IOPS of 5,000.</span></span> <span data-ttu-id="ffeb7-457">整體來說，這項設定可以達到 5,000 x 4 = 20,000 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-457">Overall, this configuration can achieve 5,000 x 4 = 20,000 IOPS.</span></span> <span data-ttu-id="ffeb7-458">hello 估計 $1,003 進行的每月 VM 的成本。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-458">hello estimated cost of this VM per month will be $1,003.</span></span> <span data-ttu-id="ffeb7-459">$544.34 進行 hello 的四個 P30 高階儲存體磁碟的每月成本。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-459">hello monthly cost of four P30 premium storage disks will be $544.34.</span></span> <span data-ttu-id="ffeb7-460">hello 預估每月成本的總計會是 $1,544。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-460">hello estimated total monthly cost will be $1,544.</span></span>

<span data-ttu-id="ffeb7-461">下表摘要說明 hello 成本分解的這種情況下，Standard 和 Premium 儲存體。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-461">Table below summarizes hello cost breakdown of this scenario for Standard and Premium Storage.</span></span>

| &nbsp; | <span data-ttu-id="ffeb7-462">**標準**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-462">**Standard**</span></span> | <span data-ttu-id="ffeb7-463">**高級**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-463">**Premium**</span></span> |
| --- | --- | --- |
| <span data-ttu-id="ffeb7-464">**每月的 VM 成本**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-464">**Cost of VM per month**</span></span> |<span data-ttu-id="ffeb7-465">$1,570.58 (Standard\_D14)</span><span class="sxs-lookup"><span data-stu-id="ffeb7-465">$1,570.58 (Standard\_D14)</span></span> |<span data-ttu-id="ffeb7-466">$1,003.66 (Standard\_DS13)</span><span class="sxs-lookup"><span data-stu-id="ffeb7-466">$1,003.66 (Standard\_DS13)</span></span> |
| <span data-ttu-id="ffeb7-467">**每月的磁碟成本**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-467">**Cost of Disks per month**</span></span> |<span data-ttu-id="ffeb7-468">$1,638.40 (32 x 1 TB 磁碟)</span><span class="sxs-lookup"><span data-stu-id="ffeb7-468">$1,638.40 (32 x 1 TB disks)</span></span> |<span data-ttu-id="ffeb7-469">$544.34 (4 x P30 磁碟)</span><span class="sxs-lookup"><span data-stu-id="ffeb7-469">$544.34 (4 x P30 disks)</span></span> |
| <span data-ttu-id="ffeb7-470">**每月的整體成本**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-470">**Overall Cost per month**</span></span> |<span data-ttu-id="ffeb7-471">$3,208.98</span><span class="sxs-lookup"><span data-stu-id="ffeb7-471">$3,208.98</span></span> |<span data-ttu-id="ffeb7-472">$1,544.34</span><span class="sxs-lookup"><span data-stu-id="ffeb7-472">$1,544.34</span></span> |

<span data-ttu-id="ffeb7-473">*Linux 散發版本*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-473">*Linux Distros*</span></span>  

<span data-ttu-id="ffeb7-474">透過 Azure 高階儲存體，您可以取得 hello 相同的 Vm 執行 Windows 和 Linux 的效能層級。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-474">With Azure Premium Storage, you get hello same level of Performance for VMs running Windows and Linux.</span></span> <span data-ttu-id="ffeb7-475">我們支援許多種 Linux 散發版本，而您可以看到 hello 完成清單[這裡](../../virtual-machines/linux/endorsed-distros.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json)。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-475">We support many flavors of Linux distros, and you can see hello complete list [here](../../virtual-machines/linux/endorsed-distros.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json).</span></span> <span data-ttu-id="ffeb7-476">請務必不同的散發版本是較佳的 toonote 適合不同類型的工作負載。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-476">It is important toonote that different distros are better suited for different types of workloads.</span></span> <span data-ttu-id="ffeb7-477">您會看到不同層級的效能視 hello distro 執行您的工作負載而定。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-477">You will see different levels of performance depending on hello distro your workload is running on.</span></span> <span data-ttu-id="ffeb7-478">測試您的應用程式的 hello Linux 散發版本，然後選擇最適合的其中一個 hello。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-478">Test hello Linux distros with your application and choose hello one that works best.</span></span>

<span data-ttu-id="ffeb7-479">當執行 Linux 與高階儲存體時，請檢查 hello 必要的驅動程式 tooensure 高效能的相關最新的更新。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-479">When running Linux with Premium Storage, check hello latest updates about required drivers tooensure high performance.</span></span>

## <a name="premium-storage-disk-sizes"></a><span data-ttu-id="ffeb7-480">進階儲存體磁碟大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-480">Premium Storage Disk Sizes</span></span>
<span data-ttu-id="ffeb7-481">Azure 進階儲存體目前提供七種磁碟大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-481">Azure Premium Storage offers seven disk sizes currently.</span></span> <span data-ttu-id="ffeb7-482">對於 IOPS、頻寬和儲存體，每個磁碟大小各有不同的調整限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-482">Each disk size has a different scale limit for IOPS, Bandwidth and Storage.</span></span> <span data-ttu-id="ffeb7-483">選擇 hello 正確 Premium 儲存體磁碟的大小視 hello 應用程式需求和 hello 高擴充能力的 VM 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-483">Choose hello right Premium Storage Disk size depending on hello application requirements and hello high scale VM size.</span></span> <span data-ttu-id="ffeb7-484">hello 下表顯示 hello 七個磁碟大小及其功能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-484">hello table below shows hello seven disks sizes and their capabilities.</span></span> <span data-ttu-id="ffeb7-485">受控磁碟目前僅支援 P4 和 P6 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-485">P4 and P6 sizes are currently only supported for Managed Disks.</span></span>

| <span data-ttu-id="ffeb7-486">進階磁碟類型</span><span class="sxs-lookup"><span data-stu-id="ffeb7-486">Premium Disks Type</span></span>  | <span data-ttu-id="ffeb7-487">P4</span><span class="sxs-lookup"><span data-stu-id="ffeb7-487">P4</span></span>    | <span data-ttu-id="ffeb7-488">P6</span><span class="sxs-lookup"><span data-stu-id="ffeb7-488">P6</span></span>    | <span data-ttu-id="ffeb7-489">P10</span><span class="sxs-lookup"><span data-stu-id="ffeb7-489">P10</span></span>   | <span data-ttu-id="ffeb7-490">P20</span><span class="sxs-lookup"><span data-stu-id="ffeb7-490">P20</span></span>   | <span data-ttu-id="ffeb7-491">P30</span><span class="sxs-lookup"><span data-stu-id="ffeb7-491">P30</span></span>   | <span data-ttu-id="ffeb7-492">P40</span><span class="sxs-lookup"><span data-stu-id="ffeb7-492">P40</span></span>   | <span data-ttu-id="ffeb7-493">P50</span><span class="sxs-lookup"><span data-stu-id="ffeb7-493">P50</span></span>   | 
|---------------------|-------|-------|-------|-------|-------|-------|-------|
| <span data-ttu-id="ffeb7-494">磁碟大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-494">Disk size</span></span>           | <span data-ttu-id="ffeb7-495">32 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-495">32 GB</span></span> | <span data-ttu-id="ffeb7-496">64 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-496">64 GB</span></span> | <span data-ttu-id="ffeb7-497">128 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-497">128 GB</span></span>| <span data-ttu-id="ffeb7-498">512 GB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-498">512 GB</span></span>            | <span data-ttu-id="ffeb7-499">1024 GB (1 TB)</span><span class="sxs-lookup"><span data-stu-id="ffeb7-499">1024 GB (1 TB)</span></span>    | <span data-ttu-id="ffeb7-500">2048 GB (2 TB)</span><span class="sxs-lookup"><span data-stu-id="ffeb7-500">2048 GB (2 TB)</span></span>    | <span data-ttu-id="ffeb7-501">4095 GB (4 TB)</span><span class="sxs-lookup"><span data-stu-id="ffeb7-501">4095 GB (4 TB)</span></span>    | 
| <span data-ttu-id="ffeb7-502">每一磁碟的 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-502">IOPS per disk</span></span>       | <span data-ttu-id="ffeb7-503">120</span><span class="sxs-lookup"><span data-stu-id="ffeb7-503">120</span></span>   | <span data-ttu-id="ffeb7-504">240</span><span class="sxs-lookup"><span data-stu-id="ffeb7-504">240</span></span>   | <span data-ttu-id="ffeb7-505">500</span><span class="sxs-lookup"><span data-stu-id="ffeb7-505">500</span></span>   | <span data-ttu-id="ffeb7-506">2300</span><span class="sxs-lookup"><span data-stu-id="ffeb7-506">2300</span></span>              | <span data-ttu-id="ffeb7-507">5000</span><span class="sxs-lookup"><span data-stu-id="ffeb7-507">5000</span></span>              | <span data-ttu-id="ffeb7-508">7500</span><span class="sxs-lookup"><span data-stu-id="ffeb7-508">7500</span></span>              | <span data-ttu-id="ffeb7-509">7500</span><span class="sxs-lookup"><span data-stu-id="ffeb7-509">7500</span></span>              | 
| <span data-ttu-id="ffeb7-510">每一磁碟的輸送量</span><span class="sxs-lookup"><span data-stu-id="ffeb7-510">Throughput per disk</span></span> | <span data-ttu-id="ffeb7-511">每秒 25 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-511">25 MB per second</span></span>  | <span data-ttu-id="ffeb7-512">每秒 50 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-512">50 MB per second</span></span>  | <span data-ttu-id="ffeb7-513">每秒 100 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-513">100 MB per second</span></span> | <span data-ttu-id="ffeb7-514">每秒 150 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-514">150 MB per second</span></span> | <span data-ttu-id="ffeb7-515">每秒 200 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-515">200 MB per second</span></span> | <span data-ttu-id="ffeb7-516">每秒 250 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-516">250 MB per second</span></span> | <span data-ttu-id="ffeb7-517">每秒 250 MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-517">250 MB per second</span></span> | 


<span data-ttu-id="ffeb7-518">所選大小的選擇取決於 hello 磁碟的磁碟數目。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-518">How many disks you choose depends on hello disk size chosen.</span></span> <span data-ttu-id="ffeb7-519">您可以使用單一 P50 磁碟或多個 P10 磁碟 toomeet 您應用程式的需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-519">You could use a single P50 disk or multiple P10 disks toomeet your application requirement.</span></span> <span data-ttu-id="ffeb7-520">請考慮進行 hello 選擇時下, 面所列的帳戶考量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-520">Take into account considerations listed below when making hello choice.</span></span>

<span data-ttu-id="ffeb7-521">*調整限制 (IOPS 和輸送量)*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-521">*Scale Limits (IOPS and Throughput)*</span></span>  
<span data-ttu-id="ffeb7-522">hello IOPS 及輸送量限制每個 Premium 磁碟大小是不同，不受影響從 hello VM 規模限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-522">hello IOPS and Throughput limits of each Premium disk size is different and independent from hello VM scale limits.</span></span> <span data-ttu-id="ffeb7-523">確定 hello IOPS 總數，而且從 hello 磁碟輸送量的 hello 的小數位數限制範圍內選擇的 VM 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-523">Make sure that hello total IOPS and Throughput from hello disks are within scale limits of hello chosen VM size.</span></span>

<span data-ttu-id="ffeb7-524">例如，如果應用程式需求是輸送量上限 250 MB/秒，而且您使用 DS4 VM 搭配單一 P30 磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-524">For example, if an application requirement is a maximum of 250 MB/sec Throughput and you are using a DS4 VM with a single P30 disk.</span></span> <span data-ttu-id="ffeb7-525">hello DS4 VM 可以放棄 too256 MB/sec 輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-525">hello DS4 VM can give up too256 MB/sec Throughput.</span></span> <span data-ttu-id="ffeb7-526">不過，單一 P30 磁碟有 200 MB/秒的輸送量限制。因此，hello 應用程式將會限制在 200 MB/秒到期 toohello 磁碟的限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-526">However, a single P30 disk has Throughput limit of 200 MB/sec. Consequently, hello application will be constrained at 200 MB/sec due toohello disk limit.</span></span> <span data-ttu-id="ffeb7-527">tooovercome 此限制，佈建多個資料磁碟 toohello VM 或調整您的磁碟 tooP40 或 P50。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-527">tooovercome this limit, provision more than one data disks toohello VM or resize your disks tooP40 or P50.</span></span>

> [!NOTE]
> <span data-ttu-id="ffeb7-528">Hello 磁碟 IOPS 及輸送量中不包含由 hello 快取的讀取，因此沒有主體 toodisk 限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-528">Reads served by hello cache are not included in hello disk IOPS and Throughput, hence not subject toodisk limits.</span></span> <span data-ttu-id="ffeb7-529">對於每個 VM，快取有其個別的 IOPS 和輸送量限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-529">Cache has its separate IOPS and Throughput limit per VM.</span></span>
>
> <span data-ttu-id="ffeb7-530">例如，剛開始時，讀取和寫入分別為 60 MB/秒和 40 MB/秒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-530">For example, initially your reads and writes are 60MB/sec and 40MB/sec respectively.</span></span> <span data-ttu-id="ffeb7-531">經過一段時間，hello 快取 warms 並且提供越來越多的 hello 讀取 hello 快取中使用。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-531">Over time, hello cache warms up and serves more and more of hello reads from hello cache.</span></span> <span data-ttu-id="ffeb7-532">然後，您可以從 hello 磁碟取得更高版本寫入輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-532">Then, you can get higher write Throughput from hello disk.</span></span>
>
>

<span data-ttu-id="ffeb7-533">*磁碟數量*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-533">*Number of Disks*</span></span>  
<span data-ttu-id="ffeb7-534">判斷的磁碟，您必須透過評估應用程式需求的 hello 數目。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-534">Determine hello number of disks you will need by assessing application requirements.</span></span> <span data-ttu-id="ffeb7-535">每個 VM 的大小也會具有 hello 數目，您可以附加 toohello VM 的磁碟上的限制。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-535">Each VM size also has a limit on hello number of disks that you can attach toohello VM.</span></span> <span data-ttu-id="ffeb7-536">一般而言，這是兩次 hello 核心數目。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-536">Typically, this is twice hello number of cores.</span></span> <span data-ttu-id="ffeb7-537">請確定該 hello 您選擇可以支援所需的磁碟的 hello 數目的 VM 大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-537">Ensure that hello VM size you choose can support hello number of disks needed.</span></span>

<span data-ttu-id="ffeb7-538">請記住，hello Premium 儲存體磁碟有較高的效能比較功能 tooStandard 存放磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-538">Remember, hello Premium Storage disks have higher performance capabilities compared tooStandard Storage disks.</span></span> <span data-ttu-id="ffeb7-539">因此，如果您要移轉您的應用程式，從使用標準儲存體 tooPremium 儲存體的 Azure IaaS VM，您可能需要較少的高階磁碟 tooachieve hello 應用程式的相同或更高的效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-539">Therefore, if you are migrating your application from Azure IaaS VM using Standard Storage tooPremium Storage, you will likely need fewer premium disks tooachieve hello same or higher performance for your application.</span></span>

## <a name="disk-caching"></a><span data-ttu-id="ffeb7-540">磁碟快取</span><span class="sxs-lookup"><span data-stu-id="ffeb7-540">Disk Caching</span></span>
<span data-ttu-id="ffeb7-541">採用 Azure 進階儲存體的高延展性 VM 有一項稱為 BlobCache 的多層快取技術。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-541">High Scale VMs that leverage Azure Premium Storage have a multi-tier caching technology called BlobCache.</span></span> <span data-ttu-id="ffeb7-542">BlobCache 結合了 hello 虛擬機器的 RAM 與 SSD 本機快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-542">BlobCache uses a combination of hello Virtual Machine RAM and local SSD for caching.</span></span> <span data-ttu-id="ffeb7-543">此快取可用 hello 高階儲存體持續性及 hello VM 本機磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-543">This cache is available for hello Premium Storage persistent disks and hello VM local disks.</span></span> <span data-ttu-id="ffeb7-544">根據預設，此快取設定為 tooRead 寫 OS 磁碟和 ReadOnly，進階儲存體上裝載的資料磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-544">By default, this cache setting is set tooRead/Write for OS disks and ReadOnly for data disks hosted on Premium Storage.</span></span> <span data-ttu-id="ffeb7-545">與 hello Premium 儲存體磁碟上啟用快取的磁碟，hello 高擴充能力 Vm 可以達到非常高的效能超過 hello 基礎磁碟效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-545">With disk caching enabled on hello Premium Storage disks, hello high scale VMs can achieve extremely high levels of performance that exceed hello underlying disk performance.</span></span>

> [!WARNING]
> <span data-ttu-id="ffeb7-546">變更 hello Azure 磁碟快取設定卸離及重新附加 hello 目標磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-546">Changing hello cache setting of an Azure disk detaches and re-attaches hello target disk.</span></span> <span data-ttu-id="ffeb7-547">如果它是 hello 作業系統磁碟時，會重新啟動 hello VM。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-547">If it is hello operating system disk, hello VM is restarted.</span></span> <span data-ttu-id="ffeb7-548">停止所有應用程式/服務，可能會受到此中斷作業再變更 hello 磁碟快取設定。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-548">Stop all applications/services that might be affected by this disruption before changing hello disk cache setting.</span></span>
>
>

<span data-ttu-id="ffeb7-549">toolearn 有關 BlobCache 的運作方式的詳細資訊，請參閱內部 toohello [Azure 高階儲存體](https://azure.microsoft.com/blog/azure-premium-storage-now-generally-available-2/)部落格文章。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-549">toolearn more about how BlobCache works, refer toohello Inside [Azure Premium Storage](https://azure.microsoft.com/blog/azure-premium-storage-now-generally-available-2/) blog post.</span></span>

<span data-ttu-id="ffeb7-550">重要 tooenable hello 右一組磁碟上的快取它。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-550">It is important tooenable cache on hello right set of disks.</span></span> <span data-ttu-id="ffeb7-551">您應該啟用 premium 磁碟上的磁碟快取，或不將取決於 hello 工作負載模式的磁碟將會處理。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-551">Whether you should enable disk caching on a premium disk or not will depend on hello workload pattern that disk will be handling.</span></span> <span data-ttu-id="ffeb7-552">下表顯示 hello 預設 OS 和資料磁碟的快取設定。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-552">Table below shows hello default cache settings for OS and Data disks.</span></span>

| <span data-ttu-id="ffeb7-553">**磁碟類型**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-553">**Disk Type**</span></span> | <span data-ttu-id="ffeb7-554">**預設快取設定**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-554">**Default Cache Setting**</span></span> |
| --- | --- |
| <span data-ttu-id="ffeb7-555">作業系統磁碟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-555">OS disk</span></span> |<span data-ttu-id="ffeb7-556">讀寫</span><span class="sxs-lookup"><span data-stu-id="ffeb7-556">ReadWrite</span></span> |
| <span data-ttu-id="ffeb7-557">資料磁碟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-557">Data disk</span></span> |<span data-ttu-id="ffeb7-558">None</span><span class="sxs-lookup"><span data-stu-id="ffeb7-558">None</span></span> |

<span data-ttu-id="ffeb7-559">下列是 hello 建議的磁碟快取設定的資料磁碟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-559">Following are hello recommended disk cache settings for data disks,</span></span>

| <span data-ttu-id="ffeb7-560">**磁碟快取設定**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-560">**Disk Caching Setting**</span></span> | <span data-ttu-id="ffeb7-561">**建議何時 toouse 這項設定**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-561">**Recommendation on when toouse this setting**</span></span> |
| --- | --- |
| <span data-ttu-id="ffeb7-562">None</span><span class="sxs-lookup"><span data-stu-id="ffeb7-562">None</span></span> |<span data-ttu-id="ffeb7-563">針對唯寫和大量寫入的磁碟，將主機快取設定為「無」。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-563">Configure host-cache as None for write-only and write-heavy disks.</span></span> |
| <span data-ttu-id="ffeb7-564">唯讀</span><span class="sxs-lookup"><span data-stu-id="ffeb7-564">ReadOnly</span></span> |<span data-ttu-id="ffeb7-565">針對唯讀和讀寫的磁碟，將主機快取設定為「唯讀」。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-565">Configure host-cache as ReadOnly for read-only and read-write disks.</span></span> |
| <span data-ttu-id="ffeb7-566">讀寫</span><span class="sxs-lookup"><span data-stu-id="ffeb7-566">ReadWrite</span></span> |<span data-ttu-id="ffeb7-567">依照 ReadWrite 只有當應用程式適當地處理寫入快取資料 toopersistent 磁碟需要時，請設定主機快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-567">Configure host-cache as ReadWrite only if your application properly  handles writing cached data toopersistent disks when needed.</span></span> |

<span data-ttu-id="ffeb7-568">*唯讀*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-568">*ReadOnly*</span></span>  
<span data-ttu-id="ffeb7-569">您可以在進階儲存體資料磁碟上設定「唯讀」快取，讓應用程式達到較低的讀取延遲，以及非常高的讀取 IOPS 和輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-569">By configuring ReadOnly caching on Premium Storage data disks, you can achieve low Read latency and get very high Read IOPS and Throughput for your application.</span></span> <span data-ttu-id="ffeb7-570">這是基於兩個理由，</span><span class="sxs-lookup"><span data-stu-id="ffeb7-570">This is due two reasons,</span></span>

1. <span data-ttu-id="ffeb7-571">從快取，位於 hello VM 記憶體和本機 SSD 執行讀取，速度比在 hello Azure blob 儲存體 hello 資料磁碟的讀取次數。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-571">Reads performed from cache, which is on hello VM memory and local SSD, are much faster than reads from hello data disk, which is on hello Azure blob storage.</span></span>  
2. <span data-ttu-id="ffeb7-572">高階儲存體不會計算的 hello 讀取由快取中，向 hello 磁碟 IOPS 及輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-572">Premium Storage does not count hello Reads served from cache, towards hello disk IOPS and Throughput.</span></span> <span data-ttu-id="ffeb7-573">因此，您的應用程式是可以 tooachieve 較高的總 IOPS 及輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-573">Therefore, your application is able tooachieve higher total IOPS and Throughput.</span></span>

<span data-ttu-id="ffeb7-574">*讀寫*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-574">*ReadWrite*</span></span>  
<span data-ttu-id="ffeb7-575">根據預設，hello OS 磁碟會有啟用 ReadWrite 快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-575">By default, hello OS disks have ReadWrite caching enabled.</span></span> <span data-ttu-id="ffeb7-576">我們最近也已在資料磁碟上增加支援「讀寫」快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-576">We have recently added support for ReadWrite caching on data disks as well.</span></span> <span data-ttu-id="ffeb7-577">如果您使用 ReadWrite 快取，您必須從快取 toopersistent 磁碟的正確方式 toowrite hello 資料。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-577">If you are using ReadWrite caching, you must have a proper way toowrite hello data from cache toopersistent disks.</span></span> <span data-ttu-id="ffeb7-578">例如，SQL Server 撰寫的控點快取資料 toohello 永續性儲存體磁碟本身。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-578">For example, SQL Server handles writing cached data toohello persistent storage disks on its own.</span></span> <span data-ttu-id="ffeb7-579">不會處理保存的 hello 的應用程式中使用 ReadWrite 快取資料可能會導致 toodata 遺失，如果需要 hello VM 損毀。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-579">Using ReadWrite cache with an application that does not handle persisting hello required data can lead toodata loss, if hello VM crashes.</span></span>

<span data-ttu-id="ffeb7-580">例如，您可以套用這些指導方針 tooSQL 伺服器進行 hello 下列高階儲存體上執行</span><span class="sxs-lookup"><span data-stu-id="ffeb7-580">As an example, you can apply these guidelines tooSQL Server running on Premium Storage by doing hello following,</span></span>

1. <span data-ttu-id="ffeb7-581">在裝載資料檔的進階儲存體磁碟上設定「唯讀」快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-581">Configure "ReadOnly" cache on premium storage disks hosting data files.</span></span>  
   <span data-ttu-id="ffeb7-582">a.</span><span class="sxs-lookup"><span data-stu-id="ffeb7-582">a.</span></span>  <span data-ttu-id="ffeb7-583">hello 快速讀取快取較低 hello SQL Server 查詢時，因為從 hello 從 hello 資料磁碟的快取比較 toodirectly 更快速擷取資料頁。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-583">hello fast reads from cache lower hello SQL Server query time since data pages are retrieved much faster from hello cache compared toodirectly from hello data disks.</span></span>  
   <span data-ttu-id="ffeb7-584">b.</span><span class="sxs-lookup"><span data-stu-id="ffeb7-584">b.</span></span>  <span data-ttu-id="ffeb7-585">由快取來服務讀取，表示高階資料磁碟會有額外的輸送量可用。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-585">Serving reads from cache, means there is additional Throughput available from premium data disks.</span></span> <span data-ttu-id="ffeb7-586">SQL Server 可以使用這個額外的輸送量來擷取更多資料頁和執行其他作業，例如備份/還原、批次載入和索引重建。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-586">SQL Server can use this additional Throughput towards retrieving more data pages and other operations like backup/restore, batch loads, and index rebuilds.</span></span>  
2. <span data-ttu-id="ffeb7-587">設定"None"高階儲存體上的快取磁碟裝載 hello 記錄檔。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-587">Configure "None" cache on premium storage disks hosting hello log files.</span></span>  
   <span data-ttu-id="ffeb7-588">a.</span><span class="sxs-lookup"><span data-stu-id="ffeb7-588">a.</span></span>  <span data-ttu-id="ffeb7-589">記錄檔以大量寫入的作業為主。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-589">Log files have primarily write-heavy operations.</span></span> <span data-ttu-id="ffeb7-590">因此，它們不會受益於 hello 唯讀快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-590">Therefore, they do not benefit from hello ReadOnly cache.</span></span>

## <a name="disk-striping"></a><span data-ttu-id="ffeb7-591">磁碟串接</span><span class="sxs-lookup"><span data-stu-id="ffeb7-591">Disk Striping</span></span>
<span data-ttu-id="ffeb7-592">當 VM 連接的數個 premium 儲存體永續性磁碟，hello 磁碟高擴充能力可以是等量一起 tooaggregate 其 IOPs、 頻寬和儲存體容量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-592">When a high scale VM is attached with several premium storage persistent disks, hello disks can be striped together tooaggregate their IOPs, bandwidth, and storage capacity.</span></span>

<span data-ttu-id="ffeb7-593">在 Windows 中，您可以一起使用儲存空間 toostripe 磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-593">On Windows, you can use Storage Spaces toostripe disks together.</span></span> <span data-ttu-id="ffeb7-594">您必須為集區中的每個磁碟設定一欄。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-594">You must configure one column for each disk in a pool.</span></span> <span data-ttu-id="ffeb7-595">否則，hello 的等量磁碟區的整體效能可能低數目超出預期，因為 toouneven hello 磁碟之間的流量分散。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-595">Otherwise, hello overall performance of striped volume can be lower than expected, due toouneven distribution of traffic across hello disks.</span></span>

<span data-ttu-id="ffeb7-596">重要事項： 使用伺服器管理員 」 UI，您可以設定 hello 總數 too8 等量磁碟區上的資料行。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-596">Important: Using Server Manager UI, you can set hello total number of columns up too8 for a striped volume.</span></span> <span data-ttu-id="ffeb7-597">在附加時 8 個以上的磁碟，請使用 PowerShell toocreate hello 磁碟區。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-597">When attaching more than 8 disks, use PowerShell toocreate hello volume.</span></span> <span data-ttu-id="ffeb7-598">使用 PowerShell，您可以設定資料行的 hello 數目等於 toohello 磁碟數目。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-598">Using PowerShell, you can set hello number of columns equal toohello number of disks.</span></span> <span data-ttu-id="ffeb7-599">例如，如果有 16 個磁碟，在單一的等量集;指定 16 個資料行中 hello *NumberOfColumns* hello 參數*New-virtualdisk* PowerShell cmdlet。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-599">For example, if there are 16 disks in a single stripe set; specify 16 columns in hello *NumberOfColumns* parameter of hello *New-VirtualDisk* PowerShell cmdlet.</span></span>

<span data-ttu-id="ffeb7-600">On Linux，請同時使用 hello MDADM 公用程式 toostripe 磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-600">On Linux, use hello MDADM utility toostripe disks together.</span></span> <span data-ttu-id="ffeb7-601">如需在 Linux 上的等量磁碟的詳細的步驟，請參閱太[Linux 上的 設定軟體 RAID](../../virtual-machines/linux/configure-raid.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json)。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-601">For detailed steps on striping disks on Linux refer too[Configure Software RAID on Linux](../../virtual-machines/linux/configure-raid.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json).</span></span>

<span data-ttu-id="ffeb7-602">*等量大小*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-602">*Stripe Size*</span></span>  
<span data-ttu-id="ffeb7-603">磁碟條狀配置中的重要組態是 hello 等量磁碟區大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-603">An important configuration in disk striping is hello stripe size.</span></span> <span data-ttu-id="ffeb7-604">hello 等量磁碟區大小或區塊大小是 hello 最小區塊的應用程式可以解決在等量磁碟區的資料。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-604">hello stripe size or block size is hello smallest chunk of data that application can address on a striped volume.</span></span> <span data-ttu-id="ffeb7-605">您所設定的 hello 等量磁碟區大小取決於 hello 類型的應用程式和它的要求模式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-605">hello stripe size you configure depends on hello type of application and its request pattern.</span></span> <span data-ttu-id="ffeb7-606">如果您選擇 hello 錯誤等量磁碟區大小，它可能會導致 tooIO 對齊錯誤，導致 toodegraded 應用程式的效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-606">If you choose hello wrong stripe size, it could lead tooIO misalignment, which leads toodegraded performance of your application.</span></span>

<span data-ttu-id="ffeb7-607">例如，如果您的應用程式所產生的 IO 要求大於 hello 磁碟等量磁碟區大小，hello 儲存系統將它寫入之間 stripe 單元界限在多個磁碟上。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-607">For example, if an IO request generated by your application is bigger than hello disk stripe size, hello storage system writes it across stripe unit boundaries on more than one disk.</span></span> <span data-ttu-id="ffeb7-608">當它是時間 tooaccess 該資料時，它會有 tooseek 跨越一個以上的等量磁碟區單位 toocomplete hello 要求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-608">When it is time tooaccess that data, it will have tooseek across more than one stripe units toocomplete hello request.</span></span> <span data-ttu-id="ffeb7-609">這類行為的 hello 累加的效果可能會導致 toosubstantial 效能降低。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-609">hello cumulative effect of such behavior can lead toosubstantial performance degradation.</span></span> <span data-ttu-id="ffeb7-610">在 hello 另一方面，如果 hello IO 要求的大小會小於等量磁碟區大小，而且如果它是隨機的 hello 的 IO 要求可能會加總 hello 上相同磁碟造成瓶頸和最終降低 hello IO 效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-610">On hello other hand, if hello IO request size is smaller than stripe size, and if it is random in nature, hello IO requests may add up on hello same disk causing a bottleneck and ultimately degrading hello IO performance.</span></span>

<span data-ttu-id="ffeb7-611">根據您的應用程式正在執行的工作負載 hello 類型，選擇適當的等量磁碟區大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-611">Depending on hello type of workload your application is running, choose an appropriate stripe size.</span></span> <span data-ttu-id="ffeb7-612">對於隨機小型 IO 要求，請使用較小的等量大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-612">For random small IO requests, use a smaller stripe size.</span></span> <span data-ttu-id="ffeb7-613">對於大型循序 IO 要求，請使用較大的等量大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-613">Whereas, for large sequential IO requests use a larger stripe size.</span></span> <span data-ttu-id="ffeb7-614">找出 hello 等量磁碟區大小 hello 應用程式建議您將在高階儲存體上執行。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-614">Find out hello stripe size recommendations for hello application you will be running on Premium Storage.</span></span> <span data-ttu-id="ffeb7-615">對於 SQL Server 而言，請將 OLTP 工作負載的等量大小設定為 64KB，而資料倉儲工作負載則設定為 256KB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-615">For SQL Server, configure stripe size of 64KB for OLTP workloads and 256KB for data warehousing workloads.</span></span> <span data-ttu-id="ffeb7-616">請參閱[Azure Vm 上的 SQL Server 的效能最佳做法](../../virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md#disks-guidance)toolearn 更多。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-616">See [Performance best practices for SQL Server on Azure VMs](../../virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md#disks-guidance) toolearn more.</span></span>

> [!NOTE]
> <span data-ttu-id="ffeb7-617">在 DS 系列 VM 上，最多可以串接 32 個進階儲存體磁碟，而在 GS 系列 VM 上，最多可以串接 64 個進階儲存體磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-617">You can stripe together a maximum of 32 premium storage disks on a DS series VM and 64 premium storage disks on a GS series VM.</span></span>
>
>

## <a name="multi-threading"></a><span data-ttu-id="ffeb7-618">多執行緒處理</span><span class="sxs-lookup"><span data-stu-id="ffeb7-618">Multi-threading</span></span>
<span data-ttu-id="ffeb7-619">設計 azure 高階儲存體的平台 toobe 大量平行。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-619">Azure has designed Premium Storage platform toobe massively parallel.</span></span> <span data-ttu-id="ffeb7-620">因此，多執行緒應用程式可達到的效能遠高於單一執行緒應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-620">Therefore, a multi-threaded application achieves much higher performance than a single-threaded application.</span></span> <span data-ttu-id="ffeb7-621">多執行緒應用程式跨多個執行緒會分割其工作，並提升其利用 hello VM 所執行的效率與最大的磁碟資源 toohello。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-621">A multi-threaded application splits up its tasks across multiple threads and increases efficiency of its execution by utilizing hello VM and disk resources toohello maximum.</span></span>

<span data-ttu-id="ffeb7-622">例如，如果您的應用程式在單一核心 VM 使用兩個執行緒上執行，hello CPU 可以 hello 兩個執行緒 tooachieve 效率之間切換。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-622">For example, if your application is running on a single core VM using two threads, hello CPU can switch between hello two threads tooachieve efficiency.</span></span> <span data-ttu-id="ffeb7-623">當一個執行緒正在等候磁碟 IO toocomplete 時，hello CPU 可以在另一個執行緒切換 toohello。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-623">While one thread is waiting on a disk IO toocomplete, hello CPU can switch toohello other thread.</span></span> <span data-ttu-id="ffeb7-624">如此一來，兩個執行緒可以完成比單一執行緒更多的工作。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-624">In this way, two threads can accomplish more than a single thread would.</span></span> <span data-ttu-id="ffeb7-625">如果 hello VM 有多個核心，進一步減少執行時間，因為每個核心可以平行執行的工作。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-625">If hello VM has more than one core, it further decreases running time since each core can execute tasks in parallel.</span></span>

<span data-ttu-id="ffeb7-626">您可能不是能 toochange hello 方式現成的應用程式實作單一執行緒或多執行緒處理。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-626">You may not be able toochange hello way an off-the-shelf application implements single threading or multi-threading.</span></span> <span data-ttu-id="ffeb7-627">例如，SQL Server 能夠處理多 CPU 與多核心。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-627">For example, SQL Server is capable of handling multi-CPU and multi-core.</span></span> <span data-ttu-id="ffeb7-628">不過，SQL Server 會決定在哪些情況下，它將會利用一個或多個執行緒 tooprocess 查詢。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-628">However, SQL Server decides under what conditions it will leverage one or more threads tooprocess a query.</span></span> <span data-ttu-id="ffeb7-629">它可以使用多執行緒來執行查詢和建立索引。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-629">It can run queries and build indexes using multi-threading.</span></span> <span data-ttu-id="ffeb7-630">包含的查詢，聯結大型資料表和排序資料，傳回 toohello 使用者之前，SQL Server 將可能使用多個執行緒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-630">For a query that involves joining large tables and sorting data before returning toohello user, SQL Server will likely use multiple threads.</span></span> <span data-ttu-id="ffeb7-631">但是，使用者無法控制 SQL Server 使用單一執行緒或多個執行緒來執行查詢。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-631">However, a user cannot control whether SQL Server executes a query using a single thread or multiple threads.</span></span>

<span data-ttu-id="ffeb7-632">沒有組態設定，您可以更改 tooinfluence 此多執行緒處理或平行處理的應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-632">There are configuration settings that you can alter tooinfluence this multi-threading or parallel processing of an application.</span></span> <span data-ttu-id="ffeb7-633">例如，如果 SQL Server 是 hello 最大 Degree of Parallelism 組態。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-633">For example, in case of SQL Server it is hello maximum Degree of Parallelism configuration.</span></span> <span data-ttu-id="ffeb7-634">呼叫 MAXDOP，此設定可讓您 tooconfigure hello 最大處理器數目平行處理時，可以使用 SQL Server。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-634">This setting called MAXDOP, allows you tooconfigure hello maximum number of processors SQL Server can use when parallel processing.</span></span> <span data-ttu-id="ffeb7-635">您可以為個別的查詢或索引作業設定 MAXDOP。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-635">You can configure MAXDOP for individual queries or index operations.</span></span> <span data-ttu-id="ffeb7-636">當您需要 toobalance 資源系統的效能關鍵應用程式時，這是有幫助。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-636">This is beneficial when you want toobalance resources of your system for a performance critical application.</span></span>

<span data-ttu-id="ffeb7-637">例如，假設您使用 SQL Server 的應用程式正在執行大型查詢和索引的作業在 hello 相同的時間。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-637">For example, say your application using SQL Server is executing a large query and an index operation at hello same time.</span></span> <span data-ttu-id="ffeb7-638">讓我們假設您想 hello 索引作業 toobe 詳細比較高效能 toohello 大型查詢。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-638">Let us assume that you wanted hello index operation toobe more performant compared toohello large query.</span></span> <span data-ttu-id="ffeb7-639">在這種情況下，您可以設定 hello 高於 hello hello 查詢 MAXDOP 值的索引作業 toobe MAXDOP 的值。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-639">In such a case, you can set MAXDOP value of hello index operation toobe higher than hello MAXDOP value for hello query.</span></span> <span data-ttu-id="ffeb7-640">如此一來，SQL Server 有更多數目的供 hello 索引作業比較 toohello 數目它可以設定專用的處理器的處理器 toohello 大型查詢。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-640">This way, SQL Server has more number of processors that it can leverage for hello index operation compared toohello number of processors it can dedicate toohello large query.</span></span> <span data-ttu-id="ffeb7-641">請記住，您無法控制 hello SQL Server 會使用每個作業的執行緒數目。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-641">Remember, you do not control hello number of threads SQL Server will use for each operation.</span></span> <span data-ttu-id="ffeb7-642">您可以控制 hello 正在專用的處理器數目上限多執行緒處理。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-642">You can control hello maximum number of processors being dedicated for multi-threading.</span></span>

<span data-ttu-id="ffeb7-643">深入了解 SQL Server 中的 [平行處理原則的程度](https://technet.microsoft.com/library/ms188611.aspx) 。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-643">Learn more about [Degrees of Parallelism](https://technet.microsoft.com/library/ms188611.aspx) in SQL Server.</span></span> <span data-ttu-id="ffeb7-644">了解這類設定會影響您的應用程式和其組態 toooptimize 效能，多執行緒處理。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-644">Find out such settings that influence multi-threading in your application and their configurations toooptimize performance.</span></span>

## <a name="queue-depth"></a><span data-ttu-id="ffeb7-645">佇列深度</span><span class="sxs-lookup"><span data-stu-id="ffeb7-645">Queue Depth</span></span>
<span data-ttu-id="ffeb7-646">hello 佇列深度或佇列長度，或佇列大小是 hello 數暫止的 IO 要求 hello 系統中。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-646">hello Queue Depth or Queue Length or Queue Size is hello number of pending IO requests in hello system.</span></span> <span data-ttu-id="ffeb7-647">佇列深度 hello 值決定多少 IO 作業可以對齊您的應用程式，將處理哪些 hello 存放磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-647">hello value of Queue Depth determines how many IO operations your application can line up, which hello storage disks will be processing.</span></span> <span data-ttu-id="ffeb7-648">它會影響所有 hello 三個應用程式效能指標，此文章 viz.IOPS、 輸送量和延遲所述。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-648">It affects all hello three application performance indicators that we discussed in this article viz., IOPS, Throughput and Latency.</span></span>

<span data-ttu-id="ffeb7-649">佇列深度與多執行緒處理密切相關。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-649">Queue Depth and multi-threading are closely related.</span></span> <span data-ttu-id="ffeb7-650">hello 佇列深度的值會指出多少多執行緒處理可以達成 hello 應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-650">hello Queue Depth value indicates how much multi-threading can be achieved by hello application.</span></span> <span data-ttu-id="ffeb7-651">Hello 佇列深度很大，如果應用程式可以執行更多作業同時，亦即，更多執行緒處理。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-651">If hello Queue Depth is large, application can execute more operations concurrently, in other words, more multi-threading.</span></span> <span data-ttu-id="ffeb7-652">如果 hello 佇列深度小，即使應用程式為多執行緒，它將會沒有足夠的請求，並行執行的方式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-652">If hello Queue Depth is small, even though application is multi-threaded, it will not have enough requests lined up for concurrent execution.</span></span>

<span data-ttu-id="ffeb7-653">一般而言，關閉 hello 放到書架應用程式不允許您 toochange hello 佇列深度，因為如果設定不正確，它會執行弊多於利。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-653">Typically, off hello shelf applications do not allow you toochange hello queue depth, because if set incorrectly it will do more harm than good.</span></span> <span data-ttu-id="ffeb7-654">應用程式會設定佇列深度 tooget hello 達到最佳效能的 hello 右值。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-654">Applications will set hello right value of queue depth tooget hello optimal performance.</span></span> <span data-ttu-id="ffeb7-655">不過，它是重要 toounderstand 這個概念，以便疑難排解您的應用程式的效能問題。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-655">However, it is important toounderstand this concept so that you can troubleshoot performance issues with your application.</span></span> <span data-ttu-id="ffeb7-656">您也可以觀察 hello 效果佇列深度的系統上執行效能評定工具。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-656">You can also observe hello effects of queue depth by running benchmarking tools on your system.</span></span>

<span data-ttu-id="ffeb7-657">某些應用程式提供設定 tooinfluence hello 佇列深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-657">Some applications provide settings tooinfluence hello Queue Depth.</span></span> <span data-ttu-id="ffeb7-658">例如，SQL Server 中的 hello MAXDOP （最大平行處理原則程度） 設定先前一節所述。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-658">For example, hello MAXDOP (maximum degree of parallelism) setting in SQL Server explained in previous section.</span></span> <span data-ttu-id="ffeb7-659">MAXDOP 是方式 tooinfluence 佇列深度和多執行緒處理，雖然它不會直接變更的 SQL Server hello 佇列深度的值。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-659">MAXDOP is a way tooinfluence Queue Depth and multi-threading, although it does not directly change hello Queue Depth value of SQL Server.</span></span>

<span data-ttu-id="ffeb7-660">*高佇列深度*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-660">*High Queue Depth*</span></span>  
<span data-ttu-id="ffeb7-661">高佇列深度排列 hello 磁碟上的更多作業。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-661">A high queue depth lines up more operations on hello disk.</span></span> <span data-ttu-id="ffeb7-662">hello 磁碟知道 hello 事先其佇列中的下一個要求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-662">hello disk knows hello next request in its queue ahead of time.</span></span> <span data-ttu-id="ffeb7-663">因此，hello 磁碟可以排程作業事先，而且最佳的順序處理它們。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-663">Consequently, hello disk can schedule operations ahead of time and process them in an optimal sequence.</span></span> <span data-ttu-id="ffeb7-664">Hello 應用程式傳送多個要求 toohello 磁碟，因為 hello 磁碟可以處理多個平行 IOs。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-664">Since hello application is sending more requests toohello disk, hello disk can process more parallel IOs.</span></span> <span data-ttu-id="ffeb7-665">最後，hello 應用程式將會無法 tooachieve 高 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-665">Ultimately, hello application will be able tooachieve higher IOPS.</span></span> <span data-ttu-id="ffeb7-666">應用程式正在處理其他要求，因為 hello hello 應用程式的總輸送量也會增加。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-666">Since application is processing more requests, hello total Throughput of hello application also increases.</span></span>

<span data-ttu-id="ffeb7-667">通常，當每個連接的磁碟上有 8-16+ 個未完成的 IO 時，應用程式可以達到最大輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-667">Typically, an application can achieve maximum Throughput with 8-16+ outstanding IOs per attached disk.</span></span> <span data-ttu-id="ffeb7-668">如果佇列深度是其中一個，應用程式不會將推送足夠 IOs toohello 系統，並會在指定時間處理較少數量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-668">If a Queue Depth is one, application is not pushing enough IOs toohello system, and it will process less amount of in a given period.</span></span> <span data-ttu-id="ffeb7-669">換句話說，輸送量較少。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-669">In other words, less Throughput.</span></span>

<span data-ttu-id="ffeb7-670">例如，在 SQL Server，設定 hello MAXDOP 值的查詢太"4"會通知它 toofour 核心 tooexecute hello 查詢可以使用的 SQL Server。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-670">For example, in SQL Server, setting hello MAXDOP value for a query too"4" informs SQL Server that it can use up toofour cores tooexecute hello query.</span></span> <span data-ttu-id="ffeb7-671">SQL Server 將會決定最佳佇列深度值和 hello 的核心數目為 hello 查詢執行。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-671">SQL Server will determine what is best queue depth value and hello number of cores for hello query execution.</span></span>

<span data-ttu-id="ffeb7-672">*最佳佇列深度*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-672">*Optimal Queue Depth*</span></span>  
<span data-ttu-id="ffeb7-673">佇列深度值太高也有其缺點。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-673">Very high queue depth value also has its drawbacks.</span></span> <span data-ttu-id="ffeb7-674">如果佇列深度的值太高，hello 應用程式會嘗試 toodrive 非常高 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-674">If queue depth value is too high, hello application will try toodrive very high IOPS.</span></span> <span data-ttu-id="ffeb7-675">除非應用程式的永續性磁碟已佈建足夠的 IOPS，否則這可能對應用程式延遲造成負面影響。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-675">Unless application has persistent disks with sufficient provisioned IOPS, this can negatively affect application latencies.</span></span> <span data-ttu-id="ffeb7-676">下列公式會顯示 hello IOPS、 延遲和佇列深度之間的關聯性。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-676">Following formula shows hello relationship between IOPS, Latency and Queue Depth.</span></span>  
    ![](media/storage-premium-storage-performance/image6.png)

<span data-ttu-id="ffeb7-677">您不應該設定佇列深度 tooany 高價值，但 tooan 最佳值，可以提供足夠的 IOPS 供 hello 應用程式，而不會影響延遲。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-677">You should not configure Queue Depth tooany high value, but tooan optimal value, which can deliver enough IOPS for hello application without affecting latencies.</span></span> <span data-ttu-id="ffeb7-678">比方說，如果 hello 應用程式的延遲需要 toobe 1 毫秒，hello 佇列深度所需的 tooachieve 5,000 IOPS 即 QD = 5000 x 0.001 = 5。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-678">For example, if hello application latency needs toobe 1 millisecond, hello Queue Depth required tooachieve 5,000 IOPS is, QD = 5000 x 0.001 = 5.</span></span>

<span data-ttu-id="ffeb7-679">*等量磁碟區的佇列深度*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-679">*Queue Depth for Striped Volume*</span></span>  
<span data-ttu-id="ffeb7-680">對於等量磁碟區，應該維持夠高的佇列深度，讓每個磁碟有各自的尖峰佇列深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-680">For a striped volume, maintain a high enough queue depth such that, every disk has a peak queue depth individually.</span></span> <span data-ttu-id="ffeb7-681">例如，請考慮推播通知的佇列深度為 2 的應用程式和 hello 等量磁碟區中有 4 個磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-681">For example, consider an application that pushes a queue depth of 2 and there are 4 disks in hello stripe.</span></span> <span data-ttu-id="ffeb7-682">hello 兩個的 IO 要求將會移 tootwo 磁碟，而剩餘的兩個磁碟會處於閒置狀態。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-682">hello two IO requests will go tootwo disks and remaining two disks will be idle.</span></span> <span data-ttu-id="ffeb7-683">因此，設定 hello 佇列深度，使所有 hello 磁碟可以都是忙碌中。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-683">Therefore, configure hello queue depth such that all hello disks can be busy.</span></span> <span data-ttu-id="ffeb7-684">下列公式會顯示如何 toodetermine hello 的等量磁碟區的佇列深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-684">Formula below shows how toodetermine hello queue depth of striped volumes.</span></span>  
    ![](media/storage-premium-storage-performance/image7.png)

## <a name="throttling"></a><span data-ttu-id="ffeb7-685">節流</span><span class="sxs-lookup"><span data-stu-id="ffeb7-685">Throttling</span></span>
<span data-ttu-id="ffeb7-686">Azure 高階儲存體佈建指定數目的 IOPS 及輸送量視 hello VM 大小和您所選擇的磁碟大小而定。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-686">Azure Premium Storage provisions specified number of IOPS and Throughput depending on hello VM sizes and disk sizes you choose.</span></span> <span data-ttu-id="ffeb7-687">每當您的應用程式會嘗試 toodrive IOPS 或輸送量上方的哪一個 hello VM 或磁碟可以處理這些限制，進階儲存體便會進行節流。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-687">Anytime your application tries toodrive IOPS or Throughput above these limits of what hello VM or disk can handle, Premium Storage will throttle it.</span></span> <span data-ttu-id="ffeb7-688">這會表示 hello 表單的應用程式中的效能降低的問題。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-688">This manifests in hello form of degraded performance in your application.</span></span> <span data-ttu-id="ffeb7-689">這可能表示延遲較高、輸送量較低或 IOPS 較低。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-689">This can mean higher latency, lower Throughput or lower IOPS.</span></span> <span data-ttu-id="ffeb7-690">如果進階儲存體不會節流，應用程式可能會超出其資源的能力負荷而完全失敗。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-690">If Premium Storage does not throttle, your application could completely fail by exceeding what its resources are capable of achieving.</span></span> <span data-ttu-id="ffeb7-691">因此，tooavoid 效能發出到期 toothrottling，一律佈建足夠的資源應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-691">So, tooavoid performance issues due toothrottling, always provision sufficient resources for your application.</span></span> <span data-ttu-id="ffeb7-692">請考量前述 hello VM 大小和上述的磁碟大小章節中。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-692">Take into consideration what we discussed in hello VM sizes and Disk sizes sections above.</span></span> <span data-ttu-id="ffeb7-693">效能評定，是最佳方式 toofigure hello 出哪些資源要 toohost 您的應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-693">Benchmarking is hello best way toofigure out what resources you will need toohost your application.</span></span>

## <a name="benchmarking"></a><span data-ttu-id="ffeb7-694">效能評定</span><span class="sxs-lookup"><span data-stu-id="ffeb7-694">Benchmarking</span></span>
<span data-ttu-id="ffeb7-695">效能評定，是模擬您的應用程式上的不同工作負載，以及測量 hello 應用程式效能，每個工作負載的 hello 程序。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-695">Benchmarking is hello process of simulating different workloads on your application and measuring hello application performance for each workload.</span></span> <span data-ttu-id="ffeb7-696">使用前一節中所述的 hello 步驟，您已經收集 hello 應用程式效能需求。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-696">Using hello steps described in an earlier section, you have gathered hello application performance requirements.</span></span> <span data-ttu-id="ffeb7-697">藉由執行效能評定 hello hello 應用程式裝載的 Vm 上的工具，您可以判斷您的應用程式可以達到進階儲存體的 hello 效能層級。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-697">By running benchmarking tools on hello VMs hosting hello application, you can determine hello performance levels that your application can achieve with Premium Storage.</span></span> <span data-ttu-id="ffeb7-698">在本節中，我們針對以 Azure 進階儲存體佈建的標準 DS14 VM，提供效能評定範例。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-698">In this section, we provide you examples of benchmarking a Standard DS14 VM provisioned with Azure Premium Storage disks.</span></span>

<span data-ttu-id="ffeb7-699">我們分別在 Windows 和 Linux 上使用一般效能評定工具 Iometer 和 FIO。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-699">We have used common benchmarking tools Iometer and FIO, for Windows and Linux respectively.</span></span> <span data-ttu-id="ffeb7-700">這些工具會繁衍多個執行緒模擬實際執行類似工作負載，以及測量 hello 系統效能。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-700">These tools spawn multiple threads simulating a production like workload, and measure hello system performance.</span></span> <span data-ttu-id="ffeb7-701">使用 hello 工具您也可以設定的參數如區塊大小和佇列深度，您通常不能變更應用程式。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-701">Using hello tools you can also configure parameters like block size and queue depth, which you normally cannot change for an application.</span></span> <span data-ttu-id="ffeb7-702">這可讓您更大的彈性 toodrive hello 最高效能大規模使用不同類型的應用程式工作負載的高階磁碟佈建的 VM 上。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-702">This gives you more flexibility toodrive hello maximum performance on a high scale VM provisioned with premium disks for different types of application workloads.</span></span> <span data-ttu-id="ffeb7-703">有關每個效能評定的工具，請瀏覽的 toolearn [Iometer](http://www.iometer.org/)和[FIO](http://freecode.com/projects/fio)。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-703">toolearn more about each benchmarking tool visit [Iometer](http://www.iometer.org/) and [FIO](http://freecode.com/projects/fio).</span></span>

<span data-ttu-id="ffeb7-704">toofollow hello 以下範例中，建立標準的 DS14 VM，並附加 11 高階儲存體磁碟 toohello VM。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-704">toofollow hello examples below, create a Standard DS14 VM and attach 11 Premium Storage disks toohello VM.</span></span> <span data-ttu-id="ffeb7-705">Hello 11 磁碟、 設定 10 個磁碟具有主機快取為"None"和 stripe 它們入呼叫 NoCacheWrites 磁碟區。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-705">Of hello 11 disks, configure 10 disks with host caching as "None" and stripe them into a volume called NoCacheWrites.</span></span> <span data-ttu-id="ffeb7-706">設定為"ReadOnly"hello 剩餘磁碟的快取的主機，並建立呼叫 CacheReads 與此磁碟的磁碟區。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-706">Configure host caching as "ReadOnly" on hello remaining disk and create a volume called CacheReads with this disk.</span></span> <span data-ttu-id="ffeb7-707">使用此安裝程式，您將無法 toosee hello 最大讀取和寫入效能標準的 DS14 VM。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-707">Using this setup, you will be able toosee hello maximum Read and Write performance from a Standard DS14 VM.</span></span> <span data-ttu-id="ffeb7-708">如需使用高階磁碟建立 DS14 VM 的詳細步驟，請移至太[建立和使用進階儲存體帳戶的虛擬機器資料磁碟](../storage-premium-storage.md)。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-708">For detailed steps about creating a DS14 VM with premium disks, go too[Create and use a Premium Storage account for a virtual machine data disk](../storage-premium-storage.md).</span></span>

<span data-ttu-id="ffeb7-709">*暖機 hello 快取*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-709">*Warming up hello Cache*</span></span>  
<span data-ttu-id="ffeb7-710">ReadOnly 主機快取與 hello 磁碟是可以 toogive hello 磁碟限制比高 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-710">hello disk with ReadOnly host caching will be able toogive higher IOPS than hello disk limit.</span></span> <span data-ttu-id="ffeb7-711">tooget 此上限值讀取效能 hello 主機快取，首先您必須準備此磁碟的 hello 快取。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-711">tooget this maximum read performance from hello host cache, first you must warm up hello cache of this disk.</span></span> <span data-ttu-id="ffeb7-712">這可確保該 hello 哪一種效能評定工具將 CacheReads 磁碟區的磁碟機讀取 IOs 實際叫用 hello 快取而且不 hello 磁碟直接。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-712">This ensures that hello Read IOs which benchmarking tool will drive on CacheReads volume actually hits hello cache and not hello disk directly.</span></span> <span data-ttu-id="ffeb7-713">hello 快取命中結果中的 hello 單一快取的其他 IOPS 啟用磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-713">hello cache hits result in additional IOPS from hello single cache enabled disk.</span></span>

> <span data-ttu-id="ffeb7-714">**重要事項：**</span><span class="sxs-lookup"><span data-stu-id="ffeb7-714">**Important:**</span></span>  
> <span data-ttu-id="ffeb7-715">您必須準備 hello 快取，然後再執行效能評定，每次重新啟動 VM。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-715">You must warm up hello cache before running benchmarking, every time VM is rebooted.</span></span>
>
>

#### <a name="iometer"></a><span data-ttu-id="ffeb7-716">Iometer</span><span class="sxs-lookup"><span data-stu-id="ffeb7-716">Iometer</span></span>
<span data-ttu-id="ffeb7-717">[下載 hello Iometer 工具](http://sourceforge.net/projects/iometer/files/iometer-stable/2006-07-27/iometer-2006.07.27.win32.i386-setup.exe/download)hello VM 上。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-717">[Download hello Iometer tool](http://sourceforge.net/projects/iometer/files/iometer-stable/2006-07-27/iometer-2006.07.27.win32.i386-setup.exe/download) on hello VM.</span></span>

<span data-ttu-id="ffeb7-718">*測試檔案*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-718">*Test file*</span></span>  
<span data-ttu-id="ffeb7-719">Iometer 使用，您會在其執行效能測試的 hello hello 磁碟區儲存的測試檔案。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-719">Iometer uses a test file that is stored on hello volume on which you will run hello benchmarking test.</span></span> <span data-ttu-id="ffeb7-720">它在磁碟機讀取和寫入這個測試檔案 toomeasure hello 磁碟 IOPS 及輸送量。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-720">It drives Reads and Writes on this test file toomeasure hello disk IOPS and Throughput.</span></span> <span data-ttu-id="ffeb7-721">如果您沒有提供此測試檔案，Iometer 會建立測試檔案。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-721">Iometer creates this test file if you have not provided one.</span></span> <span data-ttu-id="ffeb7-722">建立 hello CacheReads 和 NoCacheWrites 磁碟區上呼叫 iobw.tst 200 GB 測試檔案。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-722">Create a 200GB test file called iobw.tst on hello CacheReads and NoCacheWrites volumes.</span></span>

<span data-ttu-id="ffeb7-723">*存取規格*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-723">*Access Specifications*</span></span>  
<span data-ttu-id="ffeb7-724">hello 規格，要求 IO 大小，%讀取/寫入，%隨機/循序未設定使用中 Iometer hello 」 的存取規格 」 索引標籤。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-724">hello specifications, request IO size, % read/write, % random/sequential are configured using hello "Access Specifications" tab in Iometer.</span></span> <span data-ttu-id="ffeb7-725">每個 hello 案例，如下所述建立存取規格。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-725">Create an access specification for each of hello scenarios described below.</span></span> <span data-ttu-id="ffeb7-726">建立 hello 存取規格，並 [儲存] 以適當命名像 RandomWrites\_8k RandomReads\_8k。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-726">Create hello access specifications and "Save" with an appropriate name like – RandomWrites\_8K, RandomReads\_8K.</span></span> <span data-ttu-id="ffeb7-727">執行 hello 測試案例時，請選取 hello 對應規格。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-727">Select hello corresponding specification when running hello test scenario.</span></span>

<span data-ttu-id="ffeb7-728">以下顯示最大寫入 IOPS 案例的存取規格範例，</span><span class="sxs-lookup"><span data-stu-id="ffeb7-728">An example of access specifications for maximum Write IOPS scenario is shown below,</span></span>  
    ![](media/storage-premium-storage-performance/image8.png)

<span data-ttu-id="ffeb7-729">*最大 IOPS 測試規格*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-729">*Maximum IOPS Test Specifications*</span></span>  
<span data-ttu-id="ffeb7-730">toodemonstrate 最大 IOPs，使用較小的要求大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-730">toodemonstrate maximum IOPs, use smaller request size.</span></span> <span data-ttu-id="ffeb7-731">使用 8K 要求大小，並建立隨機寫入和讀取的規格。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-731">Use 8K request size and create specifications for Random Writes and Reads.</span></span>

| <span data-ttu-id="ffeb7-732">存取規格</span><span class="sxs-lookup"><span data-stu-id="ffeb7-732">Access Specification</span></span> | <span data-ttu-id="ffeb7-733">要求大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-733">Request size</span></span> | <span data-ttu-id="ffeb7-734">隨機 %</span><span class="sxs-lookup"><span data-stu-id="ffeb7-734">Random %</span></span> | <span data-ttu-id="ffeb7-735">讀取 %</span><span class="sxs-lookup"><span data-stu-id="ffeb7-735">Read %</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-736">RandomWrites\_8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-736">RandomWrites\_8K</span></span> |<span data-ttu-id="ffeb7-737">8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-737">8K</span></span> |<span data-ttu-id="ffeb7-738">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-738">100</span></span> |<span data-ttu-id="ffeb7-739">0</span><span class="sxs-lookup"><span data-stu-id="ffeb7-739">0</span></span> |
| <span data-ttu-id="ffeb7-740">RandomReads\_8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-740">RandomReads\_8K</span></span> |<span data-ttu-id="ffeb7-741">8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-741">8K</span></span> |<span data-ttu-id="ffeb7-742">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-742">100</span></span> |<span data-ttu-id="ffeb7-743">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-743">100</span></span> |

<span data-ttu-id="ffeb7-744">*最大輸送量測試規格*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-744">*Maximum Throughput Test Specifications*</span></span>  
<span data-ttu-id="ffeb7-745">toodemonstrate 最大的輸送量，使用較大要求大小。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-745">toodemonstrate maximum Throughput, use larger request size.</span></span> <span data-ttu-id="ffeb7-746">使用 64K 要求大小，並建立隨機寫入和讀取的規格。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-746">Use 64K request size and create specifications for Random Writes and Reads.</span></span>

| <span data-ttu-id="ffeb7-747">存取規格</span><span class="sxs-lookup"><span data-stu-id="ffeb7-747">Access Specification</span></span> | <span data-ttu-id="ffeb7-748">要求大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-748">Request size</span></span> | <span data-ttu-id="ffeb7-749">隨機 %</span><span class="sxs-lookup"><span data-stu-id="ffeb7-749">Random %</span></span> | <span data-ttu-id="ffeb7-750">讀取 %</span><span class="sxs-lookup"><span data-stu-id="ffeb7-750">Read %</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-751">RandomWrites\_64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-751">RandomWrites\_64K</span></span> |<span data-ttu-id="ffeb7-752">64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-752">64K</span></span> |<span data-ttu-id="ffeb7-753">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-753">100</span></span> |<span data-ttu-id="ffeb7-754">0</span><span class="sxs-lookup"><span data-stu-id="ffeb7-754">0</span></span> |
| <span data-ttu-id="ffeb7-755">RandomReads\_64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-755">RandomReads\_64K</span></span> |<span data-ttu-id="ffeb7-756">64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-756">64K</span></span> |<span data-ttu-id="ffeb7-757">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-757">100</span></span> |<span data-ttu-id="ffeb7-758">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-758">100</span></span> |

<span data-ttu-id="ffeb7-759">*執行 hello Iometer 測試*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-759">*Running hello Iometer Test*</span></span>  
<span data-ttu-id="ffeb7-760">執行下列 toowarm 快取的 hello 步驟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-760">Perform hello steps below toowarm up cache</span></span>

1. <span data-ttu-id="ffeb7-761">使用如下所示的值建立兩個存取規格</span><span class="sxs-lookup"><span data-stu-id="ffeb7-761">Create two access specifications with values shown below,</span></span>

   | <span data-ttu-id="ffeb7-762">名稱</span><span class="sxs-lookup"><span data-stu-id="ffeb7-762">Name</span></span> | <span data-ttu-id="ffeb7-763">要求大小</span><span class="sxs-lookup"><span data-stu-id="ffeb7-763">Request size</span></span> | <span data-ttu-id="ffeb7-764">隨機 %</span><span class="sxs-lookup"><span data-stu-id="ffeb7-764">Random %</span></span> | <span data-ttu-id="ffeb7-765">讀取 %</span><span class="sxs-lookup"><span data-stu-id="ffeb7-765">Read %</span></span> |
   | --- | --- | --- | --- |
   | <span data-ttu-id="ffeb7-766">RandomWrites\_1MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-766">RandomWrites\_1MB</span></span> |<span data-ttu-id="ffeb7-767">1MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-767">1MB</span></span> |<span data-ttu-id="ffeb7-768">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-768">100</span></span> |<span data-ttu-id="ffeb7-769">0</span><span class="sxs-lookup"><span data-stu-id="ffeb7-769">0</span></span> |
   | <span data-ttu-id="ffeb7-770">RandomReads\_1MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-770">RandomReads\_1MB</span></span> |<span data-ttu-id="ffeb7-771">1MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-771">1MB</span></span> |<span data-ttu-id="ffeb7-772">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-772">100</span></span> |<span data-ttu-id="ffeb7-773">100</span><span class="sxs-lookup"><span data-stu-id="ffeb7-773">100</span></span> |
2. <span data-ttu-id="ffeb7-774">執行 hello Iometer 測試初始化快取磁碟，並指定下列參數。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-774">Run hello Iometer test for initializing cache disk with following parameters.</span></span> <span data-ttu-id="ffeb7-775">使用三個背景工作執行緒 hello 目標磁碟區，以及 128 的佇列深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-775">Use three worker threads for hello target volume and a queue depth of 128.</span></span> <span data-ttu-id="ffeb7-776">設定 hello hello 測試 too2hrs hello [測試 Setup] 索引標籤上的 「 執行時間 」 的持續時間。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-776">Set hello "Run time" duration of hello test too2hrs on hello "Test Setup" tab.</span></span>

   | <span data-ttu-id="ffeb7-777">案例</span><span class="sxs-lookup"><span data-stu-id="ffeb7-777">Scenario</span></span> | <span data-ttu-id="ffeb7-778">目標磁碟區</span><span class="sxs-lookup"><span data-stu-id="ffeb7-778">Target Volume</span></span> | <span data-ttu-id="ffeb7-779">名稱</span><span class="sxs-lookup"><span data-stu-id="ffeb7-779">Name</span></span> | <span data-ttu-id="ffeb7-780">持續時間</span><span class="sxs-lookup"><span data-stu-id="ffeb7-780">Duration</span></span> |
   | --- | --- | --- | --- |
   | <span data-ttu-id="ffeb7-781">初始化快取磁碟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-781">Initialize Cache Disk</span></span> |<span data-ttu-id="ffeb7-782">CacheReads</span><span class="sxs-lookup"><span data-stu-id="ffeb7-782">CacheReads</span></span> |<span data-ttu-id="ffeb7-783">RandomWrites\_1MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-783">RandomWrites\_1MB</span></span> |<span data-ttu-id="ffeb7-784">2 小時</span><span class="sxs-lookup"><span data-stu-id="ffeb7-784">2hrs</span></span> |
3. <span data-ttu-id="ffeb7-785">執行 hello Iometer 測試暖機使用下列參數的快取磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-785">Run hello Iometer test for warming up cache disk with following parameters.</span></span> <span data-ttu-id="ffeb7-786">使用三個背景工作執行緒 hello 目標磁碟區，以及 128 的佇列深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-786">Use three worker threads for hello target volume and a queue depth of 128.</span></span> <span data-ttu-id="ffeb7-787">設定 hello hello 測試 too2hrs hello [測試 Setup] 索引標籤上的 「 執行時間 」 的持續時間。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-787">Set hello "Run time" duration of hello test too2hrs on hello "Test Setup" tab.</span></span>

   | <span data-ttu-id="ffeb7-788">案例</span><span class="sxs-lookup"><span data-stu-id="ffeb7-788">Scenario</span></span> | <span data-ttu-id="ffeb7-789">目標磁碟區</span><span class="sxs-lookup"><span data-stu-id="ffeb7-789">Target Volume</span></span> | <span data-ttu-id="ffeb7-790">名稱</span><span class="sxs-lookup"><span data-stu-id="ffeb7-790">Name</span></span> | <span data-ttu-id="ffeb7-791">持續時間</span><span class="sxs-lookup"><span data-stu-id="ffeb7-791">Duration</span></span> |
   | --- | --- | --- | --- |
   | <span data-ttu-id="ffeb7-792">準備快取磁碟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-792">Warm up Cache Disk</span></span> |<span data-ttu-id="ffeb7-793">CacheReads</span><span class="sxs-lookup"><span data-stu-id="ffeb7-793">CacheReads</span></span> |<span data-ttu-id="ffeb7-794">RandomReads\_1MB</span><span class="sxs-lookup"><span data-stu-id="ffeb7-794">RandomReads\_1MB</span></span> |<span data-ttu-id="ffeb7-795">2 小時</span><span class="sxs-lookup"><span data-stu-id="ffeb7-795">2hrs</span></span> |

<span data-ttu-id="ffeb7-796">快取磁碟就緒之後，繼續下面所列的 hello 測試案例。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-796">After cache disk is warmed up, proceed with hello test scenarios listed below.</span></span> <span data-ttu-id="ffeb7-797">toorun hello Iometer 測試使用至少三個工作者執行緒**每個**目標磁碟區。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-797">toorun hello Iometer test, use at least three worker threads for **each** target volume.</span></span> <span data-ttu-id="ffeb7-798">每個背景工作執行緒，選取 hello 目標磁碟區、 設定佇列深度並選取一個 hello 儲存測試規格，hello 資料表 toorun hello 對應的測試案例如下所示。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-798">For each worker thread, select hello target volume, set queue depth and select one of hello saved test specifications, as shown in hello table below, toorun hello corresponding test scenario.</span></span> <span data-ttu-id="ffeb7-799">hello 資料表也會顯示預期的結果的 IOPS 及輸送量時執行這些測試。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-799">hello table also shows expected results for IOPS and Throughput when running these tests.</span></span> <span data-ttu-id="ffeb7-800">在所有案例中，都使用較小的 IO 大小 8 KB 和較高的佇列深度 128。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-800">For all scenarios, a small IO size of 8KB and a high queue depth of 128 is used.</span></span>

| <span data-ttu-id="ffeb7-801">測試案例</span><span class="sxs-lookup"><span data-stu-id="ffeb7-801">Test Scenario</span></span> | <span data-ttu-id="ffeb7-802">目標磁碟區</span><span class="sxs-lookup"><span data-stu-id="ffeb7-802">Target Volume</span></span> | <span data-ttu-id="ffeb7-803">名稱</span><span class="sxs-lookup"><span data-stu-id="ffeb7-803">Name</span></span> | <span data-ttu-id="ffeb7-804">結果</span><span class="sxs-lookup"><span data-stu-id="ffeb7-804">Result</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="ffeb7-805">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-805">Max.</span></span> <span data-ttu-id="ffeb7-806">讀取 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-806">Read IOPS</span></span> |<span data-ttu-id="ffeb7-807">CacheReads</span><span class="sxs-lookup"><span data-stu-id="ffeb7-807">CacheReads</span></span> |<span data-ttu-id="ffeb7-808">RandomWrites\_8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-808">RandomWrites\_8K</span></span> |<span data-ttu-id="ffeb7-809">50,000 IOPS </span><span class="sxs-lookup"><span data-stu-id="ffeb7-809">50,000 IOPS</span></span> |
| <span data-ttu-id="ffeb7-810">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-810">Max.</span></span> <span data-ttu-id="ffeb7-811">寫入 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-811">Write IOPS</span></span> |<span data-ttu-id="ffeb7-812">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="ffeb7-812">NoCacheWrites</span></span> |<span data-ttu-id="ffeb7-813">RandomReads\_8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-813">RandomReads\_8K</span></span> |<span data-ttu-id="ffeb7-814">64,000 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-814">64,000 IOPS</span></span> |
| <span data-ttu-id="ffeb7-815">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-815">Max.</span></span> <span data-ttu-id="ffeb7-816">結合的 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-816">Combined IOPS</span></span> |<span data-ttu-id="ffeb7-817">CacheReads</span><span class="sxs-lookup"><span data-stu-id="ffeb7-817">CacheReads</span></span> |<span data-ttu-id="ffeb7-818">RandomWrites\_8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-818">RandomWrites\_8K</span></span> |<span data-ttu-id="ffeb7-819">100,000 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-819">100,000 IOPS</span></span> |
| <span data-ttu-id="ffeb7-820">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="ffeb7-820">NoCacheWrites</span></span> |<span data-ttu-id="ffeb7-821">RandomReads\_8K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-821">RandomReads\_8K</span></span> | &nbsp; | &nbsp; |
| <span data-ttu-id="ffeb7-822">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-822">Max.</span></span> <span data-ttu-id="ffeb7-823">讀取 MB/秒</span><span class="sxs-lookup"><span data-stu-id="ffeb7-823">Read MB/sec</span></span> |<span data-ttu-id="ffeb7-824">CacheReads</span><span class="sxs-lookup"><span data-stu-id="ffeb7-824">CacheReads</span></span> |<span data-ttu-id="ffeb7-825">RandomWrites\_64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-825">RandomWrites\_64K</span></span> |<span data-ttu-id="ffeb7-826">524 MB/秒</span><span class="sxs-lookup"><span data-stu-id="ffeb7-826">524 MB/sec</span></span> |
| <span data-ttu-id="ffeb7-827">最大</span><span class="sxs-lookup"><span data-stu-id="ffeb7-827">Max.</span></span> <span data-ttu-id="ffeb7-828">寫入 MB/秒</span><span class="sxs-lookup"><span data-stu-id="ffeb7-828">Write MB/sec</span></span> |<span data-ttu-id="ffeb7-829">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="ffeb7-829">NoCacheWrites</span></span> |<span data-ttu-id="ffeb7-830">RandomReads\_64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-830">RandomReads\_64K</span></span> |<span data-ttu-id="ffeb7-831">524 MB/秒</span><span class="sxs-lookup"><span data-stu-id="ffeb7-831">524 MB/sec</span></span> |
| <span data-ttu-id="ffeb7-832">結合的 MB/秒</span><span class="sxs-lookup"><span data-stu-id="ffeb7-832">Combined MB/sec</span></span> |<span data-ttu-id="ffeb7-833">CacheReads</span><span class="sxs-lookup"><span data-stu-id="ffeb7-833">CacheReads</span></span> |<span data-ttu-id="ffeb7-834">RandomWrites\_64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-834">RandomWrites\_64K</span></span> |<span data-ttu-id="ffeb7-835">1000 MB/秒</span><span class="sxs-lookup"><span data-stu-id="ffeb7-835">1000 MB/sec</span></span> |
| <span data-ttu-id="ffeb7-836">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="ffeb7-836">NoCacheWrites</span></span> |<span data-ttu-id="ffeb7-837">RandomReads\_64K</span><span class="sxs-lookup"><span data-stu-id="ffeb7-837">RandomReads\_64K</span></span> | &nbsp; | &nbsp; |

<span data-ttu-id="ffeb7-838">以下是 hello 的螢幕擷取畫面 Iometer 結合的 IOPS 及輸送量案例的測試結果。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-838">Below are screenshots of hello Iometer test results for combined IOPS and Throughput scenarios.</span></span>

<span data-ttu-id="ffeb7-839">*結合的讀取和寫入最大 IOPS*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-839">*Combined Reads and Writes Maximum IOPS*</span></span>  
![](media/storage-premium-storage-performance/image9.png)

<span data-ttu-id="ffeb7-840">*結合的讀取和寫入最大輸送量*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-840">*Combined Reads and Writes Maximum Throughput*</span></span>  
![](media/storage-premium-storage-performance/image10.png)

### <a name="fio"></a><span data-ttu-id="ffeb7-841">FIO</span><span class="sxs-lookup"><span data-stu-id="ffeb7-841">FIO</span></span>
<span data-ttu-id="ffeb7-842">FIO 為普遍使用的工具 toobenchmark 儲存 hello Linux Vm 上。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-842">FIO is a popular tool toobenchmark storage on hello Linux VMs.</span></span> <span data-ttu-id="ffeb7-843">它擁有 hello 彈性 tooselect IO 大小不同，連續或隨機讀取和寫入。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-843">It has hello flexibility tooselect different IO sizes, sequential or random reads and writes.</span></span> <span data-ttu-id="ffeb7-844">它會產生背景工作執行緒或處理程序 tooperform hello 指定 I/O 作業。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-844">It spawns worker threads or processes tooperform hello specified I/O operations.</span></span> <span data-ttu-id="ffeb7-845">您可以指定 hello 類型的 I/O 作業每個工作者執行緒必須使用工作檔案執行。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-845">You can specify hello type of I/O operations each worker thread must perform using job files.</span></span> <span data-ttu-id="ffeb7-846">我們建立一個工作檔案，每個以下的 hello 範例中所述的案例。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-846">We created one job file per scenario illustrated in hello examples below.</span></span> <span data-ttu-id="ffeb7-847">您可以變更這些工作檔案 toobenchmark 不同工作負載在高階儲存體上執行中的 hello 規格。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-847">You can change hello specifications in these job files toobenchmark different workloads running on Premium Storage.</span></span> <span data-ttu-id="ffeb7-848">在 hello 範例中，我們會使用標準的 DS 14 VM 執行**Ubuntu**。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-848">In hello examples, we are using a Standard DS 14 VM running **Ubuntu**.</span></span> <span data-ttu-id="ffeb7-849">使用相同的安裝程式所述的 hello hello 開頭的 hello[效能評定區段](#Benchmarking)和熱機 hello 快取，才能執行效能測試的 hello。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-849">Use hello same setup described in hello beginning of hello [Benchmarking section](#Benchmarking) and warm up hello cache before running hello benchmarking tests.</span></span>

<span data-ttu-id="ffeb7-850">開始進行之前，請先在虛擬機器上 [下載 FIO](https://github.com/axboe/fio) 並安裝。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-850">Before you begin, [download FIO](https://github.com/axboe/fio) and install it on your virtual machine.</span></span>

<span data-ttu-id="ffeb7-851">執行 hello Ubuntu，如下列命令</span><span class="sxs-lookup"><span data-stu-id="ffeb7-851">Run hello following command for Ubuntu,</span></span>

```
apt-get install fio
```

<span data-ttu-id="ffeb7-852">我們將使用來推動寫入作業的四個工作者執行緒和四個背景工作執行緒驅動 hello 磁碟上的讀取作業。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-852">We will use four worker threads for driving Write operations and four worker threads for driving Read operations on hello disks.</span></span> <span data-ttu-id="ffeb7-853">hello 寫入背景工作將會推動流量具有 10 的磁碟快取設定太 hello 「 無 」 磁碟區上 「 無 」。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-853">hello Write workers will be driving traffic on hello "nocache" volume, which has 10 disks with cache set too"None".</span></span> <span data-ttu-id="ffeb7-854">hello 讀取背景工作將會推動流量 hello"readcache 「 磁碟區，也有 1 個磁碟快取設定"ReadOnly"。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-854">hello Read workers will be driving traffic on hello "readcache" volume, which has 1 disk with cache set too"ReadOnly".</span></span>

<span data-ttu-id="ffeb7-855">*最大寫入 IOPS*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-855">*Maximum Write IOPS*</span></span>  
<span data-ttu-id="ffeb7-856">建立具有下列規格 tooget hello 工作檔案寫入的最大 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-856">Create hello job file with following specifications tooget maximum Write IOPS.</span></span> <span data-ttu-id="ffeb7-857">將它命名為 "fiowrite.ini"。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-857">Name it "fiowrite.ini".</span></span>

```
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=8k

[writer1]
rw=randwrite
directory=/mnt/nocache
[writer2]
rw=randwrite
directory=/mnt/nocache
[writer3]
rw=randwrite
directory=/mnt/nocache
[writer4]
rw=randwrite
directory=/mnt/nocache
```

<span data-ttu-id="ffeb7-858">請注意 hello 遵循遵循先前章節所述的 hello 設計指導方針的重要事情。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-858">Note hello follow key things that are in line with hello design guidelines discussed in previous sections.</span></span> <span data-ttu-id="ffeb7-859">這些規格是不可或缺的 toodrive 最大 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-859">These specifications are essential toodrive maximum IOPS,</span></span>  

* <span data-ttu-id="ffeb7-860">較高的佇列深度 256。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-860">A high queue depth of 256.</span></span>  
* <span data-ttu-id="ffeb7-861">較小的區塊大小 8KB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-861">A small block size of 8KB.</span></span>  
* <span data-ttu-id="ffeb7-862">執行隨機寫入的多個執行緒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-862">Multiple threads performing random writes.</span></span>

<span data-ttu-id="ffeb7-863">執行下列的 hello FIO 測試 30 秒，關閉命令 tookick hello</span><span class="sxs-lookup"><span data-stu-id="ffeb7-863">Run hello following command tookick off hello FIO test for 30 seconds,</span></span>  

```
sudo fio --runtime 30 fiowrite.ini
```

<span data-ttu-id="ffeb7-864">雖然 hello 測試執行時，您會無法 toosee hello 數目寫入 IOPS hello VM 和 Premium 磁碟傳遞。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-864">While hello test runs, you will be able toosee hello number of write IOPS hello VM and Premium disks are delivering.</span></span> <span data-ttu-id="ffeb7-865">Hello 以下範例所示，hello DS14 VM 會將其最大寫入 IOPS 限制的 50,000 的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-865">As shown in hello sample below, hello DS14 VM is delivering its maximum write IOPS limit of 50,000 IOPS.</span></span>  
    ![](media/storage-premium-storage-performance/image11.png)

<span data-ttu-id="ffeb7-866">*最大讀取 IOPS*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-866">*Maximum Read IOPS*</span></span>  
<span data-ttu-id="ffeb7-867">建立具有下列規格 tooget hello 工作檔案讀取的最大 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-867">Create hello job file with following specifications tooget maximum Read IOPS.</span></span> <span data-ttu-id="ffeb7-868">將它命名為 "fioread.ini"。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-868">Name it "fioread.ini".</span></span>

```
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=8k

[reader1]
rw=randread
directory=/mnt/readcache
[reader2]
rw=randread
directory=/mnt/readcache
[reader3]
rw=randread
directory=/mnt/readcache
[reader4]
rw=randread
directory=/mnt/readcache
```

<span data-ttu-id="ffeb7-869">請注意 hello 遵循遵循先前章節所述的 hello 設計指導方針的重要事情。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-869">Note hello follow key things that are in line with hello design guidelines discussed in previous sections.</span></span> <span data-ttu-id="ffeb7-870">這些規格是不可或缺的 toodrive 最大 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-870">These specifications are essential toodrive maximum IOPS,</span></span>

* <span data-ttu-id="ffeb7-871">較高的佇列深度 256。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-871">A high queue depth of 256.</span></span>  
* <span data-ttu-id="ffeb7-872">較小的區塊大小 8KB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-872">A small block size of 8KB.</span></span>  
* <span data-ttu-id="ffeb7-873">執行隨機寫入的多個執行緒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-873">Multiple threads performing random writes.</span></span>

<span data-ttu-id="ffeb7-874">執行下列的 hello FIO 測試 30 秒，關閉命令 tookick hello</span><span class="sxs-lookup"><span data-stu-id="ffeb7-874">Run hello following command tookick off hello FIO test for 30 seconds,</span></span>

```
sudo fio --runtime 30 fioread.ini
```

<span data-ttu-id="ffeb7-875">Hello 測試執行時，您將會是能 toosee hello 數讀取 IOPS hello VM，並提供高階磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-875">While hello test runs, you will be able toosee hello number of read IOPS hello VM and Premium disks are delivering.</span></span> <span data-ttu-id="ffeb7-876">Hello 以下範例所示，hello DS14 VM 會將超過 64000 讀取 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-876">As shown in hello sample below, hello DS14 VM is delivering more than 64,000 Read IOPS.</span></span> <span data-ttu-id="ffeb7-877">這是 hello 磁碟和 hello 快取效能的組合。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-877">This is a combination of hello disk and hello cache performance.</span></span>  
    ![](media/storage-premium-storage-performance/image12.png)

<span data-ttu-id="ffeb7-878">*最大讀取和寫入 IOPS*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-878">*Maximum Read and Write IOPS*</span></span>  
<span data-ttu-id="ffeb7-879">建立 hello 工作檔案的最大的下列規格 tooget 結合讀取和寫入的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-879">Create hello job file with following specifications tooget maximum combined Read and Write IOPS.</span></span> <span data-ttu-id="ffeb7-880">將它命名為 "fioreadwrite.ini"。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-880">Name it "fioreadwrite.ini".</span></span>

```
[global]
size=30g
direct=1
iodepth=128
ioengine=libaio
bs=4k

[reader1]
rw=randread
directory=/mnt/readcache
[reader2]
rw=randread
directory=/mnt/readcache
[reader3]
rw=randread
directory=/mnt/readcache
[reader4]
rw=randread
directory=/mnt/readcache

[writer1]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer2]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer3]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer4]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
```

<span data-ttu-id="ffeb7-881">請注意 hello 遵循遵循先前章節所述的 hello 設計指導方針的重要事情。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-881">Note hello follow key things that are in line with hello design guidelines discussed in previous sections.</span></span> <span data-ttu-id="ffeb7-882">這些規格是不可或缺的 toodrive 最大 IOPS</span><span class="sxs-lookup"><span data-stu-id="ffeb7-882">These specifications are essential toodrive maximum IOPS,</span></span>

* <span data-ttu-id="ffeb7-883">較高的佇列深度 128。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-883">A high queue depth of 128.</span></span>  
* <span data-ttu-id="ffeb7-884">較小的區塊大小 4KB。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-884">A small block size of 4KB.</span></span>  
* <span data-ttu-id="ffeb7-885">執行隨機讀取和寫入的多個執行緒。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-885">Multiple threads performing random reads and writes.</span></span>

<span data-ttu-id="ffeb7-886">執行下列的 hello FIO 測試 30 秒，關閉命令 tookick hello</span><span class="sxs-lookup"><span data-stu-id="ffeb7-886">Run hello following command tookick off hello FIO test for 30 seconds,</span></span>

```
sudo fio --runtime 30 fioreadwrite.ini
```

<span data-ttu-id="ffeb7-887">Hello 測試執行時，您將無法 toosee hello 數目結合讀取和寫入 IOPS hello VM 提供高階磁碟。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-887">While hello test runs, you will be able toosee hello number of combined read and write IOPS hello VM and Premium disks are delivering.</span></span> <span data-ttu-id="ffeb7-888">Hello 以下範例所示，hello DS14 VM 會將 100,000 個以上的組合的讀取和寫入的 IOPS。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-888">As shown in hello sample below, hello DS14 VM is delivering more than 100,000 combined Read and Write IOPS.</span></span> <span data-ttu-id="ffeb7-889">這是 hello 磁碟和 hello 快取效能的組合。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-889">This is a combination of hello disk and hello cache performance.</span></span>  
    ![](media/storage-premium-storage-performance/image13.png)

<span data-ttu-id="ffeb7-890">*結合的最大輸送量*</span><span class="sxs-lookup"><span data-stu-id="ffeb7-890">*Maximum Combined Throughput*</span></span>  
<span data-ttu-id="ffeb7-891">最大 tooget hello 組合讀取和寫入的輸送量，請使用較大的區塊大小和大佇列深度具有多個執行緒執行讀取和寫入。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-891">tooget hello maximum combined Read and Write Throughput, use a larger block size and large queue depth with multiple threads performing reads and writes.</span></span> <span data-ttu-id="ffeb7-892">您可以使用 64KB 的區塊大小和 128 的佇列深度。</span><span class="sxs-lookup"><span data-stu-id="ffeb7-892">You can use a block size of 64KB and queue depth of 128.</span></span>

## <a name="next-steps"></a><span data-ttu-id="ffeb7-893">後續步驟</span><span class="sxs-lookup"><span data-stu-id="ffeb7-893">Next Steps</span></span>
<span data-ttu-id="ffeb7-894">深入了解 Azure 進階儲存體：</span><span class="sxs-lookup"><span data-stu-id="ffeb7-894">Learn more about Azure Premium Storage:</span></span>

* [<span data-ttu-id="ffeb7-895">Premium 儲存體：Azure 虛擬機器工作負載適用的高效能儲存體</span><span class="sxs-lookup"><span data-stu-id="ffeb7-895">Premium Storage: High-Performance Storage for Azure Virtual Machine Workloads</span></span>](../storage-premium-storage.md)  

<span data-ttu-id="ffeb7-896">若為 SQL Server 使用者，請參閱「SQL Server 的效能最佳作法」文章：</span><span class="sxs-lookup"><span data-stu-id="ffeb7-896">For SQL Server users, read articles on Performance Best Practices for SQL Server:</span></span>

* [<span data-ttu-id="ffeb7-897">Azure 虛擬機器中的 SQL Server 效能最佳作法</span><span class="sxs-lookup"><span data-stu-id="ffeb7-897">Performance Best Practices for SQL Server in Azure Virtual Machines</span></span>](../../virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md)
* [<span data-ttu-id="ffeb7-898">Azure 進階儲存體為 Azure VM 中的 SQL Server 提供最高效能</span><span class="sxs-lookup"><span data-stu-id="ffeb7-898">Azure Premium Storage provides highest performance for SQL Server in Azure VM</span></span>](http://blogs.technet.com/b/dataplatforminsider/archive/2015/04/23/azure-premium-storage-provides-highest-performance-for-sql-server-in-azure-vm.aspx)
